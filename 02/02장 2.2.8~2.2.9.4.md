### 2.2.8 컨테이너 로깅
#### - 2.2.8.1 json-file 로그 사용하기
```dockerfile
    컨테이너 내부에서 어떤 일이 일어나는지 아는 것은 디버깅 뿐만 아니라 운영 측면에서도 중료하다.
    애플리케이션 레벨에서 로그가 기록되도록 개발해 별도의 로깅 서비스를 쓸 수도 있지만 도커는 
    컨테이너의 표준 출력(StdOut)과 에러(StdErr) 로그를 별도의 메타데이터 파일로 저장하며 
    이를 확인하는 명령어를 제공한다.
    
        'docker run -d --name maria -e \
        mariadb_root_password=1234 \
        mariadb:10.5'
    
    mariadb와 같은 애플리케이션을 구동하는 컨테이너는 포그라운드 모드로 실행되므로 -d 옵션을 써서
    백그라운드 모드로 컨테이너를 생성하는 경우가 많습니다. 따라서 애플리케이션이 잘 구동되는지
    여부를 알 수 없지만 docker logs 명령어를 써서 컨테이너의 표준 출력을 확인함으로써
    애플리케이션의 상태를 알 수 있습니다.
    
    'docker logs' 명령어는 컨테이너 내부에서 출력을 보여주는 명령어입니다. 이 명령어는
    mariadb처럼 정상적으로 실행 및 동작하지 않고 docker attach 명령도 사용하지 못하는
    개발 환경에서 docker logs 명령어로 에러를 확인할 수 있습니다.
    
    로그가 너무 많아 읽기 힘들다면 -tail 옵션을 사용해서 마지막 로그 줄부터 출력할 줄의 수를
    정할 수 있습니다.
    
        'docker logs --tail 2 mariadb'
    
    위의 명령어는 마지막에서 2 줄만 출력하도록 하는 코드이다. 또한 '--since' 옵션에 유닉스 시간을 입력해서 특정 시간 이후의 로그를 확할 수 있으며,
    '-t' 옵션으로 타임 스탬프를 표시할 수도 있다. 또한 컨테이너에서 실시간으로 출력되는 내용을 확인하려면 '-f'옵션을 써서 로그를 스트림으로 확인할 수
    있습니다. '-f'는 애플리케이션을 개발할 때 유용하다.  'docker logs' 명령어는 run 명령어에서 '- it' 옵션을 설정해 'docker attach' 명령어를
    사용할 수 있는 컨테이너에도 쓸 수 있으며, 컨테이너 내부에서 bash 셸 등을 입출력한 내용을 확인할 수도 있다. 
    
    기본적으로 위와 같은 컨테이너 로그는 JSON 형태로 도커 내부에 저장된다. 이 파일은  /var/lib/docker/containers/${CONTAINER_ID}/${CON
    TAINER_ID}-json.log에 쌓인다. 그러나 컨테이너 내부의 출력이 너무 많은 상태로 방치하면 json 파일의 크기가 계속해서 커질 수 있고, 결국 호스트의 
    남은 저장 공간을 전부 사용할 수도 있다. 이러한 상황을 방지하기 위해서 --log-opt 옵션으로 컨테이너 json 로그 파일의 최대 크기를 지정할 수 있다.
    max-size는 로그 파일의 최대 크기, max-file은 로그 파일의 개수를 의미한다. 
    
        'docker run -it \
        --log-opt max-size = 10k --log-opt max-file=3 \
        --name log-test ubuntu:14.04'
    
     어떠한 설정도 하지 않았다면 도커는 위와 같이 컨테이너 로그를 JSON 파일로 저장하지만 그 밖에도 각종 로깅 드라이버를 사용하게 설정해서 컨테이너 로그를
     수집할 수도 있다. 사용 가능한 드라이버의 예로는 syslog, journald, fluentd, awslogs 등이 있으며 애플리케이션의 특징에 적합한 로깅 드라이버를
     선택하면 된다. 
     {
        로깅 드라이버는 기본적으로 json-file으로 설정되지만 도커 데몬 시작 옵션에서 --log-driver 옵션을 써서 기본적으로 사용할 로깅 드라이버를
        변경할 수 있다. 위에서 설명한 max-size와 같은 --log-opt 옵션 또한 도커 데몬에 적용함으로써 모든 컨테이너에 일괄적으로 사용할 수 있다. 
        
            'DOCKER_OPTS="--log-driver=syslog"'
            'DOCKER_OPTS="--log-opt max-size=10k --log-opt max-file=3"'
     }
```

#### - 2.2.8.2 syslog 로그
```dockerfile
    컨테이너 로그는 JSON뿐만 아니라 syslog로 보내 저장하도록 설정할 수 있다. syslog는 유닉스 계열 운영체제에서 로그를 수집하는 오래된 표중 중 
    하나로서, 커널, 보안 등 시스템과 관련된 로그, 애플리케이션의 로그 등 다양한 종류의 로그를 수집해 저장한다. 대부분 유닉스 계열 운영 체제에서는 syslog
    를 사용하는 인터페이스가 동일하므로 체계적으로 수집하고 분석할 수 있다는 장점이 있다. 
    
    다음 명령어를 입력해서 syslog에 로그를 저장하는 컨테이너를 생성할 수 있다. 컨테이너의 커맨드가 echo syslogstest로 설정되기 때문에 syslogtest
    라는 문구를 출력하고 컨테이너는 종료될 것이다.
    
        'docker run -d --name syslog_container \ 
        --log-driver=syslog \
        ubuntu:14.04'
        'echo syslogtest'
    
    syslog 로깅 드라이버는 기본적으로 로컬호스트의 syslog에 저장하므로 운영체제 및 배포한에 따라 syslog 파일의 위치를 알아야 이를 확인할 수 있다.
    우분투 14.04는 /var/log/syslog, Centos, RHEL은 /var/log/messages 파일에서 우분투 16.04, CoreOS는 journalctl -u docker.service
    명령어로 확인할 수 있다. 

    syslog를 원격 서버에 설치하면 로그 옵션을 추가해 로그 정보를 원격 서버로 보낼 수 있다. syslog를 원격에 저장하는 방법의 하나인 rsyslog를 써서
    중앙 컨테이너로 로그를 사용하면 구현할 수 있다. 
    
        'docker run -it \
        -h rsyslog \
        --name rsyslog_server \ 
        -p 514:514 -p 514:514/udp \
        ubuntu:14.04'
        
    컨테이너 내부의 rsyslog.conf 파일을 열어서 syslog 서버를 구동시키는 항목의 주석을 해제한 후 변경 사항을 저장한다.
        'vim /etc/rsyslog.conf'
        
        {
            # provieds UDP syslog reception
            $ModLoad imudp
            $UDPServerRun 514
            
            # provides TCP syslog reception
            $ModLoad imtcp
            $InputTCPServerRun 514
            ...
        }
    
        'service rsyslog restart'
    
    rsyslog 서비스를 재시작 한다.  컨테이너를 빠져나온 뒤 클라이언트 호스트에서 아래의 명령어를 입력해서 컨테이너를 생성한다.
    
        'docker run -it \
        --log-driver=syslog \
        --log-opt syslog-address=tcp://192.168.0.100:514 \
        --log-opt tag="mylog" \
        ubuntu:14.04'
    
    '--log-opt'는 로깅 드라이버를 추가할 옵션을, 'syslog-address'에 rsyslog 컨테이너를 접근할 수 있는 주소를 입력한다.
    'tag'는 로그 데이터가 기록될 때 함께 저장될 태그이며 로그를 분류하기 위해서 사용한다. 
    (--log-opt syslog-address=udp://192.168.0.100:514로 이미 열어 놓은 udp로도 쓸 수 있다.)
    
    '--log-opt' 옵션으로 syslog-facility를 쓰면 로그가 저장될 파일을 바꿀 수 있다. 'facility'는 로그를 생성하는 주체에 따라 
    로그를 다르게 저장하는 것으로, 여러 애플리케이션에서 수집되느 ㄴ로그를 분류하는 방법이다. 기본적으로 daemon으로 설정되어 있지만, kern, user, mail
    등 다른 facility를 사용할 수 있다.
    
        'docker run -i -t \
        --log-driver syslog \
        --log-opt syslog-address=tcp://192.168.0.100:514 
        --log-opt tag="maillog" \
        --log-opt syslog-facility="mail"
         ubuntu:14.04'
         
    facility 옵션을 쓰면 rsyslog 서버 컨테이너에 해당 facility에 해당하는 새로운 로그 파일이 생성된다.  
    rsyslog는 우분투에서 쓸 수 있는 기본적인 로깅 방법이므로 별도의 UI를 제공하지는 않지만 logentries, LogAnalyzer 등과 같은 로그 분석기와
    연동하면 웹 인터페이스를 활용해서 편리하게 로그를 확인할 수 있다.
```

#### - 2.2.8.3 fluentd 로깅
```dockerfile
    fluentd는 각종 로그를 수집하고 저장할 수 있는 기능을 제공하는 오픈소스 도구로서, 도커 엔진의 컨테이너의 로그를 fluentd를 통해 저장할 수 있도록
    플러그인을 공식적으로 제공한다. fluentd는 데이터 포맷으로 JSON을 사용하기 때문에 쉽게 사용할 수 있을뿐만 아니라 수집되는 데이터를 AWS S3, 
    HDFS(Hadoop Distributed File System), MongoDB 등 다양한 저장소에 저장할 수 있다는 장점이 있다.
    
    예시로 fluentd와 몽고 DB와 연결하는 플로우이다. 
    
        도커 서버1 ⌝
                 ├ fluentd 서버 --- mongoDB   
        도커 서버2 ⌟
```

#### - 2.2.8.4 아마존 클라우드워치 로그
```dockerfile
    AWS에서는 로그 및 이벤트 등을 수집하고 저장해 시각적으로 보여주는 CloudWatch를 제공한다. 도커를 AWS EC2에서 사용하고 있다면 다른 도구를 별도로
    설치할 필요 없이 컨테이너에서 드라이버 옵션을 설정하는 것만으로 클라우드워치 로깅 드라이버를 설치할 수 있다.
    
        - 클라우드워치에 해당하는 IAM 권한 생성 (CloudWatchFull)
        - 로그 그룹 생성 (Management and Governence > CloudWatch)
        - 로그 그룹에 로그 스트림(LogStream) 생성
        - 클라우드워치의 IAM 권한을 사용할 수 있는 EC2 인스턴스 생성과 로그 전송 (EC2 인스턴스에 클라우드 워치 사용 권한 추가)
```
------------------
###  2.2.9 컨테이너 자원 할당 제한
```dockerfile
    컨테이너를 생성하는 run, create 명령어에서 컨테이너의 자원 할당량을 조정하도록 옵션을 입력할 수 있다. 아무런 옵션을 입력하지 않으면 컨테이너는 
    호스트의 자원을 제한 없이 쓸 수 있게 설정되므로 제품 단계의 컨테이너를 고려한다면 컨테이너의 자원 할당을 제한해 호스트와 다른 컨테이너의 동작을
    방해하지 않게 설정하는 것이 좋다. 컨테이너에 자원 할당 옵션을 설정하지 않으면 호스트의 자원을 전부 점유해 다른 컨테이너들뿐만 아니라 호스트 자체 동작이
    멈출 수도 있다.
    
    현재 컨테이너에 설정된 자원 제한을 확인하는 가장 쉬운 방법은 'docker inspect' 명령어를 입력하는 것이다. 
    
    {
        run 명령어에서 설정된 컨테이너의 자원 제한을 변경하려면 'update' 명령어를 사용한다.
        
        'docker update' [변경할 자원 제한] [컨테이너 이름]
        
        'docker updtae --cpuset-cpus=1 centos ubuntu'
    }
```

#### - 2.2.9.1 컨테이너 메모리 제한
```dockerfile
    docker run 명령어에 --memory를 지정해 컨테이너의 메모리를 제하할 수 있다. 입력할 수 있는 단위는 m, g이며 제한할 수 있는 최소  메모리는 4MB
    이다. 
    
        'docker run -d \
        --memory = "1g" \
        --name memory_1g \
        nginx
        '
    
    위 명령어로 컨테이너를 생성한 뒤 insepct 명령어로 메모리의 값을 확인하면 1GB에 해당하는 바이트 값이 설정 됐음을 확인할 수 있다.
    
        'docker inspect memory_1g | grep \"Memory\"'
        
    컨테이너 내에서 동작하는 프로세스가 컨테이너에 할당된 메모리를 초과하면 컨테이너는 자동으로 종료되므로 애플리케이션에 따라 메모리를 적절하게 할당
    하는 것이 좋습니다. 다음 명령어는 메모리를 매우 적게 할당하는 경우로서 4MB 메모리로 mysql 컨테이를 실행하면 메모리가 부족해서 컨테이너가 실행되지 
    않는다. 
    
        'docker run -d --name memory_4m \
        --memory="4m" \
        mysql:5.7'
    
    기본적으로 컨테이너의 Swap 메모리는 메모리의 2배로 설정되지만 별도로 지정할 수 있다. 
    
        'docker run -it --name swap_500m \
        --memory=200m \
        --memory-swap=500m
        ubuntu:14.04'
        
    위와 같이 스왑 메모리를 지정할 수 있다. 
```

#### - 2.2.9.2 컨테이너 CPU 제한 
```dockerfile

    1. --CPU-shares
    
    --cpu-shares 옵션은 컨테이너에 가중치를 설정해 해당 컨테이너가 CPU를 상대적으로 얼마나 사용할 수 있는지를 나타낸다. 즉 컨테이너에 CPU를 한 개씩 
    할당하는 방법이 아닌, 시스템에 존재하는 CPU를 어느 비중만큼 나눠 쓸 것인지를 명시하는 옵션이다. 
    
        'docker run -it --name cpu_share \
        --cpu-share 1024 \
        ubuntu:14.04'
        
    --cpu-shares 옵션은 상대적인 값을 가진다. 아무런 설정을 하지 않았을 때 컨테이너가 가지는 값은 1024로 이는 cpu 할당에서 1의 비중을 의미한다. 
    --cpu-shares 값을 1024로 설정했더라도, 호스트에 다른 컨테이너가 존재하지 않으면 CPU를 예상 이상으로 사용할 수 있다. 그렇지만 --cpu-shares의 
    값이 512로 설정된 컨테이너가 같이 실행된다면 어떻게 될까?
    
    이 경우에는 두 컨테이너가 2:1 비율로 CPU를 나눠쓰는 것을 알 수 있다. 이처럼 --cpu-shares에 설정된 값의 비율에 따라 컨테이너가 CPU를 사용할 수 있는
    비율이 정해진다. 
    
    {
        apt-get install stress로 stress를 설치한 뒤, stress라는 명령어로 CPU와 메모리에 과부하를 줘서 성능을 테스트할 수 있다.
    }


    2. --cpuset-cpu
    
    호스트에 CPU가 여러 개 있을 때 --cpuset-cpus 옵션을 지정해 컨테이너가 특정 CPU만 사용하도록 설정하도록 할 수 있다. CPU 집중적인 작업이 필요하다면
    여러 개의 CPU를 사용하도록 설정해 작업을 적절하게 분배하는 것이 좋다. 
    
        'docker run -d --name cpuset_2 \
        --cpuset-cpus=2 \
        alicek106/stress \
        stress --cpu 1'
        
    CPU 별로 사용량을 확인할 수 있는 도구로 htop이 있으며, 우분투와 CentOS에서 각각 아래의 명령어로 설치할 수 있다.
    
        {
            UBUNTU : apt-get install htop
            CentOS : yum -y install epel-release && yum -y install htop
        }
        
    htop 명령어로 CPU 사용량을 확인할 수 있다.
    
    
    3. --cpu-period, --cpu=quota
    
    컨테이너의 CFS(Completely Fair Scheduler) 주기는 기본적 100ms로 설정되만 run 명령어의 옵션 중 --cpu-period와 --cpu-quota로 이 주기를
    변경할 수 있다. 
    
        'docker run -d --name quita_1_4 \ 
        --cpu-period=100000 \
        --cpu-quota=25000 \
        alicek106/stress \
        stress --cpu 1'
        
    --cpu-period의 값은 기본적으로 100000이며, 이는 100ms를 뜻한다. --cpu-quota는 --cpu-period에 설정된 시간 중 CPU 스케쥴링에 얼마나
    할당할 것인지를 설정한다. 위의 예시는 CPU 주기가 1/4로 줄었으므로 일반적인 컨테이너보다 CPU 성능이 1/4 정도로 감소한다. 
    즉, 컨테이너는 [--cpu-quota] / [--cpu-period] 만큼 CPU 시간을 할당받는다.
    
    
    
    4. --cpus
    
    --cpus 옵션은 --cpu-period, --cpu-quota와 동일한 기능을 하지만 좀 더 직관적으로 CPU의 개수를 직접 지정한다는 점에서 다르다. 
    예를 들어 --cpus로 0.5를 설정하면 --cpu-period=100000 또는 --cpu-quota=50000와 동일하게 컨테이너 CPU를 제한할 수 있다.
    
        'docker run -d --name cpus_container \
        --cpus=0.5 \
        alicek106/stress \
        stress -cpu1'
        
    마찬가지로 컨테이너의 사용량을 확인해보면 CPU의 50%을 점유하고 있음을 알 수 있다. 
    
    {
        병렬 처리를 위해 CPU를 많이 소모하는 워크로드를 수행해야 한다면 --cpu-share, --cpus, --cpu-period, --cpu-quota 옵션보다는
        --cpuset-cpu 옵션을 사용하는 것이 좋다. 
        --cpuset-cpu 옵션을 사용하면 특정 컨테이너가 특정 CPU에서만 동작하는 CPU 친화성(Afiinity)을 보장할 수 있고, CPU캐시 미스 또는
        컨텍스트 스위칭과 같이 성능을 하락시키는 요인을 최소할 가능성이 높아지기 때문이다.
    }
    
```

#### - 2.2.9.3 Block I/O 제한
```dockerfile
    컨테이너를 생성할 때 아무런 옵션도 설정하지 않으면 컨테이너 내부에서 파일을 쓰는 대역폭 제한이 설정되지 않는다. 하나의 컨테이너가 블록 입출력을 과도하게 
    사용하지 않게 설정하려면 run 명령어에서 '--device-write-bps', '--device-read-bps', '--device-write-iops', 
    '--device-read-iops' 옵션을 지정해 블록 입출력을 제한할 수 있습니다. 단 Direct I/O의 경우에만 블록 입출력이 제한되며, Buffered I/O는 
    제한되지 않는다. 
    
    '--device-write-bps', '--device-read-bps'는 각기 읽고 쓰는 작업의 초당 제한을 설정하며, kb, mb, gb 단위로 제한할 수 있다. 예를 들어,
    
        'docker run -it \
        --device-write-bps / dev/xvda:1mb \
        ubuntu:14.04'
    
    로 생성하면 쓰기 작업이 초당 1MB로 제한되는 것을 확인할 수 있다.
    
    {
        여기서 사용되는 Block I/O를 제한하는 옵션은 [디바이스 이름]:[값] 형태로 설정해야한다. 
    }
    
        'dd if=/dev/zero of=test.out bs=1M count=10 oflag=direct'
    
    CPU의 자원 할당에서 --cpu-share에 상대적인 값을 입력했던 것처럼 --device-write-iops, --device-read-iops에도 상대적인 값을 입력한다.

```

#### - 2.2.9.4 스토리지 드라이버와 컨테이너 저장 공간 제한
```dockerfile
    도커 엔진은 컨테이너 내부의 저장 공간을 제한하는 기능을 보편적으로 제공하지는 않지만, 도커의 스토리지 드라이버나 파일 시스템 등이
    특정 조건을 만족하는 경우에만 이 기능을 제한적으로 사용할 수 있다. 
    단, 모든 스토리지 드라이버에서 컨테이너의 저장 공간을 제한할 수 있는 것은 아니다. 따라서 컨테이너 애플리케이션이 해당 스토리지 드라이버에 적합하지
    않다면 이 기능을 사용하지 않는 것이 좋을 수도 있다. 또한 컨테이너 내부에서 개발하고 있거나, 그 외 다른 특별한 상황이 아니라면 컨테이너
    자체가 상태를 가지는(stateful) 것은 그다지 바람직하지 않다. 따라서 컨테이너의 저장 공간을 제한하지 않는 선택지도 고려해 볼 수 있다. 
```

