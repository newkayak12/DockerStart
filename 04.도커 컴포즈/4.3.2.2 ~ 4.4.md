#### 4.3.2.2 도커 컴포즈 네트워크
```dockerfile
  YAML 파일에 네트워크 항목을 정의하지 않으면 도커 컴포즈는 프로젝트 별로 브릿지 타입의 네트워크를 생성한다. 생성된 네트워크의 이름은 
  {프로젝트 이름}_default로 설정되며, "docker-copmpose up" 명렁어로 생성되고 docker-compose down 명령어로 삭제된다. 
  
      'docker-compose up -d'
      Creating network "ubuntu_default" with the default driver
      ...
      
      'docker-copose down'
      ...
      Removing network ubuntu_default

  docker-compose up 명령어뿐만 아니라 docker-compose scale 명령어로 생성되는 컨테이너 전부가 이 브릿지 타입의 네트워크를 사용한다. 
  서비스 내의 컨테이너는 --net-alias가 서비스의 이름을 갖도록 자동으로 설정되므로 이 네트워크에 속한 컨테이너는 서비스의 이름으로 서비스 내의
  컨테이너에 접근할 수 있다. 

  예를 들어, web 서비스와 mysql 서비스가 각기 존재할 떄 web 서비스의 컨테이너가 mysql이라는 호스트 이름으로 접근하면 mysql 서비스의 컨테이너 중
  하나의 IP로 변환(resolve)되며, 컨테이너 여러 개 존재할 경우 라운드 로빈으로 연결을 분산한다.

  따라서 docker-compose scale 명령어로 컨테이너 수를 늘려도 해당 서비스의 이름으로 서비스의 모든 컨테이너에 접근할 수 있다. 
  서비스 이름으로 컨테이너 접근하는 방식은 스웜 모드의 서비스와 유사하지만 작동 원리는 다르다. 
```

#### 4.3.2.3 도커 스웜 모드와 함께 사용하기 
```dockerfile
    도커 컴포즈 1.10 버전에서 스웜 모드와 함께 사용할 수 있는 YAML 버전 3이 배포됨에 동시에 스웜 모드와 함께 사용되는 개념인 스택(stack)이 
    도커 엔진 1.13 버전에 추가됐다. 스택은 YAML파일에서 생성된 컨테이너의 묶음으로서 YAML 파일로 스택을 생성하면 YAML 파일에 정의된 서비스가
    스웜 모드의 클러스터에서 일괄적으로 생성된다. 즉, YAML 파일에 정의된 서비스가 스웜 모드의 서비스로 변환된 것이다.
    단 스택은  도커 컴포즈의 명령어인 docker-compose가 아닌 docker stack으로 제어해야한다. 정확히 말하자면 스택은 도커 컴포즈에 의해서 생성된
    것이 아니라 스웜 모드 클러스터의 매니저에 의해 생성된 것이다.
    
    1. 스택 사용하기 
```
```yaml
     networks: {}
     services: 
       mysql:
            command: mysqld
            image: alicek106/composetest:mysql
        web:
           command: apachectl -DFORGROUND
           image: alicek106/composetest:web
            links:
           - mysql:db
           ports:
           - 80:80
     version: '3.0'
     volumes: {}
```
```dockerfile
    위의 docker-compose.yml을 스택으로 변환해보자 'docker stack deploy' 명령어에 --config-file, 또는 -c 옵션으로 YAML 파일을
    지정한 뒤 마지막에 스택 이름을 입력한다.
     
      'docker stack deploy -c docker-compose.yml mystack'
     
      "Ignoring unsupported options: links"
      "Creating network mystack_default"
      ...
    
    Ignoring unsupported options:links에서 볼 수 있듯, links나 depends_on과 같이 컨테이너 간의 의존성을 정의하는 항목을 사용할 수 
    없다. 앞서 언급한 도커 수웜에서 도커 컴포즈를 사용하느 ㄴ제약사항에 links를 사용하려면 양 컨테이너가 같은 호스트에 생성돼야 하기 때문이다. 
    
    생성된 스택은 docker stack ls 명령어로 확인할 수 있으며, docker stack ps 명령어로 특정 서비스에 존재하는 컨테이너를 확인할 수도 있다.
    서비스 이름은 [스택 이름]_[YAML 파일에 정의된 서비스의 이름]으로 구성된다. 
     
      'docker stack ls'
        NAME    SERVICES
        mystack     2
     
      'docker stack ps mystack'
        
        
    스택에서 생성된 서비스는 스웜 모드에서 사용된 서비스와 같으므로 docker service 명령어로도 확인할 수 있다. 예를 들어, docker service ls
    와 docker stack services는 'docker service ls'와 같은 정보를 출력한다. 
    스택은 도커 컴포즈가 아닌 스웜 킷에 의해 생성되므로 'docker-compose scale' 명령어가 아닌 'docker service scale'을 사용해 컨테이너 
    수를 조절해야한다. 이는 스웜 모드에서 설명한 'docker service scale' 명령어와 같으므로 클러스터에 컨테이너가 적절히 분배된다. 
       
       'docker service scale mystack_web=2'
   
    스택을 삭제하려면 'docker stack rm' 명령어를 사용한다. 또한 'docker service rm'으로도 스택의 서비스를 하나씩 삭제할 수 있다. 가능하면
    'docker stack' 명령어로 생성된 서비스는 'docker stack rm'으로 삭제하는 것이 좋다. 
       
       'docker stack rm mystack' 
         
    2. 스택 네트워크
    도커 컴포즈에서 프로젝트를 생성했던 것과 같이 스택도 해당 스택을 위한 네트워크가 자동으로 생성된다. 스택을 생성할 때 
    "Creating network mystack_default"와 같은 출력 결과를 확인했다면 알 수 있다. 
    그러나 도커 컴포즈의 네트워크와 다르게 스택의 네트워크는 기본적으로 오버레이 네트워크 속성을 가지며 스웜 클러스터에서 사용하도록 설정된다.
    'docker network ls' 명령어로 스택의 네트워크를 확인해보면 SCOPE가 swarm으로 설정된 것을 알 수 있다. 이 네트워크는 '--attachable'
    옵션이 설정되지 않기 떄문에 일반 컨테이너는 이 네트워크를 사용할 수 없다.


### 4.4 도커 학습을 마치며: 도커와 컨테이너 생태계
    이번 절에서 도커 내부의 구조와 컨테이너 생태계를 알아볼 것이다. 도커는 컨테이너 기술이 특정 벤더 또는 회사에 의존적으로 개발되지 않도록 중립적인
    입장에서 컨테이너 표준을 정의하는 OCI(Open Container Initiative)를 발표했다. OCI에서는 컨테이너를 구성하기 위해서 공통적으로 구현돼야
    하는 런타임 및 이미지 스펙의 표준을 정의하고 있으며, 도커 컨테이너를 포함한 여러 컨테이너 기술이 OCI를 준수하고 있다. OCI 발표 이후
    Moby라는 프로젝트 안에서 도커 컨테이너 기술을 관리하기 시작했고, 도커는 runC, containerd 그리고 도커 엔진으로 분리됐다. 
    
    도커의 핵심 프로세스라고 하면 보통 도커 데몬(dockerd)을 떠올리기 쉽지만 사실 도커 데몬은 컨테이너가 아니다. 실제로 컨테이너 프로세스라고 
    부를 수 있을 만한 것은 dockerd가 아닌 runC이며, 컨테이너에 1:1로 매칭되는 런타임 역할을 runC가 담당한다. 그리고 여러 개의 runC
    컨테이너 프로세스 및 이미지를 관리하는 주체가 바로 containerd이다 우리가 알고 있는 도커 엔진(dockerd 프로세스)은 containerd와 통신해 
    runC를 사용할 수 있도록 하는 엔즈 유저용 도구에 불과하다. 
    
    runc, contained 프로세스는 도커가 실행 중인 호스트에서도 바로 확인할 수 있다.
    
    root@ubuntu:/home/pi# ps aux | grep containerd
    
    root         795  0.0  1.0 1557204 40228 ?       Ssl  05:00   0:23 /usr/bin/containerd
    root         866  0.0  1.8 1511748 70168 ?       Ssl  05:00   0:36 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock
    root        1360  0.0  0.2 711016  8460 ?        Sl   05:02   0:14 /usr/bin/containerd-shim-runc-v2 -namespace moby -id 6c6374fada0fdc95bc79443b385a439b3cf79a3859a727611fa60bfb2d32a56f -address /run/containerd/containerd.sock
    root        1363  0.0  0.2 711016  7972 ?        Sl   05:02   0:10 /usr/bin/containerd-shim-runc-v2 -namespace moby -id de8ee888b34f63028b5063b5ecccd5a2486e5c59d7158f4e9806c193dbec4924 -address /run/containerd/containerd.sock
    
    컨테이너를 생성하고 사용하기 위해 도커가 반드시 필요한 것은 아니며, runC와  containerd는 도커 엔진 없이도 독립적으로 사용할 수 있다. 따라서 
    우리가 흔히 "도커 컨테이너"라고 부르는 것은 정확히 말하면 "도커"가 아니다. 하지만 일반적으로 사용자의 편의, 또는 다른 컴포넌트와의 통합을 위해
    도커 엔진과 runC, containerd를 함께 사용하는 경우가 대부분이기 때문에 이러한 것의 총칭을 "도커 컨테이너"라고 부르는 경우가 많다.
    
    컨테이너 생태계에는 runC와 containerd 외에도 다양한 컨테이너들이 존재한다. 호스트와 격리 수준을 높이는 kata, AWS에서 개발하고 있는 
    firecracker, 쿠버네티스 생태계에서 containerd에 대응하는 cri-o 및 도커 엔진에 대응되는 Podman 등 다양한 목적을 위해 수많은 컨테이너
    런타임이 존재한다. 그 중에서 도커가 가장 성숙한 기술기기 때문에 가장 많이 사용되고 있을 뿐, 절대적으로 도커 컨테이너만을 사용해야하는 것은 아니다.
     