```dockerfile
            퍼시스턴트 볼륨(PV)와 퍼시스턴트 볼륨 클레임(PVC)
    
    지금까지 사용했던 테스트용 디플로이먼트는 모두 상태가 없는(stateless) 애플리케이션이었다. 즉, 디플로이먼트의 각 포드는 별도의 데이터를 가지고 있지 
    않았으며, 단순히 요청에 대한 응답만을 반환했다. 그렇지만 데이터베이스처럼 포드 내부에서 특정 데이터를 보유해야하는, 상태가 있는(stateful) 애플리케이션
    의 경우에는 데이터를 어떻게 관리해야할지 고민해야 한다. 예를들어 MySQL 디플로이먼트를 통해 포드를 생성했다고 하더라도 MySQL 포드 내부에 저장된
    데이터는 절대 영속적이지 않다. 디플로이먼트가 삭제되면 포드도 함께 삭제되고, 그와 동시에 포드의 데이터 또한 함께 삭제된다. 
    
    이를 해경하기 위해서는 포드의 데이터를 영속적으로 저장하기 위한 방법이 필요하다. 이전에 도커에서 볼륨을 다룰 때 사용했던 'docker run -v' 옵션이나
    'docker volume' 명령어가 있다. 이러한 옵션들은 단일 컨테이너의 디렉토리를 호스트와 공유함으로써 데이터를 보존했다.
        
        {
            'docker volume create myVolume'
            'docker run -it --name test -v myVolume:/mn ubuntu:16.04'
        } 
        
    쿠버네티스에서도 호스트에 위치한 디렉토리를 각 포드와 공유함으로써 데이터를 보존하는 것이 가능하다. 그렇지만 여러 개의 서버로 구성된 쿠버네티스와 같은
    클러스터 환경에서는 이 방법이 적합하지 않을 수 있다. 쿠버네티스는 워커 노드 중 하나를 선택해서 포드를 할당하는데, 특정 노드에서만 데이터를 보관해 
    저장하면 포드가 다른 노드로 옮겨갔을 때 해당 데이터를 사용할 수 없게 된다. 따라서 특정 노드에서만 포드를 실행해야하는 경우가 발생할 수 있다.
    
    이를 해결할 수 있는 일반적인 방법은 어느 노드에서도 접근해서 사용할 수 있는 퍼시스턴트 볼륨(Persistent Volume)을 사용하는 것이다. 퍼시스턴트 볼륨은 
    워커 노드들이 네트워크상에서 스토리지를 마운트해 영속적으로 데이터를 저장할 수 있는 볼륨을 의미한다. 따라서 포드에 장애가 생겨 다른 노드로 옮겨가더라도
    해당 노드에서 퍼시스턴트 볼륨에 네트워크로 연결해 데이터를 계속해서 사용할 수 있다. 네트워크로 연결해 사용할 수 있는 퍼시스턴트 볼륨의 대표적인 에로는
    NFS, AWS의 EBS(Elastic Block Store), Ceph, GlusterFS 등이 있다.
    
    쿠버네티스는 퍼시스턴트 보륨을 사용하기 위한 기능을 자체적으로 제공하고 있다. 이번 장에서는 상태를 가지는 프도의 데이터를 보존하기 위한 쿠버네티스
    오브젝트인 퍼시스턴트 볼륨(Persistent Volume: PV), 퍼시스턴트 볼륨 클레임(Persistent Volume Clain: PVC)에 대해서 살펴볼 것이다.
    
    
    
            > 로컬 볼륨 : hostPath, emptyDir
    쿠버네티스가 어떻게 볼륨을 관리하는지 알아보기 전에 볼륨을 간단히 사용해 볼 수 있는 hostPath, emptyDir 두 가지 볼륨에 대해서 먼저 알아봐야한다.
    hostPath는 호스트와 볼륨을 공유하기 위해서 사용하고, emptyDir는 포드의 컨테이너 간에 볼륨을 공유하기 위해서 사용한다. 
    
          
          
            > 워커 노드의 로컬 디렉토리를 볼륨으로 사용하기 : hostPath
    포드의 데이터를 보존할 수 있는 가장 간단한 방법은 호스트의 디렉토리를 포드와 공유해 데이터를 저장하는 것이다. 호스트와 디렉토리를 공유하는 포드를
    생성하기 위해 아래의 내용으로 YAML 파일을 작성해보자
```
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: hostpath-pod
spec:
  containers:
    - name: my-container
      image: busybox
      args: ["tail", "-f", "/dev/null"]
      volumeMounts:
      - name: my-hostpath-volume
        mountPath: /etc/data
  volumes:
    - name: my-hostpath-volume
      hostPath:
        path: /tmp
```
```dockerfile   
    이전에 컨피그맵을 포드의 볼륨으로 사용했던 것과 비슷한 형식이다. volumes 항목에 볼륨을 정의한 뒤, 이를 포드를 정의하는 conainers 항목에서 참조해서
    사용한다. 위 예시에서는 볼륨에서 hostPath 항목을 정의함으로써 호스트의 /tmp를 포드의 /etc/data에 마운트 했다.
    
    포드를 생성한뒤 포드의 컨테이너 내부로 들어가 /etc/data 디렉토리에 파일을 생성하면 호스트의 /tmp에 파일이 저장된다. 포드 컨테이너의 /etc/data와
    호스트 /tmp는 동일한 디렉토리로써 사용되는 것이다.
    
        'kubectl apply -f hostpath-pod.yaml'
        'kubectl exec -it hostpath-pod touch /etc/data/mydata'
        
    그렇지만 이러한 방식의 데이터 보존은 바람직하지 않다. 디플로이먼트의 포드에 장애가 겨 다른 노드로 포드가 옮겨갔을 경우, 이전 노드에 저장된 데이터를 
    사용할 수 없기 때문이다. hostPath 방식의 볼륨을 반드시 사용해야한다면 스케쥴링을 이용해 특정 노드에만 포드를 배치하는 방법도 생각해볼 수 있지만,
    이 방법 또한 호스트 서버에 장애가 생기면 데이터를 잃게 된다는 단점이 있다.
    
    그렇지만 hostPath 볼륨은 모든 노드에 배치해야하는 특수한 포드의 경우에 유용하게 사용할 수 있다. 예를 들어 모니터링 툴인 CAdvisor는 호스트의 디렉토리
    와 도커 소켓(/var/run/docker.sock)등을 컨테이너 내부로 공유해 모니터링 데이터를 수집했다.
    
        ' docker run \
        --volume=/:rootfs:ro \ 
        --volume=/var/run:/var/run:rw \
        --volume=/sys:/sys:ro \
        --volume=/var/lib/docker/:/var/lib/docker:ro \
    
    만약 CAdvisor와 같은 모니터링 툴을 쿠버네티스의 모든 워크 노드에 배포해야한다면 hostPath를 사용하는 것이 옳은 선택일 것이다. 단, 이러한 특수한 경우
    를 제외한다면 hostPath를 사용하는 것은 보안 및 활용성 측면에서 그다지 바람직하지 않으므로 hostPath를 사용하는 것을 신중히 고려하는 것이 좋다.
    
    
        > 포드 내의 컨테이너 간 임시 데이터 공유 : emptyDir
    emptyDir 볼륨은 포드의 데이터를 영속저긍로 보존하기 위해 외부 볼륨을 사용하는 것이 아닌, 포드가 실행되는 도중에만 필요한 휘발성 데이터를 각 컨테이너가
    함께 사용할 수 있도록 임시 저장 공간을 생성한다. emptyDir이라는 이름이 의미하는 것처럼 emptyDir 디렉토리는 비어있는 상태로 생성되며, 포드가 
    삭제되면 emptyDir에 있던 데이터도 함께 삭제된다. emptyDir을 사용하는 간단한 예시로 아파치 웹 서버를 생성하는 포드를 생성해볼 것이다. 아래의 yaml
    은 아파치 웹서버의 루트(htdocs)를 emptyDir에 마운트함과 동시에 이 디렉토리를 cotent-creator 컨테이너의 /data 디렉토리와 공유한다. 
```
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: emptydir-pod
spec
  containers:
  - name: content-creator
    image: alicek106/alpine-wget:latest
    args: ["tail", "-f", "/dev/null"]
    volumeMounts:
    - name: my-emptydir-volume
      mountPath: /data      # 1. 이 컨테이너가 /data에 파일을 생성하면
      
  - name: apache-webserver
    image: httpd:2
    volumeMounts:
    - name: my-emptydir-volume
      mountPath: /usr/local/apache2/htdocs/  # 2. 아파치 웹서버에서 접근할 수 있다.

  volumes:
    - name: my-emptydir-volume
      emptyDir: {}              #포드 내에서 파일을 공유하는 emptyDir
```
```dockerfile
    emptyDir은 한 컨테이너가 파일을 관리하고 한 컨테이너가 그 파일을 사용하는 경우에 유용하게 사용할 수 있다. content-creator 컨테이너 내부로 들어가
    '/data' 디렉토리에 웹 콘텐츠를 생성하면 아파치 웹 서버 컨테이너의 htdocs 디렉토리에도 동일하게 웹 컨텐츠 파일이 생성될 것이고, 이는 최종적으로
    웹 서버에 의해 외부로 제공될 것이다. 
    
        'kubectl apply -f emptydir-pod.yaml'
        'kubectl exec -it emptydir-pod -c content-creater sh #echo Hello, Kubernetes! >> /data/test.html'

    이러한 emptyDir의 사용 방법은 단적인 예시일 뿐이며, 애플리케이션 구성에 따라 다양한 방법으로 사용할 수 있다. 예를 들어 깃허브 소스코드를 받아 empty
    Dir을 통해 애플리케이션 컨테이너에 공유해주는 사이드카 컨테이너를 생각해볼 수도 있고, 설정 파일을 동적으로 갱신하는 컨테이너를 포드에 포함시킬 수도 있다.
    
    
    
            > 네트워크 볼륨
    쿠버네티스에서는 별도의 플러그인 없이 다양한 종류의 네트워크 볼륨을 포드에 마운트할 수 있다. 온프레미스 환경에서도 구축할 수 있는 NFS, iSCSI, 
    GlusterFS, Ceph와 같은 네트워크 볼륨뿐만 아니라 AWS의 EBS(Elastic Block Store), GCP의 gcePersistentDisk와 같은 클라우드 플랫폼의
    볼륨을 포드에 마운트할 수도 있다. 
    네트워크 볼륨의 위치는 특별히 정해진 것이 없으며, 네트워크로 접근할 수만 있다면 쿠버네티스 클러스터 내부, 외부 어느 곳에 존재하도 크게 상관은 없다.
    단, AWS의 EBS와 같은 클라우드에 종속적인 볼륨을 사용하려면 AWS에서 쿠버네티스 클러스터를 생성할 때 특정 클라우드를 위한 옵션이 별도로 설정되어 있어야
    한다. 쿠버네티스에서 사용할 수 있는 네트워크 볼륨의 종류는 매우 많기 때문에 이번 절에서는 간단히 사용해볼 수 있는 NFS 볼륨의 사용법만 볼 것이다. 
    
            > NFS를 네트워크 볼륨으로 사용하기 
    NFS(Network File System)은 대부분의 운영체제에서 사용할 수 있는 네트워크 스토리지로 여러 개의 클라이언트가 동시에 마운트해 사용할 수 있다는 특징이
    있다. NFS는 여러 개의 스토리지를 클러스터링하는 다른 솔루션에 비해서 안정성이 떨어질 수 있으나 하나의 서버만으로 간편하게 사용할 수 있으며, NFS를
    마치 로컬 스토리지처럼 사용할 수 있다는 장점이 있다. NFS를 사용하려면 NFS 서버와 NFS 클라이언트가 각각 필요하다. NFS 서버는 영속적인 데이터가
    실제로 저장되는 네트워크 스토리지 서버이고, NFS 클라이언트는 NFS 서버에 마운트해 스토리지에 파일을 읽고 쓰는 역할을 한다. NFS 클라이언트는 워크 노드
    의 기능을 사용할 것이므로 따로 준비할 필요는 없으며, NFS 서버만 별도로 구축하면 된다.
    
    실제 운영환경에서 NFS를 사용하려면 별도의 튜닝이 적용된 NFS 서버를 구축하는 것이 좋지만 테스트로 쿠버네티스 클러스터 내부에 임시 NFS 서버를 생성해보자
    아래의 내용으로 nfs-deployment.yaml파일과 nfs-service.yaml을 작성한 뒤 디플로이먼트를 생성한다.
```
```yaml
apiVersion: apps/v1
kind: Deployment
metadata: 
  name: nfs-server
spec:
  selector:
    matchLabels:
      role: nfs-server
  template:
    metadata:
      labels:
        role: nfs-server
    spec:
      containers:
      - name: nfs-server
        image: gcr.io/google_containers/volume-nfs:0.8
        ports:
          - name: nfs
            containerPort: 2049
          - name: mountd
            containerPort: 20048
          - name: rpcbind
            containerPort: 111
        securityContext:
            privileged: true
```
```yaml
apiVersion: v1
kind: Service
metadata:
  name: nfs-service
spec: 
  ports:
  - name: nfs
    port: 2049
  - name: mountd
    port: 20048
  - name: rpcbind
    port: 111
  selector:
    role: nfs-server
```
```dockerfile
    'kubectl apply -f nfs-deployment.yaml'
    'kubectl apply -f nfs-service.yaml'
    
    NFS서버를 위한 디플로이먼트와 서비스를 생성했다면 다음은 해당 NFS 서버의 볼륨을 포드에서 마운트해 데이터를 영속적으로 저장하는 것이다. NFS 서버를
    컨테이너에 마운트하는 포드를 새롭게 생성해보자
```
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nfs-pod
spec:
  containers:
  - name: nfs-mount-container
    image: busybox
    args: ["tail", "-f", "/dev/null"]
    volumeMounts:
    - name: nfs-volume
      mountPath: /mnt #포드 컨테이너 내부의 /mnt 디렉터리에 마운트
  volumes:
  - name: nfs-volume
    nfs:              #NFS 서버의 볼륨을 포드의 컨테이너에 마운트 한다. 
      path: /
      server: (NFS_SERVICE_IP)
```
```dockerfile
    mountPath를 '/mnt'로 설정했기 떄문에 NFS 서버의 네트워크 볼륨은 포드 컨테이너의 '/mnt' 디렉터리에 마운트될 것이다. 즉, 컨테이너 내부에서 '/mnt'
    디렉터리에 파일을 저장하면 실제로는 NFS 서버에 데이터가 저장된다. 또한, volumes 항목에서 nfs라는 항목을 정의하면서 NFS 서버의 볼륨을 사용한다고
    명시했다. 
    위의 YAML 파일에서 유의해야할 점은 server 항목이 nfs-service라는 서비스의 DNS 이름이 아닌 [NFS_SERVICE_IP]로 성정돼 있다는 것이다. NFS
    볼륨의 마운트는 컨테이너 내부가 아닌 워크 노드에서 발생하므로 서비스의 DNS 이름으로 NFS 서버에 접근할 수 없다. 노드에서는 포드의 IP로 통신할 수 있지만,
    쿠버네티스의 DNS를 사용하도록 설정돼 있지는 않기 때문이다. 따라서 이번에는 예외적으로 NFS 서비스의 Cluster IP를 얻은 뒤 YAML에 적용하는 식으로 
    포드를 생성해 볼 것이다. 
    
            {
                #NFS 서버에 접근하기 위한 Cluster IP 얻기
                export NFS_CLUSTER_IP=$(kubectl get svc/nfs-service -o jsonpath={.spec.clusterIP})
                
                #nfs-pod의 server 항목을 NFS_CLUSTER_IP로 교체해 생성한다.
                cat nfs-pod.yaml | sed "s/{NFS_SERVICE_IP}/$NFS_CLUSTER_IP/g" | kubectl apply -f -
                
                
                > o jsonpath='{.sepc.clusterIP}' 옵션으로 json에서 해당 항목만 추출해서 출력한다. 
                
            }
    이후 확인해보면 NFS 서버로부터 저장공간을 마운트해 사용하고 있음을 알 수 있다.
            {
                NFS 서버에 마운트하려면 워커 노드에서 별도의 NFS 패키지를 설치해야할 수 있다. 만약 포드가 ContainerCreating 상태에서 더 이상
                진행이 되지 않는다면 kubectl describe pods 명령어로 무엇이 문제인지 파악하고 포드가 할당된 워커 노드에서 'apt-get install \
                nfs-common'을 입력해서 NFS 관련 패키지를 설치한다. 
            }
    NFS 서버가 '/mnt' 디렉토리에 마운트됐으므로 포드의 컨테이너 내부의 '/mnt' 디렉토리에 젖아된 파일은 포드가 다른 노드로 옮겨거가나 포드를 재시작해도
    삭제되지 않는다. 네트워크로 접근할 수 있는 볼륨인 NFS 서버에 파일이 영속적으로 저장되기 떄문이다. 
    
    실제 NFS를 운영 환경에서 도입하려면 백업 스토리지를 별도로 구축해서 NFS의 데이터의 손실에 대비하거나, NFS 서버의 설정 튜닝 및 NFS 서버에 접근하기 
    위한 DNS 이름을 준비해야할 수도 있다.
    
    
            > PV, PVC를 이용한 볼륨 관리 
            
            > 1. 퍼시스턴트 볼륨과 퍼시스턴트 볼륨 클레임을 사용하는 이유
    쿠버네티스에 지원하는 대부분의 볼륨 타입은 포드나 디플로이먼트의 YAML 파일에서 직접 정의해서 사용할 수 있다. 지금까지의 예시는 포드의 YAML 파일에
    볼륨 정보를 직접 입력했다. 예를 들어 NFS의 경우 YAML에 nfs라는 항목을 정의하고 NFS 서버의 엔드 포인트도 함께 정의했다.

    {
            volumeMounts:
             - name: nfs-volume
                mountPath: /mnt #포드 컨테이너 내부의 /mnt 디렉터리에 마운트
         volumes:
        - name: nfs-volume
            nfs:              #NFS 서버의 볼륨을 포드의 컨테이너에 마운트 한다. 
            path: /
            server: (NFS_SERVICE_IP)  #네트워크 볼륨의 엔드 포인트를 직접 입력
            
    }
    
    실제 환경에서 위와 같은 경우는 바람직하지 않을 수 있다. 예를들어 MySQL 디플로이먼트를 배포하기 위한 YAML을 작성한다고 했을 때, MySQL은 상태를 
    가지기에 영속성 스토리지를 마운트해서 데이터를 보관해야한다. 따라서 쿠버네티스에서 사용할 수 있는 여러 네트워크 볼륨 종류 중 NFS를 사용하기로 했고
    MySQL의 디플로이먼트를 정의하는 YAML파일에 nfs항목과 NFS 서버의 정보를 기술했다.
    
    문제는 MySQL 디플로이먼트의 YAML파일에 네트워크 볼륨으로 NFS를 고정적으로 명시했기 때문에 해당 YAML로 MySQL을 생성하려면 반드시 NFS가 된다.
    게다가 MySQL 파일을 보관하려 iSCSI, GlusterFS를 사용하려면 볼륨 타입을 명시하는 별도의 YAML을 따로 만들어야 한다. 즉, 볼륨이 애플리케이션 정의에
    밀접하게 의존하는 상황이 연출된다. 
    
    이러한 불편함을 해결하기 위해서 쿠버네티스는 퍼시스턴트 볼륨(Persistent Volume : PV)과 퍼시스턴트 볼륨 클레임(Persistent Volume Claim :PVC)
    이라는 오브젝트를 제공한다. 이 두 개의 오브젝트는 포드가 볼륨의 세부적인 사항을 몰라도 볼륨을 사용할 수 있도록 추상화 해주는 역할을 담당한다. 즉, 포드를
    생성하는 YAML 입장에서는 네트워크 볼륨이 NFS인지, AWS의 EBS인지 상관 없이 볼륨을 사용할 수 있도록 하는 것이 핵심 아이디어이다. 
    
    우선 쿠버네티스를 관리하는 인프라 관리자와 애플리케이션을 배포하려는 사용자(개발자)가 나뉘어 있다고 가정해보자 인프라 관리자는 NFS, Ceph와 같은 스토리지
    에 접근해 사용할 수 있으며, 이를 쿠버네티스로 가져오는 역할을 담당한다. 이때, 사용자(개발자)가 디플로이먼트의 포드에 볼륨을 마운트해 사용하려면 아래와
    같은 과정을 거친다. 
    
        1. 인프라 관리자는 네트워크 볼륨의 정보를 이용해 퍼시스턴트 볼륨 리소스를 미리 생성해둔다. 네트워크 볼륨의 정보에는 NFS나 iSCSI와 같은 스토리지
        서버에 마운트 하기 위한 엔드포인트가 포함될 수 있다.
        
        2. 사용자(개발자)는 포드를 정의하는 YAML 파일이 '이 포드는 영속적으로 저장해야하므로 마운트할 수 있는 외부 볼륨이 필요하다.'라는 의미의 퍼시스
        턴트 볼륨 클레임을 명시하고, 해당 퍼시스턴트 볼륨 클레임을 생성한다. 
        
        3. 쿠버네티스는 기존에 인프라 관리자가 생성해 뒀던 퍼시스턴트 볼륨의 속성과 사용자가 요청한 퍼시스턴트 볼륨 클레임의 요구 사항이 일치하면
        두 개의 리소스를 매칭시켜 바인드한다. 포드가 이 퍼시스턴트 볼륨 클레임을 사용함으로써 포드의 컨테이너 내부에 볼륨이 마운트된 상태로 생성된다. 
    
    위 과정에서 중요한 점은 '사용자는 디플로이먼트의 YAML 파일에 볼륨의 상세한 스펙을 정의하지 않아도 된다.'는 것이다. 사용자는 YAML에서 '이 디플로이\
    먼트는 볼륨을 마운트할 수 있어야 한다.'는 의미를 명시할 뿐이다. 실제로 마운트되는 볼륨이 무엇인지 알 필요가 없다. 따라서 디플로이먼트를 정의하는 
    YAML을 배포할 때에도 '이 디플로이먼트는 외부 볼륨을 필요로 한다.'는 사실만 포함해서 배포할 뿐, 그 볼륨이 무엇인지는 정의하지 않는다. 인프라 관리자가
    미리 준비해 둔 퍼시스턴트 볼륨을 사용하기만 하면 되기 떄문이다. 이러한 방식을 사용하면 애플리케이션을 배포하는 YAML 파일을 좀 더 보편적인 방식으로 
    작성할 수 있다.
    
    {
    
        volumes:                                    volumes:
          - name: nfs-volume                            - name: nfs-volume
             nfs:                           ->            persistentVolumeClaim:
             path: /                                        className: mtpvc
             server: (NFS_SERVICE_IP)
    }
    
    위는 퍼시스턴트 볼륨 사용 안할 떄, 사용할 때의 파일이다. 디플로이먼트를 생성하는 YAML 파일에 nfs 항목을 정의하는 대신, persistentVolumeClaim
    항목을 사용해 볼륨의 사용 여부만 나타냈다. 만약 인프라 관리자가 NFS, iSCSI, GlusterFS 등 볼륨의 종류에 상관없이 퍼시스턴트 볼륨을 생성해 뒀다면
    쿠버네티스는 이를 매칭시켜 마운트할 것이다. 
    
        {
            퍼시스턴트 볼륨 클레임을 통해 볼륨을 요청할 때, 볼륨의 크기, 1:N 또는 1:1 쓰기 가능 여부, 읽기 전용 등의 볼륨 요구 사항을 쿠버네티스에
            전달할 수도 있다. 이때 해당 조건에 만족하는 볼륨만을 매칭시켜 포드의 컨테이너에 마운트하게 된다. 
        }
        
   
   
            > 2. 퍼시스턴트 볼륨과 퍼시트턴트 볼륨 클레임 이용하기
    퍼시스턴트 볼륨은 persistentvolume, 퍼시스턴트 볼륨 클레임은 persistentvolumeclaim이라는 이름으로 사용할 수 잇다. 그렇지만 오브젝트의 이름이
    너무 길어 오브젝트 이름을 전부 타이핑하는 것은 귀찮기에 pv, pvc라는 이름으로 많이 사용한다. kubectl get pv, pvc 명령어로 리소스 목록을 출력해 
    보자
    
        'kubectl get persistentvolume, persistentvolumeclaim'
        'kubectl get pv, pvc'
        
    어떠한 퍼시스턴트 볼륨도 생성하지 않았다면 아무것도 출력되지 않는다. 이전에 테스트용 쿠버네티스 내부에 생성해 두었던 NFS 서버를 퍼시스턴트 볼륨으로 
    등록해도 상관언 없지만 이번에는 AWS 클래우드 플랫폼의 볼륨으로 사용해보자. AWS에서 kops로 쿠버네티스를 설치했다면 퍼시스턴트 볼륨은 EBS와 연동해서
    사용할 수 있다.
            {
                GKE라면 영구 디스크(Persistent Disk)라는 GCP 볼륨을 사용할 수 있다. 어떤 환경이든 쿠버네티스 사용하면 퍼시스턴트 볼륨 개념은 같지만
                볼륨 종류에 따라서 퍼시스턴트 볼륨 생성 방법이 다르다. 
            }
    
    
                > 2.1. AWS에서 EBS 퍼시스턴트 볼륨으로 사용하기  
    
    AWS에서 EBS를 쿠버네티스의 퍼시스턴트 볼륨으로 등록하려면 가장 먼제 EBS를 생성해야한다. AWS 웹사이트의 관리 콘솔에서 EBS를 생성해도 상관은 없지만,
    지금은 awscli 명령어를 이용해 EBS를 새롭게 보자. '--size' 옵션에는 볼륨의 크기를 기가바이트(GB) 단위로 입력한다. 
    
        'export VOLUME-ID=$(aws ec2 create-volume --size 5} \
        --region ap-northeast-2 \
        --availability-zone ap-northeast-2a \
        --volume-type gp2 \
        --tag-specifications \
        "ResourceType=volume, Tags=[{Key=kubernetesCluster, value=mycluster.k8s.local}]" \
        | jq ".VolumeId" -r)'    
            
    EBS의 볼륨 ID를 $VOLUME_ID라는 셸 변수에 저장해 뒀다. 이 ID를 통해 퍼시스턴트 볼륨을 생성할 것이다. 생성한 EBS 볼륨을 통해 쿠버네티스의 퍼시스턴
    트 볼륨을 생성해보자 
```
```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: ebs-pv
spec:
  capacity:
    storage: 5Gi          # 이 볼륨 크기는 5기가 바이트
  accessModes:
    - ReadWriteOnce       # 하나의 포드(또는 인스턴스)에 의해서만 마운트 될 수 있다.
  awsElasticBlockStore:
    fsType: ex4
    volumeId: <VOLUME_ID>
```
```dockerfile
    이전에 NFS 서버를 포드에 마운트하기 위해 nfs라는 항목을 YAML에 정의했던 것처럼 이번에는 AWS의 EBS를 마운트하기 위해 awsElasticBlockStore
    라는 항목을 정의했다. 볼륨 타입에 따라 하위 항목에 정의하는 옵션이 달라질 수 있으며, 이번에는 NFS와 달리 EBS의 volumeID를 입력해야한 다는 점에
    유의하면 된다.
    
        {
            위의 YAML 파일에서 storage:5Gi는 볼륨의 크기를, ReadWriteOnce는 해당 볼륨이 1:1로 마운트 가능함을 의미한다. 이러한 항목들은
            볼륨의 속성을 나타내며, 퍼시스턴트 볼륨 클레임의 요구 조건을 매칭할 떄 사용한다.
        }
        
    EBS를 생성할 때 셸 변수에 저장했던 VOLUME_ID 값을 통해 퍼시스턴트 볼륨을 생성해보자 volumeID에 <VOLUME_ID> 대신 EBS의 ID를 입력한 뒤
    'kubectl apply -f'를 입력하여 퍼시스트 볼륨을 생성해도 상관 없다. 
    
        'cat ebs-pv.yaml | sed "s/<VOLUME_ID>/$VOLUME_ID/g" | kubectl apply -f'
        
    퍼시스턴트 볼륨이 정상적으로 생성됐는지 확인하기 위해 볼륨의 목록을 출력한다. 퍼시스턴트 볼륨은 네임스페이스에 속하지 않은 클러스터 단위의 오브젝트이므로
    네임스페이스에 상관 없이 모든 퍼시스턴트 볼륨이 출력된다. 
    
    CAPACITY(볼륨 크기), ACESS MODES(읽기 쓰기 모드) 등 퍼시스턴트 볼륨에 대한 다양한 정보를 확인할 수 있다. 그렇지만 아직 퍼시스턴트 볼륨 클레임을
    생성하지는 않았기 때문에 STATUS 항목이 Avilable(사용 가능)인 것을 알 수 있다.
    
    다른 상황으로 배포시 퍼시스턴트 볼륨 클레임과 포드를 함께 생성해보자 아래의 YAML 파일은 my-ebs-pvc라는 퍼시스턴트 볼륨 클레임을 먼저 생성한 뒤,
    이를 포드의 volume항목에서 사용함으로써 포드 내부의 EBS 볼륨을 마운트한다.   
```
```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: my-ebs-pvc   #1. my-ebs-pvc라는 이름의 pvc를 생성한다.
spec: 
  storageClassName: ""
  accessModes:
    - ReadWriteOnce   #2.1 속성이 ReadWriteOnce인 퍼시스턴트 볼륨과 연결한다.
  resources:
    requests:
      storage: 5Gi    #2.2 볼륨 크기가 최소 5Gi인 퍼시스턴트 볼륨과 연결한다.

---

apiVersion: v1
kind: Pod
metadata:
  name: ebs-mount-container
spec:
  containers:
  - name: ebs-mount-container
    image: busybox
    args: ["tail", "-f", "/dev/null"]
    volumeMounts:
    - name: ebs-volume
      mountPath: /mnt
  volumes: 
  - name: ebs-volume
    persistentVolumeClaim:
      claimName: my-ebs-pvc   # my-ebs-pvc라는 이름의 pvc를 사용한다. 
```
```dockerfile
    퍼시스턴트 볼륨 클레임을 정의하는 YAML 파일을 accessModes와 resources 항목은 볼륨의 요구 사항으로, 해당 조건을 만족하는 퍼시스턴트 볼륨과
    연결돼야한다는 의미이다. 이 조건들은 이전에 생성해뒀던 EBS의 퍼시스턴트 볼륨과 일치하므로 문제 없이 바인드 된 뒤 포드에 마운트될 것이다.
        {
            퍼시스턴트 볼륨 클레임의 요구 사항과 일치하는 퍼시스턴트 볼륨이 존재하지 않으면 포드는 pending 상태로 남는다.
            예를 들어 3Gi 크기의 EBS 볼륨을 생성해 퍼시스턴트 볼륨으로 등록했다면 위의 퍼시스턴트 볼륨 클레임이 요구하는 볼륨 크기인 5Gi를 만족하지 
            않으므로 바인드되지 않을 것이다. 쿠버네티스는 계속해서 주기적으로 조건이 일치하는 퍼시스턴트 볼륨을 체크해 연결하려고 시도하기 때문에
            5Gi 이상의 퍼시스턴트 볼륨을 생성하면 자동으로 볼륨 클레임과 연결된다. 
        }
    'kubectl apply -f ebs-pod-pvc.yaml'
    퍼시스턴트 볼륨과 퍼시스턴트 볼륨 클레임의 상태가 bound로 설정됐다면 두 리소스가 성공적으로 연결된 것이다. 포드가 정상적으로 생성되어 Running 상태라면
    EBS 볼륨 또한 포드 내부에 정상적으로 마운트 됐다는 뜻이다. 포드 내부에는 5Gi 크기의 EBS 볼륨이 마운트되어 있다.
    
    'kubectl exec ebs-mount-container --df -h | grep /mnt'
    
        {
            퍼시스턴트 볼륨은 네임스페이스에 속하지 않는 클러스터 단위의 오브젝트이지만, 퍼시스턴트 볼륨 클레임은 네임스페이스에 속하는 오브젝트이다.
            따라서 이 예시서는 default 네임스페이스에서 포드와 퍼시스턴트 볼륨 클레임이 함께 생성됐다.  
        }
    
    1. 포드의 데이터를 영속적으로 저장하기 위해 AWS에서 EBS 볼륨을 생성했다. awscli 또는 AWS 웹 페이지에서 직접 생성한 뒤, 불륨의 ID를 기록해 뒀다.
    2. ebs-pv.yaml 파일을 이용해 1번에서 생성한 EBS 볼륨을 쿠버네티스에스 퍼시스턴트 볼륨으로 등록했다. 이때 ebs-pv.yaml 파일에는 awsElasticBlock
    Store 항목에 EBS의 볼륨 ID를 명시했다. 또한 볼륨의 읽기 및 쓰기 속성(accessModes), 볼륨의 크기를 별도로 설정했다.
    3. ebs-pod-pvc.yaml 파일에서 퍼시스턴트 볼륨 클레임을 먼저 정의해 생성했다. 퍼시스턴트 볼륨 클레임에는 원하는 볼륨의 조건을 나열했다. 
    볼륨 크기는 5Gi여야 하며, 읽기 및 쓰기 속성은 RWO여야 한다고 명시했다. 
    4. 2번에서 생성한 퍼시스턴트 볼륨의 속성이 3번에서 생성한 퍼시스턴트 볼륨 클레임의 요구 조건과 일치하기 떄문에 두 리소스가 연결된다. kubectl get
    pv, pvc의 출력 결과에서 리소스의 상태가 연결(Bound) 상태로 바뀐 것을 확인할 수 있었다. 
    5. ebs-pod-pvc.yaml 파일에 정의된 포드는 4번에서 생성한 퍼시스턴트 볼륨 클레임을 사용하도록 설정돼 있다(YAML 파일의 volumes 항목). 최종적으로
    EBS 볼륨이 컨테이너 내부에 마운트된다. 
    
    가장 처음에 사용했던 방식처럼 포드를 정의하는 YAML 파일에 nfs 항목을 직접 정의해 사용하는 것이 더욱 직관적이라는 생각이 들 수 있다. 퍼시스턴트 볼륨을 
    사용하려면 위처럼 훨씬 더 복잡한 단계를 거쳐야 하므로 퍼시스턴트 볼륨을 굳이 사용하고 싶지 않을 수도 있다. 
    그렇지만 이전에 설명했던 것처럼 애플리케이션 배포를 수행할 때 실제로 인프라에 프로비저닝되어 있는 볼륨 타입이 무엇이든 간에 상관없이 퍼시스턴트 볼륨
    클레임의 조건만 일치하면 볼륨을 마운트해 사용할 수 있다는 점을 이해해야 한다. 즉, 애플리케이션을 배포하는 입장에서는 볼륨의 세부 구현 및 스펙을 알 필요
    없이 볼륨 사용에 대한 추상화된 인터페이스를 제공받을 수 있는 것이다. 



            > 3. 퍼시스턴트 볼륨을 선택하기 위한 조건 명시
    퍼시스턴트 볼륨 클레임을 사용하면 실제로 볼륨이 어떠한 스펙을 가졌는지 알 필요가 없지만, 사용하려는 볼륨이 애플리케이션에 필요한 최소한의 조건을 맞출
    필요는 있을 것이다. 예를 들어 볼륨의 크기가 적어도 얼마나 돼야 하는지, 여러 개의 포드에 의해 마운트 될 수 있는지, 읽기 전용으로만 사용할 수 있는지 등이 
    그러한 조건에 해당할 수 있다. 즉 실제 볼륨의 구현 스펙까지는 아니더리도, 적어도 특정 조건을 만족하는 볼륨만을 사용할 수 있는지 등이 그러한 조건에 해당
    할 수 있다. 즉, 실제 볼륨의 구현 스펙까지는 아니더라도, 적어도 특정 조건을 만족하는 볼륨만을 사용해야 한다는 것을 퍼시스턴트 볼륨 클레임을 통해 
    쿠버네티스에 알려줄 필요가 있다. 
    
    지금까지 퍼시스턴트 볼륨을 사용하며 간단히 설명했던 AcessMode나 볼륨의 크기 등이 바로 이러한 조건에 해당한다. 퍼시스턴트 볼륨과 퍼시스턴트 볼륨 클레임의 
    accessMode 및 볼륨 크기 속성이 부합해야만 쿠버네티스는 두 리소스를 매칭해 바인드한다. 
    이전에 사용했던 NFS는 여러 개의 인스턴스에 의해 마운트가 가능하지만(1:N 마운트), AWS의 EBS는 하나의 인스턴스에 의해서만 마운트될 수 있다.(1:1 마운트)
    또한, NFS 서버의 저장 공간 크기는 일반적으로 호스트의 스토리지 크기와 동일하지만, AWS의 EBS는 생성 당시에 설정한 크기만큼만 데이터를 저장할 수 있다.
    이때 퍼시스턴트 볼륨 클레임의 설정에 '1:1 마운트가 가능해야하면 5Gi의 볼륨이 필요하다.'라고 명시하면 해당 조건을 만족하는 AWS의 EBS의 볼륨과 바인드
    될 것이다.
    
        > accessModes와 볼륨 크기, 스토리지 클래스, 라벨 셀렉터를 이용한 퍼시스턴트 
    accessModes는 퍼시스턴트 볼륨과 퍼시스턴트 볼륨 클레임을 생성할 때 설정할 수 있는 속성으로, 볼륨에 대해 읽기 및 쓰기 작업이 가능한지, 여러 개의 
    인스턴스에 의해 마운트 될 수 있는지 등을 의미한다. 사용 가능한 accessModes의 종류는 아래와 같다. 
```
| accessModes 이름 | kubectl get에서 출력되는 이름 |           속성 설명            |
|:--------------:|:---------------------:|:--------------------------:|
| ReadWriteOnce  |          RWO          | 1:1 마운트만 가능,<br/> 읽기 쓰기 가능 |
|  ReadOnlyMany  |          ROX          |   1:N 마운트 가능 <br/>읽기 전용    |
| ReadWriteMany  |          RWX          |  1:N 마운트 가능<br/>읽기 쓰기 가능   |
```dockerfile
    EBS 볼륨은 기본적으로 읽기, 쓰기가 모두 가능하며 1:1 관계의 마운트만 가능하기 때문에 ReadWriteOnce로 사용했다. 그렇지만 만약 1:N 마운트가 필요
    하다면 ReadWriteMany를 사용하는 것이 맞을 것이다. 
    
    자주사용되는 다른 조건으로는 볼륨 사이즈가 있다. 이전에 EBS를 마운트하기 위해 사용했던 퍼시스턴트 볼륨 클레임을 정의하는 YAML 파일에서 
    resource.request.storage 항목을 5Gi로 설정했다. 이 조건 역시 부합되어야 바인드 된다.
    
    단, accessModes나 볼륨 크기는 해당 볼륨의 메타데이터일 뿐, 볼륨이 정말로 그러한 속성을 가지도록 강제하지는 않는다. 예를 들어 AWS의 EBS를 통해
    퍼시스턴트 볼륨을 생성하더라도 accessModes를 ReadWriteMany로 설정하는, 바람직하지 않은 설정을 만들 수도 있다. 그뿐만 아니라 로컬 볼륨
    (Local, hostPath 등) 또한 퍼시스턴트 볼륨으로 사용할 수 있는데, 그러한 경우에는 YAML 파일의 capacity.storage 항목에 크기를 지정한다고 해서
    해당 크기의 새 디스크 파티션이 생성되는 것도 아니다. 따라서 이러한 설정들을 애플리케이션을 배포할 때 적절한 볼륨을 찾아주는 라벨과 같은 역할을 한다고
    생각하는 것이 좋다. 
    그 외에도 스토리지 클래스나 라벨 셀렉터를 사용해서 퍼시스턴트 볼륨의 선택을 좀 더 세분화 할 수 있다. 스토리지 클래스는 볼륨의 대표 속성 등을 나타내는 
    것으로, 퍼시스턴트 볼륨을 생성할 때 클래스를 설정하면 해당 클래스를 요청하는 퍼시스턴트 볼륨 클레임과 연결해 바인드 한다.
    
```
ebs-pv-storageclass.yaml
```yaml
    capacity:
      storage: 5Gi
    accessModes:
      - ReadWriteOnce
    storageClassName: my-ebs-volume
awsElasticBlockStore:
```
ebs-pod-pvc-custom-sc.yaml
```yaml
kind: PersistentVolumeClaim
metadata:
  name: my-ebs-pvc
spec:
  storageClassName: my-ebs-volume
accessModes:
```
```dockerfile
    위 두 개의 YAML에는 각각 storageClassNmae이라는 항목에 'my-ebs-volume'이라는 값을 입력했다. 이러한 경우 스토리지 클래스의 이름이 일치하는 
    퍼시스턴트 볼륨과 퍼시스턴트 볼륨 클레임이 서로 연결된다. 단, storageClassName을 별도로 YAML 파일에 명시하지 않으면 클래스가 설정되지 않았다는 뜻인
    ""(값이 없음)으로 설정되며, 똑같이 스토리지 클래스가 설정되지 않은 퍼시스턴트 볼륨 또는 퍼시스턴트 볼륨 클레임과 매칭된다.
    
    또는 라벨 셀렉터를 사용할 수도 있다. 이전에 서비스와 디플로이먼트를 서로 연결할 때 라벨 셀렉터를 사용했던 것처럼 퍼시스턴트 볼륨 클레임에 라벨 셀렉터인
    matchLabels 항목을 정의함으로 특정 퍼시스턴트 볼륨과 바인드하는 것도 가능하다. 
```
ebs-pv-label.yaml
```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
    name: ebs-pv-label
    labels:
      region: ap-northeast-2a
spec:
  capacity:
    storage: 5Gi
```
ebs-pod-pvc-label-selector.yaml
```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: my-ebs-pvc-selector
spec:
  selector:
    matchLabels:
      region: ap-northeast-2a
  accessModes:
    - ReadWriteOnce
```

```dockerfile
                > 4. 퍼시스턴트 볼륨과 라이프사이클과 Reclaim Policy
    퍼시스턴트 볼륨을 생성한 뒤, kubectl get pv 명령어로 목록을 확인해보면 STATUS라는 항목을 볼 수 있다. Bound(연결됨)으로 바뀐다. 퍼시스턴트 볼륨이
    이미 바인드 됐기 때문에 다른 퍼시스턴트 볼륨 클레임과 연결할 수 없는 상태이다.
    
    그럼 퍼시스턴트 볼륨과 연결된 퍼시스턴트 볼륨 클레임을 삭제하면 어떻게 될까? 직관적으로 보면 연결돼 있던 퍼시스턴트 볼륨 클레임이 없어졌으니 퍼시스턴트
    볼륨을 다시 사용할 수 있을 것 같다. 더 나아가 이전에 생성했던 포드, 퍼시스턴트 볼륨 클레임을 삭제해보자
        
        'kubectl delete -f ebs-pod-pvc.yaml'
    
    포드와 퍼시스턴트 볼륨 클레임을 삭제했더니 퍼시스턴트 볼륨의 상태가 Available이 아닌 Relased로 상태가 변경됐다. Released는 해당 퍼시스턴트
    볼륨의 사용이 끝났다는 것을 의미하며, Released 상태에 있는 퍼시스턴트 볼륨은 다시 사용할 수 없다. 그렇지만 실제 데이터는 볼륨 안에 있기 때문에
    퍼시스턴트 볼륨을 삭제한 뒤 다시 생성하면 Available인 볼륨을 볼 수 있다.
    
        'cat ebs-pv.yaml | sed "s/<VOLUME_ID>/$VOLUME_ID/g | kubectl apply -f -'
    
    하지만 퍼시스턴트 볼륨 클레임을 삭제했을 때, 퍼시스턴트 볼륨의 데이터를 어떻게 처리할 것인지 별도로 정의할 수도 있다. 퍼시스턴트 볼륨의 사용이 끝났을 때
    해당 볼륨을 어떻게 초기화할 것인지도 별도로 설정할 수 있다. 쿠버네티스에서는 이를 Reclaim Policy라고 부른다. 크게 Retain, Delete, Recycle
    방식이 있다. 
    
    보통 퍼시스턴트 볼륨의 용도는 데이터를 영구적으로 저장하기 위한 것이기 떄문에 퍼시스턴트 볼륨의 사용이 끝난 뒤에도 원격 스토리지에 저장된 데이터를 계속 
    보존하고 싶을 것이다. 쿠버네티스는 기본 값이 Retain이다. kubectl get pv 명령어에서 츌력되는 RECLAIM POLICY 항목의 Retain이라는 설정값이
    바로 이것을 의미한다. 퍼시스턴트 볼륨의 라이프 사이클은 Available -> Bound -> Released가 된다. 
    
    
            [Available 상태]  -- 1. pvc 생성 --> [Bound 상태] -- 2. pvc 삭제 --> [released 상태]
            pv를 생성한 직후                      pvc와 연결되었을 때         연결된 pvc가 삭제되었을때 (ReclaimPolicy가 retain 일 때)
            
    RECLAIM POLICY가 Retain으로 설정된 퍼시스턴트 볼륨은 연결된 퍼시스턴트 볼륨 클레임을 삭제한 뒤에 Released 상태로 전환되며, 스토리지에 저장된
    실제 데이터는 그대로 보존된다. 
    
            {
                퍼시스턴트 볼륨과 퍼시스턴트 볼륨 클레임이 정상적으로 연결돼 있으며, 볼륨이 포드의 컨테이너 내부에 마운트된 상황에서는 Storage Obejct
                in Use Protection이라는 기능이 적용된다. 예를 들어 퍼시스턴트 볼륨과 퍼시스턴트 볼륨 클레임이 연결된 상황에서는 퍼시스턴트 볼륨을
                삭제해도 실제로 삭제되지 않는다. 이와 마찬가지로 퍼시스턴트 볼륨 클레임을 사용하고 있는 포드가 있다면 퍼시스턴 볼륨 클레임을 삭제해도
                실제로는 삭제되지 않는다. 즉, 다른 오브젝트와 연결된 리소스는 그 연결성이 없어지기 전까지는 실제로 삭제되지 않도록 보호된다고 보면 된다.
            }  
    
    Retain과 반대의 역할을 하는 Reclaim Policy로는 Delete, Recycle이 있다. 만약 퍼시스턴트 볼륨 Reclaim Policy를 Delete롤 설정해 생성했다면
    퍼시스턴트 볼륨의 사용이 끝난 뒤에 자동으로 퍼시스턴트 볼륨이 삭제되며, 가능한 경우에 한해서 연결된 외부 스토리지도 함께 삭제된다. 
```
```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: ebs-pv-delete
spec:
  capacity:
    storage: 5Gi
  accessModes:
    - ReadWriteOnce
  awsElasticBlockStore:
    fsType: ex4
    volumeID: <VOLUME_ID>
  persistentVolumeReclaimPolicy: Delete
```
```dockerfile
    'cat ebs-pv-delete.yaml | sed "s/<VOLUME_ID>/$VOLUME_ID/g | kubectl apply -f -'
    
    Reclaim Policy가 Delete인 퍼시스턴트 볼륨을 내부 포드에 마운트한 뒤, 연결된 퍼시스턴트 볼륨을 삭제하면 어떻게 될까?
    
    'kubectl apply -f ebs-pod-pvc.yaml'  # 생성
    'kubectl get pods'                   # 포드가 정상적으로 실행됐다.
    'kubectl get pv,pvc'                 # pv, pvc가 정상적으로 바인드 됨
    'kubectl delete -f ebs-pod-pvc.yaml' # 연결된 PVC를 삭제함으로써 PV의 사용을 종료
    'kubectl get pv,pvc'                 # Reclaim Policy가 Delete로 설정된 PV도 같이 삭제된다. (No resources found.)
    
    Reclaim Policy가 Delete로 설정됐기 떄문에 퍼시스턴트 볼륨 클레임이 삭제됨과 동시에 퍼시스턴트 볼륨도 함께 삭제됐다. 그뿐만 아니라 외부에 연결돼
    있던 EBS 볼륨도 한꺼번에 삭제되기 때문에 볼륨에 저장돼 있던 파일들이 모두 유실된다는 점에 유의해야 한다. 
    그 외에는 퍼시스턴트 볼륨 클레임이 삭제됐을 때 퍼시스턴트 볼륨의 데이터를 모두 삭제한 뒤 Available 상태로 만들어주는 Recycle이라는 정책을 사용할 수
    도 있다. Delete와 마찬가지로 실제로 저장돼있던 데이터를 모두 삭제한다는 점은 같지만, 퍼시스턴트 볼륨이나 외부 스토리지 자체를 삭제하지는 않는다는 점이
    다르다. 그렇지만 Recycle 정책은 쿠버네티스에서 Deprecated라는 것을 알아둬야한다. 
    
            {
                Delete 정책이나 Recycle은 모든 스토리지 유형에 대해서 사용할 수 있는 것은 아니다. AWS의 EBS나 GCP의 영구 디스크에서는 동적으로
                스토리지를 프로비저닝해 사용하기 떄문에 Delete 정책을 사용할 수 있다. NFS와 같은 스토리지 타입에는 Delete를 적용할 수 없지만
                Recycle을 사용하는 것은 가능하다. 
            } 
    
    결과적으로 정리하면, 
            1. Reclaim Policy -> Retain  : 퍼시스턴트 볼륨이 Released로 변경
            2. Reclaim Policy -> Delete  : 퍼시스턴트 볼륨 삭제, EBS 등 외부 볼륨도 함께 삭제
            3. Reclaim Policy -> Recycle : 퍼시스턴트 볼륨이 Available로 변경, 볼륨의 데이터 모두 삭제
            
            
            
            
                    > 5. StorageClass와 Dynamic Provisioning
                        다이나믹 프로비저닝과 스토리지 클래스
    
    지금까지 퍼시스턴트 볼륨을 사용하려면 미리 외부 스토리지를 준비해야만 했다. 예를 들어 AWS의 EBS를 퍼시스턴트 볼륨으로 사용하려면 EBS를 미리 생성한 뒤,
    볼륨 ID를 YAML 파일에 직접 입력하는 방식을 사용했다. 하지만 매번 이렇게 볼륨을 매번 수동으로 삭제하고 스토리지에 대한 접근 정보를 YAML 파일에 적는
    것은 귀찮은 일이다. 
    
    이를 위해 쿠버네티스 다이나믹 프로비저닝(Dynamic Provisioning)이라는 기능을 제공한다. 다이나믹 프로비저닝은 퍼시스턴트 볼륨 클레임이 요구하는 조건과
    일치하는 퍼시스턴트 볼륨이 존재하지 않는다면 자동으로 퍼시스턴트 볼륨과 외부 스토리지를 함께 프로비저닝하는 기능이다. 따라서 다이나믹 프로비저닝을 사용하면
    EBS와 같은 외부 스토리지를 직접 미리 생성해 둘 필요가 없다. 퍼시스턴트 볼륨 클레임을 생성하면 외부 스토리지가 자동으로 생성되기 때문이다.
    
    앞서 특정 퍼시스턴트 볼륨을 선택하기 위해서 스토리지 클래스(Storage Class)를 사용했던 것과 같이 다이나믹 프로비저닝에서도 사용할 수 있다. 이는 다이
    나믹 프로비저닝이 스토리지 클래스의 정보를 참고해 외부 스토리지를 생성하기 때문이다. 
    
            1. Storage Class를 명시
            2. PVC에 해당 클래스를 명시, 외부 볼륨 스펙 명시
            3. pv로서 등록되고, pvc와 바인딩 됨
            4. 외부 스토리지가 생성
    
    단, 다이나믹 프로비저닝이 모든 쿠버네티스에서 범용적으로 사용할 수 있는 것은 아니며 다이나믹 프로비저닝이 지원되는 스토리지 프로비저너가 미리 활성화
    되어 있어야한다. AWS, GCP와 같은 클라우드 플랫폼에서 쿠버네티스를 사용하고 있다면 별도로 설정하지 않아도 자동으로 다이나믹 프로비저닝을 사용할 수 있다.
    
            {   
                    AWS에서 다이나믹 프로비저닝
                    
                    1. 스토리지 클래스 생성 (스토리지 클래스 또한 쿠버네티스 오브젝트이기 때문에 'kubectl get'으로 확인할 수 있다.)
```
storageclass-slow.yaml
```yaml
kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: slow
provisioner: kubernetes.io/aws-ebs
parameters:
  type: st1
  fsType: ex4
  zones: ap-northeast-2a #쿠버네티스 클러스터가 위치한 가용 영역
```
storageclass-fast.yaml
```yaml
kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: fast
provisioner: kubernetes.io/aws-ebs
parameter:
  type: gp2
  fsType: ext4
  zones: ap-northeast-2a
```
```
                * 위의 yaml에서 주목할 것은 provisioner, type이다. provisioner는 AWS의 쿠버네티스에서 사용할 수 있는 EBS 동적 프로비저너인
                kubernetes.io/aws-ebs로 설정했다. 
                
                * type은 EBS의 종류이며 st1, gp2, sc1, io1 등이 있다. 
                
                
                2. 생성 ('kubectl apply -f storageclass-slow.yaml','kubectl apply -f storageclass-fast.yaml')
                
                3. 퍼시스턴트 볼륨 클레임 생성으로 프로비저닝 발생시키기
```
```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata: 
  name: pvc-fast-sc
spec:
  storageClassName: fast
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
```
```dockerfile
                    'kubectl apply -f pvc-fast-sc.yaml'
                     {
                            퍼시스턴트 볼륨 클레임에 storageClassName 항목을 아예 정의하지 않았을 때, 쿠버네티스에 기본적으로 사용하도록 
                            설정된 스토리지 클래스가 있다면 해당 스토리지 클래스를 통해 다이나믹 프로비저닝이 수행된다. 따라서 다이나믹 프로비저닝을
                            아예 사용하지 않으려면 storageClassName:""와 같이 명시적으로 공백으로 설정하는 것이 좋다.
                     }
                     
                     원래대로라면 퍼시스트 볼륨이 없기에 퍼시스트 볼륨 클레임은 pending으로 있어야하지만 스토리지 클래스를 통해 다이나믹 프로비저닝을
                     사용하도록 설정했기에 동적으로 SSD 타입의 EBS가 생성되고 이로부터 퍼시스턴트 볼륨 또한 생성될 것이다.
                     
                     다이나믹 프로비저닝을 사용할 때 주의해야 할 점은 퍼시스턴트 볼륨의 Reclaim Policy가 자동으로 Delete로 설정된다는 것이다.
                     동적으로 생성되는 퍼시스턴트 볼륨의 Reclaim Policy는 스토리지 클래스에 설정된 reclaimPolicy를 상속 받는데, 스토리지 클래스
                     의 recliamPolicy가 Delete가 기본이다. 따라서 퍼시스턴트 볼륨 클레임을 삭제하면 EBS 볼륨 또한 함께 삭제된다. 다이나믹
                     프로비저닝을 사용할 때 Delete가 아닌 Retain을 사용하고 싶다면 스토리지 클래스를 정의 하는 YAML 파일에 
                     'reclaimPolicy:Retain'을 명시하거나 'kubectl edit ', 'kubectl patch'로 퍼시스턴트 볼륨의 속성(persistentVolumeReclaimPolicy)
                     를 직접 변경해도 된다. 
            } 
            
            
                    > 다이나믹 프로비저닝에서 특정 스토리지 클래스를 기본값으로 사용
    다이나믹 프로비저닝을 사용할 때, 기본적으로 사용할 스토리지 클래스를 별도로 설정할 수도 있다. 스토리지 클래스를 생성할 때 주석을 추가하면 해당 스토리지
    클래스를 기본적으로 사용한다. 
```
```yaml
metadata:
  name: generic
  annotations:
    storageclass.kubernetes.io/is-default-class: "true"...
```
```dockerfile
    'kubectl apply -f storageclass-default.yaml' 스토리지 클래스를 별도로 명시하지 않으면 자동으로 기본 스토리지 클래스를 통해 다이나믹 프로비
    저닝이 수행되지만, storageClsasName의 값을 ""(공백)으로 하면 다이나믹 프로비저닝이 발생하지 않는다. 
        
```