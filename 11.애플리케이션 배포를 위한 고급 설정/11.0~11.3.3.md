```dockerfile
                > 애플리케이션 배포를 위한 고급 설정 
            1. 포드의 자원 사용량 제한
    쿠버네티스와 같은 컨테이너 오케스트레이션 툴의 가장 큰 장점 중 하나는 여러 대의 서버를 묶어서 리소스 풀로 사용할 수 있다는 것이다. 클러스터의 CPU나
    메모리 등의 자원이 부족할 떄 필요한 용량만큼 서버를 동적으로 추가함으로써 수평적으로 확장할 수 있기 떄문이다. 하지만 서버를 수평적으로 늘리는 스케일 아웃
    (scale-out) 만큼 중요한 작업이 하나 이다. 바로 클러스터 내부에서 컴퓨팅 자원 활용률(Utilization)을 늘리는 것이다.
    
    자원 활용률은 서버 클러스터에서 자원을 얼마나 효율적으로 빠짐없이 사용하고 있는지를 의미한다. 예를 들어 쿠버네티스에서 실행 중인 컨테이너의 CPU, 메모리
    사용량이 현저히 낮거나 유휴 상태의 컨테이너에게 과잉 할당을 했다면 이를 자원 활용률이 낮다고 표현한다. 이러한 상황을 방지하기 위해서 각 컨테이너에
    적절한 자원 사용량을 제한해야하며, 남는 자원을 사용할 수 있는 전략을 세워야 한다. 
    
    쿠버네티스는 컴퓨팅 자원을 컨테이너에 할당하기 위한 여러 기능을 제공한다. 이번 장에서는 포드나 컨테이너에 CPU, 메모리 등의 자원을 할당하는 기본 방법을
    먼저 알아본 후, 쿠버네티스의 자원 활용률을 높이기 위한 오버커밋(Overcommit) 방법을 알아본다. 그 후 ResourceQuota, LimitRange라는 쿠버네티스 
    오브젝트를 알아본다.
    
            > 1.1 컨테이너와 포드의 자원 사용량 제한 : Limits
    쿠버네티스에서 자원을 할당하는 방법을 알아보기 전 도커 컨테이너의 자원 제한을 다시 상기시켜보자. 컨테이너의 자원 사용량을 제한하는 방법은 여러 가지가 있지만
    '--memory', '--cpu', '--cpu-shares', '--cpu-quota' 및 '--cpu-runtime' 등이 있다. '--memory' 옵션은 컨테이너가 사용 가능한 최대
    메모리 사용량을 제한하며, 그외의 옵션들의 CPU의 사용량을 제한한다. 이 중에서 '--cpu-shares'는 정량적인 CPU 할당량이 아닌 비율 값을 사용한다는
    점에서 특별한 옵션이었다. 
    
        'docker run -it --name memory_1gb --memory 1g ubuntu:16.04'
        'docker run -it --name cpu_1_alloc --cpus 1 ubuntu:16.04'
        'docker run -it --name cpu_shares_example --cpu-shares 1024 ubuntu:16.04'
    
    또는 다음관 같이 자원 제한 옵션을 설정하기 않고 도커 컨테이너를 생성하면 호스트의 모든 CPU, 메모리를 사용할 수 있었다.
    
        'docker run -it --name unlimited_blade unbuntu:16.04'
    
    쿠버네티스는 기본적으로 도커를 컨테이너 런타임으로 사용하기 때문에 포드를 생성할 때 docker와 동일한 원리로 CPu, 메모리 최대 사용량을 제한할 수 있다.
    그렇지만 지금까지 포드나 디플로이먼트 등을 생성할 때 자원 할당량을 명시적으로 제한했던 적이 없다는 것을 눈치챘을 것이다. 이처럼 자원 할당량을 설정하지 
    않으면 포드의 컨테이너가 노드의 물리 자원을 모두 사용할 수 있기 때문에 노드의 자원이 모두 고갈되는 상황이 발생할 수 있다. 
    
    이 예방할 수 있는 가장 간단한 방법은 포드 자체에 자원 사용량을 명시적으로 설정하는 것이다. 포드의 CPU, 메모리 사용량을 제한하기 위해 아래 내용으로 
    YAML을 작성해보자.
```
resource-limit-pod.yaml
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: resource-limit-pod
  labels:
    name: resource-limit-pod
spec:
  containers:
  - name: nginx
    image: nginx:latest
  resources:
    limits:
      memory: '256Mi'
      cpu: '1000m'
```
```dockerfile
    포드를 정의하는 스펙에 새롭게 spec.containers.resources.limits 항목을 정의했다. 메모리는 256를 입력했는데, 이 설정값은 도커 명령어에서
    'docker run --memory 256m'과 같다. 즉 이 포드의 컨테이너 최대 메모리 사용량은 256Mi으로 제한된다. 
    cpu에는 1개의 cpu를 뜻하는 1000m(밀리코어)라는 값을 입력했으며, 이는 도커 명령에서 'docker run --cpus 1'와 같다. 따라서 이 포드의 컨테이너는
    최대 1개 CPU 만큼의 사이클을 사용할 수 있다. 
    
        {
            이전에 포드에는 여러 개의 컨테이너가 존재할 수 있다. 따라서 하나의 포드에 여러 개의 컨테이너가 할당돼 있다면 각 컨테이너에 대해
            자원을 각각 할당할 수 있다. 
        }
        
    위 내용으로 YAML을 작성한 후 포드를 생성하면 'kubectl apply -f resource-limit-pod.yaml'
    
    'docker info' 명령어로 도커 호스트의 가용 자원을 확인할 수 있던 것처럼 쿠버네티스에서도 'kubectl describe node' 명령어로 워커 노드의 가용 자원을
    간단하게 확인할 수 있다. 이를 위해 방금 생성한 포드가 어느 노드에 생성돼 있는지 먼저 확인한 다음, 'kubectl describe' 명령어로 해당 노드의 자세한
    정보를 확인한다.
    
        'kubectl get pods -o wide'
        'kubectl descrbie node [NODE....]'
        
    'kubectl describe node' 명령어의 출력 내용 중에서 중간 부분에 위치한 Non-terminated Pods 항목에서는 해당 노드에서 실행 중인 포드들의 자원
    할당량을 확인할 수 있다. 방금 생성한 resource-limit-pod라는 이름의 포드 외에도 kube-system 네임스페이스의 포드가 미리 존재하고 있을 것이다.
    이 포드들은 쿠버네티스의 네트워크를 위한 핵심 컴포넌트로, 따로 설정하지 않아도 기본적으로 CPU와 메모리가 할당된다.
    
    'kubectl describe node' 명령어의 출력 내용 중에서 중간 부분에 위치한 Non-terminated Pods 항목에서는 해당 노드에서 실행 중인 포드들의 자원
    할당량을 확인할 수 있다. 방금 생성한 resource-limit-pod라는 이름의 포드 외에도 kube-system 네임스페이스의 포드가 미리 존재하고 있을 것이다.
    이 포드들은 쿠버네티스의 네트워크를 위한 핵심 컴포넌트로, 따로 설정하지 않아도 기본적으로 CPU와 메모리가 할당된다.
    
    그 아래 Allocated resources 항목에서는 해당 노드에서 실행 중인 포드들의 자원 할당량을 모두 더한 값이 출력된다. 즉, 방금 생성한 resource-limit-pod
    라는 이름의 포드 및 다른 시스템 컴포넌트의 자원 할당량의 합계를 확인할 수 있다. 
    
    
    
            > 1.2 컨테이너와 포드의 자원 사용량 제한하기 : Request
    limits는 해당 포드의 컨테이너가 최대로 사용할 수 있는 자원의 상한선을 의미한다. 방금 생성한 포드 또한 YAML 파일에서 Limits를 설정했고, 포드의 컨테이너는
    Limits보다 더 많은 자원을 사용할 수 없다는 것을 알 수 있다. 여기서 Request라는 단어가 등장했다. 
    
    쿠버네티스의 자원 관리에서 Request는 '적어도 이 만큼의 자원은 컨테이너에게 보장돼야 한다.(하한선)'는 의미이다. Limits의 개념과 유사해보이지만, Requests는
    쿠버네티스에서 자원의 Overcommit을 가능하게 하는 개념이다. 
    Request가 정확히 어떤 기능을 하는지 설명하기 전에 자원의 오버커밋이 무엇인지 알아야 한다. 오버커밋은 한정된 컴퓨팅 자원을 효율적으로 사용하기 위한 방법으로,
    사용할 수 있는 자원보다 더 많은 양을 가상 머신이나 컨테이너에게 할당함으로써 전체 자원의 사용률(Utilization)을 높이는 방법이다. 
    
    1GB의 전체 메모리에서 A -> 512MB, B -> 512MB를 정적으로 할당하는 것은 비효율이 생긴다. 만약 사용률이 낮은 컨테이너가 높은 컨테이너에게 빌려줄 수 
    있다면 좋을 것이다. 이처럼 정적인 할당은 유휴 자원을 제대로 활용하지 못한다. 이러한 문제를 해결하는 가장 좋은 방법은 사용량을 예측하여 적절히 결정 하는
    것이지만, 컨테이너가 실제로 얼마나 사용할지 예측하기란 여간 어려운 일이다. 
    
    이를 위해서 쿠버네티스에서는 오버커밋을 통해 물리 자원보다 더 많은 양의 자원을 할 당할 수 있다. 1GB 전체 메모리라도 750MB, 750MB인 포드 두 개를 
    생성할 수 있다고 보면 된다. 실제 메모리가 1GB이므로 실제로는 그렇게 되지 않지만 A가 사용률이 낮다면 B에 빌려주는 식으로 자원을 효율적으로 사용하게 할 수 
    있다. 이러한 자원 제한을 쿠버네티스에서는 Limits라고 한다. 위에서 작성한 resource-limit-pod의 resources가 이러한 설정이다.
    그렇지만 만약 A가 500MB를 사용할 때, B가 750MB를 사용하고자 하면 어떻게 될까? 이러한 상황을 방지하기 위해서 새로운 개념이 도입된다. 각 컨테이너가
    '사용을 보장받을 수 있는 경계선'을 정하는 것이다. A와 B 컨테이너에 하한선을 512MB로 잡았지만 Limits은 750MB로 같다. 두 컨테이너 모두 메모리 사용을
    보장받을 수 있는 경계선이 500MB이기 떄문에 500MB 이내에 메모리를 사용한다면 문제가 되지 않는다.
    
    그렇지만 컨테이너 A가 500MB를 사용하고 있을 때 컨테이너 B가 750MB를 사용하려면 B는 메모리 사용에 실패한다. 컨테이너 A는 메모리 사용을 보장받을 수 
    있는 경계선 내에 500MB를 사용하고 있는데, 컨테이너 B가 이를 침범하려 했기 때문이다. 이러한 경계선을 쿠버네티스에서 Request라고 한다. 즉, Request는
    컨테이너가 최소한으로 보장받아야 하는 자원의 양을 뜻한다. 
    
    포드에 설정될 Request 자원의 값은 Limit과 같이 YAML에서 지정할 수 있다.
```
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: resource-limit-with-request-pod
  labels:
    name: resource-limit-with-request-pod
spec:
  containers:
    - name: nginx
      image: nginx:latest
      resources:
        limits:
          memory: "256Mi"
          cpu: "1000m"
        requests:
          memory: "128Mi"
          cpu: "500m"
```
```dockerfile
    먼저 이 YAML 파일에 정의된 포드 컨테이너의 메모리 할당량을 보자 requests에서 128Mi를 limit을 256Mi로 설정했기에 '하한선 128mb 유휴 자원 존재 시
    256mb 까지 설정한다. '는 의미를 갖는다. CPU 또한 같은 원리로 해석하면 '하한선 0.5CPU ~ 상한선 1CPU' 이다.
    단, requests는 컨테이너가 보장받아야 하는 최소한의 자원을 뜻하기 때문에 노드의 총 자원의 크기보다 더 많은 양을 할당할 수는 없다. 따라서 쿠버네티스
    스케쥴러는 포드의 request만큼 여유가 있는 노드를 선택해 포드를 생성한다. 즉, 포드를 할당할 떄 사용되는 자원 할당 기준은 Limit이 아닌 Request이다.
    Requests의 값을 낮게 설정해서 포드를 생성하면 포드가 스케쥴링 되어 노드에 할당될 확률은 높아지겠지만, 포드가 사용을 보장받을 수 있는 자원의 양은 적어질 것이다.
    
        {
            노드에 할당된 포드의 Limits 값의 합은 노드의 물리 자원 크기를 초과할 수도 있다. 
        } 
        
            
            
            > 1.3 CPU 자원 사용량의 제한 원리
            쿠버네티스에서 CPU Requests와 Limits
    앞서 설명한 것처럼 쿠버네티스에서는 CPU를 m(밀리코어) 단위로 제한하며, 1개의 CPU는 1000m에 해당한다. 따라서 서버에 2개의 CPU가 존재한다면 최대
    2000m 만큼의 CPU Requests를 포드의 컨테이너에 할당할 수 있다.
    
    기본적인 CPU 자원의 단위를 이해했다면 이번에는 포드의 CPU Request와 Limit가 실제로 어떻게 동작하는지 알아보자. 이전에 사용했던 포드의 YAML 파일에는
    CPU의 Limits와 Requests가 각각 설정돼 있다. 
```
resource-limit-with-request-pod.yaml
```yaml
...
  resources:
    limits:
      memory: "256Mi"
      cpu: "1000m"      #최대 1개 CPU만큼 사용할 수 있다.
    requests:
      memory: "128Mi"
      cpu: "500m"       #최소한 0.5개의 CPU만큼 사용을 보장받을 수 있다.
```
```dockerfile
    CPU의 Limits를 의미하는 resources.limit.cpu를 1000m 설정하면 포드의 컨테이너는 최대 1개 만큼의 CPU를 사용할 수 있다. 즉, 이는 아래의 도커
    명령과 같다. 이는 컨테이너가 사용 가능한 CPU의 최대한도를 나타내기 때문에 어렵지 않게 이해할 수 있다. 
        {
            'docker run --cpus 1 ...'
            'docker run --cpu-period 100000 --cpu-runtime 100000....'
        }
    그렇다면 resources.requests.cpu를 설정해 CPU가 보장받아야하는 최소한의 CPU 자원을 설정하면 컨테이너에서 어떻게 설정될까? 결론부터 말하면 CPU의
    Requests는 docker run의 '--cpu-shares' 옵션과 같다. '--cpu-shares'는 서버에 CPU가 실제로 몇 개가 있는지에 상관없이 '--cpu-shares'의 할당
    비율에 따라 컨테이너가 사용할 수 있는 CPU 자원이 결정되는 옵션이다. '--cpu-shares'가 설정된 여러 개의 컨테이너가 동시에 존재한다면 각 컨테이너의
    '--cpu-shares' 비율에 따라 CPU를 사용할 수 있다. 예를 들어 3개의 컨테이너에서 '--cpu-shares'를 각각 1024, 1024, 512로 설정했다면 CPU의 
    사용률이 100%가 되는 포화 상태에서는 각 컨테이너가 2:2:1의 비율으로 CPU를 사용할 수 있을 것이다. 단, '--cpu-shares'을 얼마나 설정했는지와는 상관없이
    시스템에 CPU의 유휴 자원이 존재할 때는 CPU를 전부 사용할 수 있다. 
    
    도커 명령어를 공부할 떄는 '--cpu-shares' 옵션이 쓸모없어 보였을 수도 있지만, 이 옵션을 '--cpus(Limits)'와 함께하면 CPU 자원에 오버 커밋을 적용
    할 수 있다. 다시 쿠버네티스로 돌아와서 이번에는 '--cpu-shares(Requests)'와 '--cpus(Limits)'가 함께 설정된 컨테이너를 생각해보자
    
        {
            쿠버네티스는 CPU 단위를 밀리코어(m) 단위로 나타내기 때문에 Requests('--cpu-shares')의 값 또한 m으로 나타낸다. 이 값이 실제로 CPU
            Share의 값으로 변환되는 식은 아래와 같다.
                (Requests에 설정된 CPU 밀리 코어 값 * 1024) / 1000 = CPU Share의 값
                ex) (500m * 1024) / 1000 = 512 (실제로 컨테이너에 설정된 '--cpu-shares의 값')
        }
    
    컨테이너가 하나만 존재하는 상황이라면 Requests('--cpu-shares')와 상관없이 CPU의 Limits의 값(700m)만큼 사용할 수 있을 것이다. 그렇지만
    두 개의 컨테이너 Limit은 700m, requests는 500m이라면 어떨까?
    
    두 컨테이너의 Requests('--cpu-shares') 비율은 500m으로 같기 떄문에 CPU 자원 포화일 경우, 1:1 비율로 사용할 것이다. 따라서 Requests의 값인
    500m은 최종적으로 각 컨테이너에 보장돼야 하는 최소한의 CPU 자원을 나타낸다고 할 수 있다. 전체 CPU 자원인 1000m 만큼 Requests를 소진했기에
    새로운 Requests('--cpu-shares')를 가지는 컨테이너를 새롭게 할당하는 것은 불가능하다. 
    이번에는 Requests보다 더 많은 CPU자원을 사용하려 할 때, 자원의 경합(Contention)이 발생하는 상황을 가정해보자. 다른 컨테이너가 CPU를 사용하고 있지
    않아 유휴 CPU 자원이 발생한다면 다른 컨테이너는 Limits에 설정된 CPU 값만큼 사용할 수 있다.
    
    총 1000m 인 CPU에서 컨테이너 A가 Requests보다 더 많은 CPU를 사용하고 있는데(700), 컨테이너 B가 Requests 만큼 CPU를 사용하려고 하면(500) 
    컨테이너 A에는 CPU 쓰로틀(throttle)이 발생한다. 따라서 컨테이너 B는 Requests에 명시한 만큼의 CPU 비율을 사용할 수 있다. 
    
        {
            쿠버네티스에서는 CPU를 압축 가능한 (Compressible) 리소스라고 부른다. 이는 Requests보다 더 많은 CPU를 사용해서 CPU 경합이 발생하더라도
            컨테이너의 CPU 사용량을 쓰로틀을 사용해서 억제할 수 있기 때문이다. 이와 반대로 메모리나 스토리지는 압축 불가능한(Incompressible) 리소스
            라고 부르는데, 컨테이너 간에 메모리 사용의 경합이 발생하면 우선순위가 낮은 컨테이너의 프로세스가 먼저 종료되기 때문이다. 
        }
        
    아래와 같이 Requests에 할당되지 않은 여유 CPU 자원이 노드에 남아있는 경우도 생각해 볼 수 있다. 앞에서 서술한 바와 같이 Limits만큼 CPU를 사용할 수 
    있다면 컨테이너는 Limits까지 CPU를 사용할 수 있다. 하지만 두 컨테이너가 동시에 최대치를 사용하려 하면 Requests('--cpu-shares')의 비율에
    맞춰서 사용하도록 한다. 
    
        
        
                > 1.4 QoS 클래스와 메모리 자원 사용량 제한 관리
    지금까지 설명한 내용을 다시 보면 포드의 컨테이너는 최대 Limits만큼의 자원을 사용할 수 있지만, 최소한 Requests 만큼의 자원을 사용할 수 있도록 보장
    받는다. 이떄 Requests보다 더 많은 자원을 사용하는 것을 오버커밋이라고 부르며, Requests를 넘어서 자원을 사용하려 시도하다 다른 컨테이너와 자원이
    충돌하게 되면 CPU 스로틀과 같은 원리에 의해 자원 사용이 실패할 수 있다. CPU의 사용량에 경합이 발생하면 일시적으로 컨테이너 내부의 프로세스에 CPU
    쓰로틀이 걸릴 뿐, 컨테이너 자체에는 큰 문제가 발생하지 않는다.
    
    그렇지만 메모리의 사용량에 경합이 발생하면 문제가 심각해진다. 앞서 설명했던 것처럼 프로세스의 메로리는 이미 데이터가 메모리에 적재돼 있기 때문에 CPU와
    달리 메모리는 압축 불가능(Incompressible) 자원으로 취급된다. 따라서 하나의 노드에서 여러 개의 컨테이너가 Requests보다. 더 많은 자원을 사용하려고
    시도해도 이미 메모리에 적재된 데이터를 압축할 수는 없다. 이러한 상황에 쿠버네티스는 가용 메모리를 확보하기 위해서 우선순위가 낮은 포드 또는 프로세스를 
    강제로 종료하도록 설계되어 있다. 강제로 종료된 포드는 다른 노드로 옮겨가는데 이를 쿠버네티스에서는 퇴거(Eviction)이라고 한다. 
    
    그렇다면 여기서 가장 중요한 부분이 '노드에 메모리 자원이 부족해지면 어떤 포드나 프로세스가 먼저 종료돼야 하는가?'이다. 이를 위해 쿠버네티스는 포드의 
    컨테이너에 설정된 Limtis와 Requests 값에 따라 내부적으로 우선순위를 계산한다. 그 뿐만 아니라 쿠버네티스는 포드의 우선순위를 구분하기 위해서 QoS
    (Quality Of Service) 클래스를 명시적으로 포드에 설정한다.
    
            > 쿠버네티스에서의 메모리 부족과 OOM(Out Of Memory)
    쿠버네티스의 노드에는 각종 노드의 이상 상태 정보를 의미하는 Condtions라는 값이 존재합니다. 이 값은 kubectl describe nodes 명령어로도 확인할 
    수 있다. 이상 상태의 종류에서는 MemoryPressure, DiskPressure 등이 있다. 쿠버네티스의 에이전트인 kubeletdms 노드의 자원 상태를 주기적으로
    확인하면서 Conditions의 MemoryPressure, DiskPressure 등의 값을 갱신한다. 
    
    예를 들어, 평소에 메모리가 부족하지 않을 때는 MemoryPressure의 값이 False로 설정되어 있다가 노드의 가용 메모리가 부족해지만 MemoryPressure
    상태의 값이 True가 된다. MemoryPressure는 기본적으로 노드의 가용 메모리가 100Mi 이하일 때 발생하도록 설정돼 있다. MemoryPressure가 발생하면
    쿠버네티스는 해당 노드에 실행 중이던 모든 포드에 대해서 순위를 매긴 다음, 가장 우선순위가 낮은 포드를 다른 노드로 퇴거(Evict) 시킨다. 그 뿐만 아니라
    MemoryPressure의 값이 True인 노드에는 더 이상 포드를 할당하지 않는다. 이때 포드의 우선순위는 QoS 클래스 및 메모리 사용량에 따라 정렬된다. 
    
        {
            MemoryPressure와 같은 이상 상태를 감지하기 위한 임계치를 Hard Eviction Threshold라고 부르며, kubelet의 실행 옵션에서 설정 값을
            적절히 변경할 수도 있다. Hard Eviction Threshold의 다른 예시로 DiskPressure가 있으며, DiskPressure의 상태가 활성화(True)되면
            쿠버네티스는 사용 중이지 않은 도커 이미지를 자동으로 삭제하기도 한다.
        }
    
    만약 kubelet이 MemoryPressure 상태를 감시하기 전에 급작스럽게 메모리 사용량이 많아질 경우, 리눅스 시스템의 OOM(Out Of Memory) Killer라는
    기능이 우선순위가 낮은 컨테이너의 프로세스를 강제로 종료해서 가용 메모리를 확보할 수도 있다. OOM의 우선 순위 점수에는 oom_score_adj이고, 두 번째는
    oom_score이다. OOM Killer는 oom_score의 값에 따라서 종료할 프로세스를 산정한다. 
    
    OOM Killer는 리눅스에 기본적으로 내장된 기능이기 때문에 아무런 설정 없이 모든 프로세스에 자동으로 OOM 점수를 매긴다. OOM 점수가 높으면 높을수록
    강제 종료 가능성이 커지므로 절대로 종료되지 말아야 하는 핵심 프로세스는 일반적으로 매우 낮은 값을 부여 받는다. 
    
    예를 들어 쿠버네티스를 설치함으로써 실행되는 도커 데몬은 기본적으로  OOM 점수가 -999이다. 이 점수는 쿠버네티스 노드 중 하나에 접속하면 확인할 수 있다.
    이러한 프로세스는 메모리 부족이 생겨도 강제 종료 되는 일은 거의 없다. 
    
        'ps aux | grep dockerd'
        'ls /proc/[PID]' -> oom_adj, oom_score, oom_score_adj
        'cat /proc/[PID]/oom_score_adj' -> -999
        
    프로세스가 메모리를 얼마나 사용하고 있는지에 따라 프로세스의 최종 OOM 점수(oom_score)가 갱신되는데, OOM Killer는 이 점수를 기반으로 최종적으로
    종료할 프로세스를 결정한다. 
    
    
            > QoS 클래스의 종류 (1) Guaranteed 클래스 
    쿠버네티스에서는 포드의 Limits와 Requests 값에 따라서 'QoS 클래스'라는 것을 모든 포드에 대해서 설정한다. QoS 클래스에는 BestEffort, Burstable,
    Guaranteed 총 세 종류가 있다. QoS 클래스는 우리가 설정하지 않아도 자동으로 설정되므로 kubectl describe 명령어로 포드 정보를 조회하면
    QoS 클래스를 확인할 수 있다. 
    
        {
            'kubectl describe pod resource-limit-pod | grep QoS'
            QoS Class: Guaranteed
        }
    
    resource-limit-pod라느 이름의 포드는 Guaranteed라는 QoS 클래스로 설정됐다. Guaranteed 클래스는 포드의 컨테이너에 설정된 Limits와 Requests
    값이 완전히 동일할 떄 부여되는 클래스이다. 이전에 위의 resource-limit-pod 포드를 생성할 떄 사용했던 YAML 파일을 다시 살펴보자.
```
```yaml
...
containers:
  - name: nginx
    image: nginx:latest
    resources:
      limits:
        memory: '256Mi'
        cpu: '1000m'
```
```dockerfile
    이전에 생성할 때 limits만 명시했는데 Guaranteed 포드로 분류됐다 이는 Requests 없이 Limit만 정의하면 Requests가 Limits과 동일하게 설정되기
    때문이다. 혹은 아예 Requests, Limits을 동일하게 명시해도 Guaranteed로 생성된다. Guaranteed 클래스로 분류되는 포드는 Requests와 Limits
    값이 동일하기 때문에 할당받은 자원을 아무런 문제 없이 사용할 수 있다. 물론 Requests의 범위 내에서도 자유롭게 자원을 사용할 수 있으며, Requests의
    값이 Limits와 동일하기 때문에 Requests보다 더 많은 자원을 사용하지도 않는다. 즉, 자원의 오버커밋이 허용되지 않기 때문에 할당받은 자원의 사용을
    안정적으로 보장(Guaranteed) 받을 수 있다고 생각하면된다. 
    Guaranteed 클래스의 포드 내부에서 실행되는 프로세스들은 모두 기본  OOM 점수(oom_score_adj)가 -998로 설정된다. 도커 데몬이나 kubelet의 프로
    세스가 거의 동일한 레벨로 프로세스가 보호 받기에 노드에서 메모리가 고갈되어도 시스템 컴포넌트가 요구하지 않는 한 Guaranteed 클래스의 포드나 프로세스가
    강제로 종료되는 일은 없다. 
    
            > QoS 클래스의 종류 (2) BestEffort 클래스 
    BestEffort는 Requests와 Limits를 아예 설정하지 않는 포드에 설정되는 클래스이다. 즉, 포드의 스펙을 정의하는 YAML 파일에서 resources 항목을
    아예 사용하지 않으면 BestEffort 클래스로 분류된다. 
```
```dockerfile
apiVersion: v1
kind: Pod
metadata:
    name:nginx-besteffort-pod
spec:
    containers:
    - name: nginx-besteffort-pod
      image: nginx:latest
```
```dockerfile
    BestEffor 클래스의 포드는 Limits 값을 설정하지 않았기에 노드에 유휴 자원이 있다면 제한 없이 모든 자원을 사용할 수 있다 그러나 Requests 또한
    설정하지 않았기 때문에 BestEffort 클래스의 포드는 사용을 보장받을 수 있는 자원이 존재하지 않는다. 따라서 떄에 따라서는 노드에 존재하는 모든 자원을
    사용할 수도 있지만 자원을 전혀 사용하지 못할 수 도 있다.
    
            
            > QoS 클래스 (3) Burstable 클래스 
    Burstable 클래스는 Requests와 Limits가 설정돼 있지만, Limits의 값이 Requests보다 큰 포드를 의미하낟. 따라서 Burstable 클래스의 포드는
    Requests에 지정된 자원만큼 사용을 보장받을 수 있지만 상황에 따라서는 Limits까지 자원을 사용할 수 있다. Burstable이라는 이름이 의미하는 것처럼
    필요에 따라서 순간적으로 자원의 한계를 확장해 사용할 수 있는 포드라고 생각하면 된다.
    
    Guaranteed, BestEffor에 속하지 않는 포드는 모두 Burstable이라고 보면 된다. 아래와 같은 예시가 Burstable이다. 
```
```yaml
    ...
    resources:
      limits:
        memory: '256Mi'
        cpu: '1000m'
      requests:
        memory: '128Mi'
        cpu: '500m'
```
```dockerfile
    Burstable 클래스의 포드는 주어진 Requests 내에서 자원을 사용하면 문제가 없지만, Requests를 넘어 Limits 범위 내에서 자원을 사용하려 시도한다면
    다른 포드와 자원 경합이 발생할 수도 있다. 그러한 상황에서 Requests보다 더 많은 자원을 사용하고 있는 포드나 프로세스의 우선순위가 더 낮게 설정된다.
    
    
                > QoS 클래스와 메모리 부족
    일전에 서술한 바와 같이 kubelet이 메모리가 부족한 상황을 감지하면 우선순위가 가장 낮은 포드를 종료한 뒤 다른 노드로 내쫗는 퇴거(Evict)를 수행한다. 
    만약 메모리 사용량이 값작스럽게 높아지면 리눅스의 OOM Killer는 OOM 점수가 가장 낮은 컨테이너의 프로세스를 강제로 종료한 수도 있다. 포드가 다른 노드로
    퇴거(Evict)되면 단순히 다른 노드에서 포드가 다시 생성될 뿐이지만, OOM Killer에 의해서 종료되면 포드의 재시작 정책(restartPolicy)에 따라서 다시
    시작된다. 
    
            {
                OOM Killer는 메모리를 많이 사용하는 프로세스를 강제 종료하는 것이다. 컨테이너나 포드를 종료하는 것은 아니다. 따라서 컨테이너 내부의 
                init 프로세스가 아닌 다른 프로세스가 메모리를 많이 사용하고 있다면 해당 프로세스만 종료될 수 있다.
            }
    기본적으로 포드의 우선 순위는 Guaranteed가 가장 높으며, 그 뒤로 Burstable과 BestEffort 따라서 노드에 메모리가 부족하면 가장 먼저 BestEffort
    포드가 종료되고, 그 다음 Burstable이 종료되는 것이 일반적이다. Guaranteed 포드는 낮은 우선순위의 포드가 존재하지 않을 떄 마지막으로 종료된다.
    
    하지만 이러한 우선순위는 항상 절대적인 것은 아니다. 왜냐하면 Burstable과 BestEffort 클래스의 포드는 현재 메모리를 얼마나 사용하고 있는지에 따라서 
    우선 순위가 역전될 수도 있기 때문이다. 정확히 말하면 포드가 메모리를 많이 사용하면 사용할 수록 우선순위가 낮아진다. 예를 들어, Guaranteed 포드
    내부의 프로세스는 메모리 사용을 보장받아야 하기 때문에 우선순위가 가장 높지만, Burstable과 BestEffort 포드의 프로세스는 메모리를 많이 사용할수록
    우선순위가 낮아진다.
    
    - 자원 오버커밋의 필요성
    쿠버네티스에서 사용할 수 있는 자원 오버커밋의 원리는 때로는 복잡할 수 있다. 포드가 언제, 어떻게, 얼마나 자원을 사용하게 될지를 정확히 예측하기는 어려우며,
    오버커밋을 허용함으로 인해 예상치 못한 문제가 발생할 수도 있기 때문이다. 
    
    오버커밋이 쿠버네티스의 기능이라고 해서 반드시 사용해야만 하는 것은 아니다. 오히려 애플리케이션이 반드시 안정적인 상태로 동작해야한다면
    모든 포드의 Limits, Requests를 동일하게 설정함으로 Guaranteed 클래스를 생성하는 것도 해답이 된다. 
    
    
            > 1.5 ResourceQuota와 LimitRange
    여러 개발팀이 쿠버네티스에서 작업한다면 어떻게 환경을 구성하는 것이 좋을까? 개발팀마다 쿠버네티스를 구축하는 것이 좋지만 관리가 번거롭고 클러스터 프로비저닝
    을 위한 비용도 높아진다.
    이를 위해서 네임스페이스를 생성하여 각 개발팀이 해당 네임스페이스에서만 API를 사용할 수 있도록 롤, 롤바인딩으로 RBAC(Role-Base Access Control)
    을 구성하는 방법을 고려하는 것이 좋다. 그렇지만 한 쪽에서 자원을 독점한다면 다른 네임스페이스의 자원이 부족한 상황이 연출된다.  이를 위해서 네임스페이스
    당 자원 한도를 정하는 것이 좋다. 이를 위해 쿠버네티스에서는 ResourceQuota와 LimitRange라는 오브젝트를 이용해서 자원량을 관리할 수 있다.
    
    
            > 1.5.1 ResourceQuota로 자원 사용량 제한
    ResourceQuota는 특정 네임스페이스에서 사용할 수 있는 자원 사용량의 합을 제한할 수 있는 쿠버네티스 오브젝트이다. 
    
        1. 네임스페이스에서 할당할 수 있는 자원 (CPU, 메모리, 퍼시스턴트 볼륨 클레임 사이즈, 컨테이너 내부의 임시 스토리지)의 총량을 제한할 수 있다.
        2. 네임스페이스에서 생성할 수 있는 리소스(서비스, 디플러이먼트 등)을 제한할 수 있다.
        
    1번은 네임스페이스 별 자원 소모량을 제한하기 위해서이다. 2번 역시 쿠버네티스 클러스터의 자원 고갈을 막기 윔이다. 예시로 관리자가 실수로 쿠버네티스에서
    리소스를 무한정 생성한다고 하면 쿠버네티스 리소스의 개수에 제한이 없다면 메모리, 스토리지가 가득 찰 때까지 리소스를 생성할 것이고 결국 쿠버네티스가 정상적으로
    작동하지 못할 수 있다. ResourceQuota는 이러한 상황을 방지하기 위해서 네임스페이스에서 생성할 수 있는 서비스, 디플로이먼트 컨피그맵 등의 리소스 개수를
    제한하는 기능을 제공한다.
    
    ResourceQuota는 네임스페이스에 종속되는 오브젝트이므로 네임스페이스별로 ResourceQuota를 생성해야한다. 기본값은 어떠한 ResourceQuota도 생성되어
    있지 않다.
    
            'kubectl get quota |(resourcequota)' #quota라는 이름으로도 사용 가능
    
    ResourceQuota는 퍼시스턴트 볼륨 클레임이나 ephemeral-storage의 크기를 제한하기 위해서 사용할 수도 있으나, 이번 절에서는 default 네임스페이스의
    CPU, 메모리의 Request, Limits를 제한하는 것을 해볼 것이다.
```
resource-quota.yaml
```yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: resource-quota-example
  namespace: default
spec:
  hard:
  request.cpu: '1000m'
  request.memory: '500Mi'
  limits.cpu: "1500m"
  limit.memory: '1000Mi'
```
```dockerfile
    반드시 Requests, Limits을 함께 제한할 필요는 없으며 CPU, 메모리를 하나의 ResourceQuoata에서 제한할 필요도 없다.  위의 예시는 함께 제한한 예시
    이다. 
    위의 YAML 파일에서는 네임스페이스를 default로 지정했기에 default 네임스페이스에서 사용할 수 있는 총 자원의 할당량을 제한할 것이다. 단일 포드의 자원
    할당량을 제한하는 것이 아닌, 네임스페이스에서 사용할 수 있는 자원 할당량의 합에 대한 제한이라는 점에 유의하자. ResourceQuota를 생성한 뒤 리소스 정보를
    출력하면
    
            'kubectl apply -f resource-quota.yaml'
            'kubectl describe quota' 
            
    ResourceQuota의 정보에 현재 default 네임스페이스에 생성된 포드들의 자원 할당량 합이 출력된다. 새롭게 생성되는 포드가 한계치보다 더 많은 자원을
    사용하려고 하면 포드를 생성하는 API 요청은 실패한다. 예를 들어, 위 예시에서는 500m의 limits.cpu를 가지는 3개의 포드는 생성할 수 있지만(1500m), 
    그 뒤로는 limits.cpu를 가지는 포드를 더 이상 생성할 수 없다. 단, ResourceQuota를 생성하기 이전에 존재하고 있던 포드들이 이미 자원을 한계치보다
    많이 사용하고 있다고 해서 기존 포드가 종료되지는 않는다. 
    예시로 메모리를 과도하게 사용하는 포드를 생성해보자
        'kubectl run memory-over-pod --image=nginx --generator=run-pod/v --requests="cpu=200m,memory=300Mi" --limits="\
        cpu=200m,memory=3000Mi"'
    방금 생성한 ResourceQuota는 default 네임스페이스에서 최대 1000Mi와 메모리만 사용할 수 있도록 설정했지만, 위 명령어로 3000Mi의 메모리를 요구
    했기 때문에 생성에 실패했다. 그렇다면 디플로이먼트를 통해 생성하면 어떻게 될까?
```
```yaml
apiVersion: apps/v1
kind: Deployment
...
      resources:
        limits: 
          memory: '3000Mi'
          cpu: '1000m'
        requests:
          memory: '128Mi'
          cpu: '500m'
```
```dockerfile
    'kubectl apply -f deployment-over-memory.yaml'
    
    이상하게도 디플로이먼트는 정상적으로 생성된다. 하지만 포드 목록을 출력하면 'kubectl get pods | grep deployment-over-memory' 출력 결과가
    없다는 것을 확인할 수 있다. 여기서 짚고 넘어가야할 것은 '포드를 생성하는 주체는 디플로이먼트가 아닌 레플리카셋'이라는 것이다. 디플로이먼트는
    포드를 생성하기 위한 레플리카셋의 메타데이터를 선언적으로 가지고 있을 뿐, 디플로이먼트 리소스가 직접 포드를 생성하지 않는다. 따라서 포드 생성 거부에 대한
    에러가 레플리카셋에 남아있지 않을 것이다. 
    
        'kubectl get replicasets'
        'kubectl describe rs [레플리카셋 이름]' -> 에러 로그 출력
        
    레플리카셋은 지속적으로 라벨 셀렉터에 해당하는 포드를 생성하려 시도하기 때문에 ResourceQuota가 업데이트되거나 가용 자원이 발생하면 포드를 정상적으로
    생성할 것이다. 
    
    
    - ResourceQuota로 리소스 개수 제한하기 
    ResourceQuota는 자원의 사용뿐만 아니라 디플로이먼트, 포드, 시크릿 등의 리소스 개수를 제한할 수도 있다. ResourceQuota는 아래의 쿠버네티스 오브젝트
    개수를 제한할 수 있다.
    
        1. 디플로이먼트, 포드, 서비스, 시크릿, 컨피그맵, 퍼시스턴트 볼륨 클레임 개수
        2. NodePort 타입의 서비스 개수, LoadBalancer 타입의 서비스 개수
        3. QoS 클래스 중에서 BestEffort 클래스에 속하는 포드의 개수 
        
    포드나 서비스의 최대 개수를 제한하려면 YAML 파일에 count/pod와 같은 형식으로 정의한다. 이전에 사용하던 ResourceQuota YAML을 수정해보자.
```
quota-limit-pod-svc.yaml
```yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: resource-quota-example
  namespace: default
spec:
  hard:
    requests.cpu: "1000m"
    requests.memory: "500Mi"
    limits.cpu: '1500m'
    limits.memory: '1000Mi'
    count/pods: 3
    count/services: 5
```
```dockerfile
    위의 YAML 파일을 적용하려면 default 네임스페이스에서는 최대 포드 3개, 서비스 5개를 생성할 수 있다. 그 이상 리소스를 생성하려고 하면 API요청이 거절
    된다. 예를 들어, ResourceQuota에서 제한된 개수 이상으로 생성 시도하면 [exceeded quota: ~~]와 같이 에러메시지를 출력한다.
    제한 가능한 다른 쿠버네티스 오브젝트의 경우, :리소스 개수 -> count/<오브젝트 명>.<API 그룹 이름> 
    추가적으로 오브젝트가 어떤 API 그룹에 속하는지 'kubectl api-resources' 명령어로 확인할 수 있다.
        ex)hard:
            count/resourcequotas: 3
            count/secrets: 5
            count/configmaps: :5
            count/persistentvolumeclaims: 2
            count/services.nodeports: 3
            count/services.loadbalancers: 1
            count/deployments.apps: 0


    - ResourceQuota로 BestEffort 클래스의 포드 개수 제한하기 
    ResourceQuota를 사용하면 Request와 Limits가 모두 설정돼 있지 않아서 노드의 자원을 제한할 수 없는 포드, 즉 BestEffort 클래스의 포드 개수를 
    제한할 수도 있다. 
```
quota-limit-baseeffort.yaml
```yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: besteffort-quota
  namespace: default
spec:
  hard:
    count/pods: 1
  scopes:
    - BestEffort
```
```dockerfile
    이번에는 이전과 달리 scopes라는 항목을 새롭게 정의했다. scopes는 필수 항목은 아니지만, BestEffort 및 Terminationg, NotTerminateing,
    NotBestEffort와 같은 포드의 상태를 값으로 입력할 수 있다. 위 예시에서는 BestEffort 클래스의 포드 개수를 제한하기 위해서 scopes에 BestEffort
    를 설정했다.
    BestEffort 클래스의 포드는 아무런 자원 할당을 설정하지 않은 경우에 해당하기 때문에 hard 항목에서 limit.cpu나 limit.memory와 같은 자원 제한
    설정과 연결되어 사용하지 않는다. BestEffort 클래스의 포드 개수를 제한할 때는 위의 YAML처럼 포드 개수를 제한하는 항목 (count/pods)만 유효하게
    작동한다. 
        {
            scope에서 NotBestEffort는 BestEffort 클래스가 아닌 QoS클래스를 의미하며, Terminating은 포드의 종료 시간(activeDeadline)이 
            명시적으로 설정된 경우를 의미한다. 이는 보통 잡(Job)이라고 하는 쿠버네티스 오브젝트에서 사용되기 때문에 생성하는 대부분의 포드는 NotTermi
            nating에 속한다고 생각하면 된다. NotBestEffort, Terminating, NotTerminating을 scopes에 설정하는 경우에는 limit.cpu나 
            limit.memory와 같은 자원 제한 및 count/pods와 함꼐 연결해서 사용할 수 있다.
        }
    
    아무런 포드가 생성돼 있지 않다고 가정하고, 위의 ResourceQuota를 생성한 다음 BestEffort 클래스의 포드를 여러 개 생성해보자. 제한을 넘어 포드를 생
    성하려고 시도하면 이 또한 요청이 거절될 것이다.
    
        #생성된 포드, ResourceQuota 삭제
        'kubectl delete quota --all && kubectl delete pod --all && kubectl delete deploy --all'
        'kubectl apply -f quota-limit-besteffort.yaml'
        'kubectl run besteffort-1 --image=nginx --genenrator=run-pod/v1'
        'kubectl run besteffort-2 --image=nginx --gnenrator=run-pod/v1'
        
    하지만 이렇게 명시적으로 BestEffort 포드의 개수를 허용하지 않은 채로 ResourceQuota에서 메모리나 CPU를 제한한다면 BestEffort 포드의 생성은
    실패한다. CPU와 메모리를 제한하는 ResourceQuota만 생성해 둔 다음, 어떠한 자원도 할당하지 않은 BestEffort 클래스의 포드를 생성해보자.
    
        #생성된 포드, ResourceQuota 삭제
        'kubectl delete quota -all && kubectl delete pod -all'
        #이전에 사용했던 CPU, 메모리를 제한하는 ResourceQuota 재생성
        'kubectl apply -f resource-quota.yaml'
        
        'kubectl run besteffort-1 --image=nginx --generator=run-pod/v1'
         -> failed:quota: resource-quota example: must specify limits.cpu, limits.memory, requests.cpu, requests.memory
     ResourceQuota에 limits.cpu나 limits.memory 등을 이용해 네임스페이스에서 사용가능한 자원의 합을 설정했다면 포드를 생성할 때 반드시
     해당 항목을 함께 정의해야한다.그렇지 않으면 위와 같은 에러가 반환된다.
     
     이를 위해서 쿠버네티스에서는 포드의 자원 사용량을 기본적으로 제한할 수 있는 LimitRange라는 기능을 제공한다.
     
     
            > 1.5.2 LimitRange로 자원 사용량 제한
    LimitRange는 특정 네임스페이스에서 할당되는 자원의 범위 또는 기본값을 지정할 수 있는 쿠버네티스 오브젝트이다. LimitRange의 용도를 간단히 보면
    아래와 같다.
        1. 포드의 컨테이너에 CPU나 메모리 할당량이 설정돼 있지 않은 경우, 컨테이너에 자동으로 기본 Requests 또는 Limits 값을 설정할 수 있다.
        2. 포드 또는 컨테이너의 CPU, 메모리, 퍼시스턴트 볼륨 클레임 스토리지 크기의 최소/최대값을 지정할 수 있다.
    LimitRange도 ResourceQuota와 마찬가지로 네임스페이스별로 적용할 수 있는 기능이므로 네임스페이스에 종속되는 오브젝트이다. 기본적으로 어떠한 Limit
    Range도 생성돼 있지 않다. 
    
        'kubectl get limitranges'
        'kubectl get limits' #limits라는 이름으로도 사용 가능
    
    LimitRange를 아래의 YAML을 보면서 이해해보자
```
limitrange-example.yaml
```yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: mem-limit-range
spec:
  limits: 
  - default:          # 1. 자동으로 설정될 기본 Limits 값
      memory: 256Mi
      cpu: 200m
    defaultRequest:   # 2. 자동으로 설정될 기본 Requests 값
      memory: 128Mi
      cpu: 100m
    max:
      memory: 1Gi     # 3. 자원 할당량의 최댓값
      cpu: 1000m
    min:              # 4. 자원 할당량의 최솟값
      memory: 16Mi
      cpu: 50m
    type: Container   # 5. 각 컨테이너에 대해서 적용
```
```dockerfile
    1. default: 포드의 컨테이너에 Limits 값이 설정돼 있지 않다면 자동으로 이 값을 Limits로 설정한다.
    2. defaultRequest: 포드의 컨테이너에 Requests 값이 설정돼 있지 않다면 자동으로 이 값을 Requests로 설정한다.
    3. max: 포드의 컨테이너에 설정될 수 있는 Limits 값의 최대치를 의미한다. 만약 max에 설정된 값보다 더 많은 자원을 사용하려고 하면 포드의 생성은 실패한다.
    4. min: 포드의 컨테이너에 설정될 수 있는 Requests 값의 최소치를 의미한다. 만약 min에 설정된 값보다 자원을 더 적게 사용하려고 시도하면 포드의
    생성은 실패한다.
    5. 이러한 자원 할당에 대한 설정이 컨테이너 단위로 적용될 것임을 의미한다. 컨테이너 외에도 Pod, PersistentVolumeClaim을 입력할 수 있다. 
    
    이 YAML 파일로 LimitRange를 생성한 뒤 BestEffort 클래스의 포드를 생성해 보면 자동으로 Requests와 Limits 값이 설정되는 것을 확인할 수 있다.
        'kubectl apply -f limitrange-example.yaml'
        'kubectl run pod-limitrange-example --image-nginx --generator=run-pod/v1'
        'kubectl describe pod pod-limitrange-example'
    마찬가지로 min과 max의 범위를 벗어나는 포드의 컨테이너는 생성할 수 없다. 
        'kubectl run test --image=nginx --generator=run-pod/v1 --requests="cpu=10m, memory=16Mi" --limits="cpu=100m, memory=500Mi"'
        'kubectl run test --image=nginx --generator=run-pod/v1 --requests="cpu=50m, memory=16Mi" --limits="cpu=1001m, memory=500Mi"'
    LimitRagne에서 maxLimitRequestRatio 항목을 사용하면 포드의 컨테이너에서 오버커밋되는 자원에 대한 비율을 제한할 수도 있다. 예를 들어 아래와
    같이 생성했다고 가정해 보자.
```
limitrange-ratio.yaml
```yaml
apiVersion: v1
kind: LimitRange
metadata: 
  name: limitrange-ratio
spec:
  limits:
  - maxLimitRequestRatio:
      memory: 1.5
      cpu: 1
    type: Container
```
```dockerfile
    위 예시에서는 maxLimitRequestRatio.memory의 값을 1.5로 설정했으며, 이는 새롭게 생성되는 포드의 Limits, Requests의 비율은 1.5보다 반드시
    작아야만 한다는 의미한다.
    간단한 예시로 메모리의 Limits가 200Mi이고 Requests가 100Mi로 설정된 포드의 컨테이너를 생성하려고 시도한다고 생각해 보자. 이 포드의 LimiRequestRatio
    값 200Mi / 100Mi = 2이지만, LimitRange에는 Limits와 Request의 비율을 최대 1.5까지만 허용하고 있기 때문에 이 포드의 생성은 거절될 것이다.
    
        'kubectl apply -f limirage-ratio.yaml'
        'kubectl run test --image=nginx --generator=run-pod/v1 --requests="cpu=100m, memory=100Mi" \
        --limits="cpu=100m, memory=200Mi"'
        
    maxLimitRequestRatio는 오버커밋을 얼마나 허용할 수 있는지 제어할 수 있을 뿐만 아니라, 이 값을 1로 설정함으로써 반드시 Guaranteed 클래스의
    포드만을 생성하도록 강제하는 용도로 사용할 수도 있다. 
    
    만약 포드 단위로 자원 사용량의 범위를 제한하고 싶다면 아래의 YAML 파일처럼 정의해 사용할 수 있다. 이 때의 포드의 사용량은 포드에 존재하는 모든 컨테이너의
    자원의 합이 된다. 예를 들어, 아래의 LimitRange는 포드의 컨테이너들에 할당된 메모리의 합이 최소 200Mi이여야 하며, 최대 1Gi까지 허용된다는 것을
    의미한다. 
```
limitrange-example-pod.yaml
```yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: pod-limit-range
spec:
  limits:
  - max:
      memory: 1Gi
    min:
      memory: 200Mi
    type: Pod
```
```dockerfile
    ResourceQuota에서 네임스페이스의 Limits, Requests를 설정하면 기본적으로 BestEffort 클래스의 포드 생성이 거부되지만, LimitRange를 사용하면
    포드의 컨테이너에 일괄적으로 기본 자원 할당량을 설정할 수 있다는 점을 숙지하자.
    
    
    
                > 1.6 ResourceQuota, LimitRange의 원리 : Admission Controller
    이전에 service account를 설명할 때 어드미션 컨트롤러(Admission Controller)에 대해서 알아본 적이 있다. 사용자가 'kubectl' 등을 통해
    쿠버네티스의 API 서버에 요청을 보낼 때, 인증과 인가 외에도 어드미션 컨트롤러라는 단계가 존재했다.
    
    어드미션 컨트롤러에 대해 간단하게 설명하면 '사용자의 API 요청이 적절한지 검증하고, 필요에 따라 API 요청을 변형하는 단계'라고 할 수 있다. 만약 kubectl
    등으로부터 전송된 API가 부적절하다면 어드미션 컨트롤러 단계에서 해당 API 요청을 거절할 수도 있고, 필요하다면 API 요청에 포함된 파라미터를 변경할 수도 
    있다. 
    
    지금까지 여러분 어드미션 컨트롤러에 대해 직접적으로 신경 쓴 적은 없었지만, 이미 여러 가지 어드미션 컨트롤러를 사용하고 있었다. 대표적으로 앞서 사용해
    봤던 service account가 바로 어드미션 컨트롤러의 한 종류였다. 그뿐만 아니라. 방금 사용했던 ResourceQuota와 LimitRange 또한 어드미션 컨트롤러
    의 한 종류이다.
    
    이와 같은 동작 방식을 구현하기 위해서 쿠버네티스에는 총 두 단계의 어드미션 컨트롤러가 있다. API 요청을 검사하는 것을 검증(Validating) 단계라고 부르며,
    API 요청을 적절히 수정하는 것을 변형(Mutating) 단계라고 한다. 이 두 가지 단계가 있다는 사실에 유의하면서 포드를 생성하는 API 요청이 ResourceQuota
    와 LimitRange 어드미션 컨트롤러에 의해 어떻게 조작되는지 생각해보자. 
    
        1. 사용자가 kubectl apply -f pod.yaml와 같은 명령어로 API 서버에 요청을 전송했다.
        2. x509 인증서, service account 등을 통해 인증 단계를 거친다.
        3. 롤, 클러스터 롤 등을 통해 인가 단계를 거친다.
        4. 어드미션 컨트롤러인 ResourceQuota는 해당 포드의 자원 할당 요청이 적절지 검증(Validating)한다. 만약 해당 포드로 인해 ResourceQuota
        에 설정된 네임스페이스의 최대 자원 할당량을 초과한다면 해당 API 요청은 거절된다. 
        5. 해당 API 요청에 포함된 포드 데이터에 자원 할당이 설정되지 않은 경우, 어드미션 컨트롤러인 LimitRange는 포드 데이터에 CPU 및 메모리 할당의
        기본값을 추가함으로써 원래의 포드 생성 API의 데이터를 변형한다. 
        
    위 단계 중 4,5번이 어드미션 컨트롤러가 동작하는 단계이다. 위 예시에서는 ResourceQuota와 LimitRange를 통해 단적인 예시만 알아봤지만 실제로
    'kubectl' 명령어를 사용할 때 실제로 동작하는 어드미션 컨트롤러는 더 많을 수 있다. 
    
    이러한 기본적인 어드미션 컨트롤러는 대부분 기본적으로 활성화돼 있기 때문에 별도로 신경 쓸 필요는 없지만, 필요하다면 커스터마이징한 어드미션 컨트롤러를 
    직접 구현해 쿠버네티스에 등록하는 것 또한 가능하다. 예를 들어 Nginx 포드를 생성하는 API 요청이 제출됐지만, 개발자의 실수로 Nginx 컨테이너가 80번
    포트가 아닌 다른 포트를 사용하도록 YAML 파일에 정의돼 있다면 이를 자동으로 수정해주는 어드미션 컨트롤러를 직접 구현할 수 있다.
    
    그뿐만 아니라 포드의 어노테이션에 따라서 별도의 사이드카 컨테이너를 서비스 메쉬(Service Mesh) 솔류션인 Istio 또한 어드미션 컨트롤러를 통해 포드에
    프록시 사이드카 컨테이너를 주입하는 방법을 사용한다. 
    
   
            > 2. 쿠버네티스 스케쥴링
    클라우드에서 자원 제한 기능과 함께 고려해야할 중요한 기능은 스케쥴링이다. 여기서 말하는 스케쥴링이란 컨테이너나 가상 머신과 같은 인스턴스를 새롭게 생성할
    때, 그 인스턴스를 어느 서버에 생성할 것인지 결정하는 일을 의미한다.
    쿠버네티스와 같은 클라우드 시스템에서 스케쥴링이 중요한 이뉴는 상황에 따라서 매우 다양하다. 간단한 예로 특정 컨테이너가 빠른 파일 입출력을 위해서 SSD를
    사용해야 한다면 SSD를 가지고 있는 서버에 할당할 수도 있다. 또는 컨테이너를 모든 서버에 최대한 고르게 배포함으로써 서버에 장애가 발생해도 애플리케이션의
    무중단, 즉 고가용성(HA: High Availablity)을 확보해야 할 수도 있다. 이처럼 컨테이너를 생성하기 전에 특정 목적에 최대한 부합하는 워커 노드를 선택하는
    작업이 스케쥴링에 해당한다.
    
    쿠버네티스에서는 포드를 생성할 워커 노드를 선택할 수 있도록 다양한 스케쥴링 방법을 제공하고 있다. 위와 같이 간단한 예시를 위한 스케쥴링 전략 외에도, 
    조금 더 복잡한 스케쥴링 전략을 직접 선택해서 구현할 수도 있다. 이와 이어서 포드를 할당할 워커 노드를 결정하는 스케쥴링 과정을 알아보고 포드를 생성하기
    위한 YAML 파일에 사용할 수 있는 여러 스케쥴링 설정 값을 알아보자.
    
    
            > 2.1 포드가 실제로 노드에 생성되기까지의 과정
    포드를 스케쥴링할 수 있는 옵션들을 알아보기 전에, 먼저 쿠버네티스에서 스케쥴링이 어떻게 수행되는지 알아보자. 사용자가 kubectl이나 API 서버로 포드 생성
    요청을 전송하면 어떠한 일이 일어나는지 정리해보자.
    
        1. ServiceAccount, RoleBinding 등의 기능을 이용해 포드 생성을 요청한 사용자의 인증 및 인가 작업을 수행한다.
        2. ResourceQuota, LimitRange와 같은 어드미션 컨트롤러가 해당 포드의 요청을 적절히 변형(Mutating)하거나 검증(Validating)한다.
        3. 어드미션 컨트롤러의 검증을 통과해 최종적으로 포드 생성이 승인됐다면 쿠버네티스는 해당 포드를 워커 노드 중 한 곳에 생성한다.
    
    포드의 스케쥴링은 위 단계 중에서 3번에서 수행된다. 이전 단계들은 모두 성공적으로 통과했다고 가정하고, 3번을 더 자세히 보자. 
    쿠버네티스에는 여러 가지 핵심 컴포넌트들이 기본적으로 실행되고 있으며, 이 컴포넌트들은 kube-system 네임스페이스에서 실행되고 있다. kube-system 
    네임스페이스에는 kubectl로 상호 통신할 수 있는 API 서버(kube-apiserver) 컴포넌트 외에도 다양한 핵심 컴포넌트가 있다. 그중에서 스케쥴링에 관하여는
    컴포넌트 kube-scheduler와 etcd이다. kube-scheduler는 쿠버네티스 스케쥴러에 해당하며, etcd는 쿠버네티스 클러스터의 전반적인 상태 데이터를 저장하는
    일종의 DB 역할을 한다. 
    
    kube-scheduler와 etcd 또한 포드로써 실행되기 때문에 kubectl get pods 명령어로 쉽게 확인할 수 있다. 
        
            'kubectl get pods -n kube-system'
        
    etcd는 분산 코디네이터(Distributed Coordinator)라는 불리는 도구의 일종으로, 클라우드 플랫폼 등의 환경에서 여러 컴포넌트가 정상적으로  상호 작용
    할 수 있도록 데이터를 조정하는 역할을 담당한다. 쿠버네티스 또한 클러스터 운용에 필요한 정보를 분산 코디네이터인 etcd에 저장하는데, 현재 생성된 
    디플로이먼트나 포드의 목록과 정보, 클러스터 자체의 정보 등과 같은 대부분의 데이터가 etcd에 저장돼 있다.
    etcd에 저장된 데이터는 무조건 API 서버(kube-apiserver)를 통해서만 접근할 수 있다. 예를 들어, 우리들이 kubectl get pods와 같은 명령어를 
    실행하면 API 서버에 요청이 전달되고, API 서버는 etcd의 데이터를 읽어와 kubectl 사용자에게 반환한다고 생각하면 된다.
    
    etcd에 저장된 포드의 데이터에는 해당 포드가 어느 워커 노드에서 실행되는지를 나타내는 nodeName 항목이 존재한다. nodeName 항목은 다음과 같이 
    kubectl get 명령어로도 쉽게 확인할 수 있다. 
    
        'kubectl get pods mypod -o yaml | grep -F3 nodeName'
        
    인증, 인가, 어드미션 컨트롤러 등의 단계를 모두 거쳐 포드 생성 요청이 최종적으로 승인됐다면 API 서버는 etcd에 포드의 데이터를 저장한다. 하지만 API
    서버는 포드의 데이터 중에서 nodeName 항목을 설정하지 않은 상태로 etcd에 저장한다. 아직은 스케쥴링이 수행되지 않았기 때문에 포드가 실제로 생성되지
    않은, 단순히 데이터로만 저장된 상태이기 떄문이다.
    
    쿠버네티스 스케쥴러 컴포넌트에 해당하는 kube-scheduler는 API 서버의 Watch를 통해 nodeName이 비어 있는 포드 데이터가 저장됐다는 사실을 전달
    받는다. 즉, 사용자의 포드 생성 요청에 의해 포드의 데이터가 etcd에 저장되긴 했지만, 아직 특정 노드에 스케쥴링되지 않은 포드를 감지하는 것이다.
    스케쥴러(kube-scheduler)는 nodeNmae이 설정되지 않은 해당 포드를 스케쥴링 대상으로 판단하고, 포드를 할당할 적절한 노드를 선택한 다음 API 서버에게
    해당 노드와 포드를 바인딩할 것을 요청한다. 그리고 나면 포드의 nodeName 항목의 값에는 선택된 노드의 이름이 설정된다.  클러스터의 각 노드에서 실행 중인
    kubelet은 API 서버에 둔 Watch를 통해 포드의 데이터에서 nodeName이 설정됐다는 소식을 전달받는다. 그리고 나서야 해당 nodeName에 해당하는 노드의 
    kubelet이 컨테이너 런타임을 통해 포드를 생성합니다. 여기까지가 쿠버네티스의 포드가 최종적으로 생성되기까지의 과정이다. 
    
        
            > 2.2  포드가 생성될 노드를 선택하는 스케쥴링 과정
    위 과정에서 가장 중요한 과정은 '스케쥴러가 적절한 노드를 어떻게 선택하느냐'이다. 스케쥴러는 크게 노드 필터링, 노드 스코어링 단계를 거쳐 최종적으로 노드를
    선택한다. 
    
        - 노드 필터링 : 포드를 할당할 수 있는 노드와 그렇지 않은 노드를 분리해서 걸러내는(Filtering) 단계이다. 예를 들어 포드에 설정된 CPU나 메모리의
        Requests만큼의 가용 자원이 존재하지 앟는 노드는 노드 필터링 단계에서 제외될 것이다. 그 외에도 기본적으로 마스터 노드는 포드를 할당할 수 없는 노드로
        취급되며, 장애가 발생해 kubectl get nodes에서 STATUS가 Ready가 아닌 워커 노드 또한 제외된다. 노드 필터링 단계에서 선정된 노드의 목록은 노드
        스코어링 단계로 전달된다.
        
        - 노드 스코어링: 노드 스코어링 단계에서는 쿠버네티스의 소스 코드에 미리 정의된 알고리즘의 가중치에 따라서 노드의 점수를 계산한다. 예를 들어, 포드가
        사용하는 도커 이지미가 이미 노드에 존재할 때는 빠르게 포드를 생성할 수 있기 때문에 해당 노드의 점수가 증가한다.(Image Locality). 또는 노드의
        가용 자원이 많으면 많을 수록 점수가 높게 평가될 수도 있다 (Least Requested). 이러한 알고리즘들의 값을 합산함으로써 후보 노드들의 점수를 계산한
        다음, 가장 점수가 높은 노드를 최종적으로 선택한다.  
    
    노드 스코어링은 쿠버네티스에 내장된 로직에 의해 계산되기 때문에 우리가 직접 점수를 매기는 알고리즘을 수정하는 경우는 많지 않다. 대부분은 스케쥴링 조건을
    포드의 YAML로 설정하여 노드 필터링 단계에 적용할 수 있도록 구성하는 것이 일반적이다.
    
    
    
            > 2.3 NodeSelector와 Node Affinity, Pod Affinity
            nodeName과 nodeSelector를 사용한 스케쥴링 방법
    특정 워커 노드에 포드를 할당하는 가장 확실한 방법은 포드의 YAML 파일에 노드의 이름(nodeName)을 직접 명시하는 것이다. 'kubectl get nodes' 명령어
    에서 출력된 노드의 이름을 다음과 같이 nodeName 항목에 명시한 다음 포드를 생성하면 해당 노드에 포드가 할당된다.
        
            'kubectl get nodes'
```
```yaml
apiVersion: v1,
kind: Pod
metadata:
  name: nginx
spec:
  nodeName: [노드 이름]
  containers: 
  - name: nginx
    image: nginx:latest
```
```dockerfile
    포드를 생성한 다음, 해당 포드의 위치를 확인해 보면 nodeName에 설정한 노드에 할당됐음을 알 수 있다. 
    
        'kubectl apply -f nodename-nginx.yaml'
        
    하지만 이러한 방식의 포드 스케쥴링은 바람직하지 않다. 우선 노드의 이름을 고정으로 설정했기에 다른 환경에서 해당 YAML을 보편적으로 활용할 수 없다.
    또한 노드에 장애가 발생했을 때도 유연하게 대처할 수 없다. 
    
    nodeName 대신에 사용할 수 있는 여러 가지 다른 방법이 있지만, 그중에서 가장 쉽게 사용할 수 있는 방법은 노드의 라벨(Label)을 사용하는 것입니다. 라벨을
    이용하면 특정 라벨이 존재하는 노드에만 포드를 할당할 수 있다. 노드의 라벨은 쿠버네티스가 자동으로 설정해 놓은 것도 있지만, 필요에 따라 여러분이 직접 라벨
    을 추가할 수도 있다. 
    
    kubectl get nodes --show-labels 명령어를 실행해 보면 쿠버네티스가 기본적으로 설정했 놓은 노드의 라벨을 확인할 수 있다. 미리 설정된 라벨들은
    대부분 kubernetes.io/라는 접두어로 시작하는데, 이는 쿠버네티스에 의해 미리 예약돼 사용하는 것을 의미한다. 
    
        'kubectl get nodes --show-labels'
    
    지금까지 사용해 온 라벨과 동일하게 라벨은 <키=값> 형태로 설정된다. 기본적으로 설정되는 라벨에는 해당 노드의 OS(Linux), CPU 아키텍쳐(amd64),
    호스트 이름 등이 있다. 이 라벨을 사용해도 큰문제는 없지만, 이번에는 3개의 워커 노드 중에서 1개의 노드는 'mylabel/disk'='ssd' 라벨을, 2개의
    노드는 'mylabel/disk'='hdd' 라벨을 추가해보자.
    
    노드에 라벨을 추가하려면 kubectl label nodes < 노드 이름 > < 추가할 라벨 > 과 같이 명령어를 사용하면 된다. 
        'kubectl label nodes [node이름] mylabel/disk=ssd'
    나머지 두 개의 노드에 대해서도 라벨을 추가하되, mylabel/disk=hdd라는 라벨을 설정한다.
    
        {
            노드에 설정된 라벨을 삭제하려면 라벨 키의 이름에 -(대시)를 추가하면 된다. 예를 들어 mylabel/disk를 삭제하려면
            
            'kubectl label nodes [노드 이름] mylabel/disk-'
        }
    
    이때 mylabel/disk 키의 값이 hdd인 노드에 포드를 할당하려면 포드의 YAML 파일에 아래와 같이 nodeSelector를 정의한다.
```
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-nodeselector
spec:
  nodeSelector:
    mylabel/disk: hdd
  containers:
  - name: nginx
    image: nginx:latest
```
```dockerfile
    mylabel/disk: hdd라는 라벨을 갖는 노드가 2개 이상이라면 해당 노드 중 하나가 선택된다. 즉, nodeSeelctor는 해당 라벨이 존재하는 노드 중 하나를
    선택하기 때문에 적어도 노드의 이름에 종속적이지 않게 YAML 파일을 작성할 수 있다.
    단, 이러한 포드 스케쥴링 방법은 각 단일 포드에 대해 수행한다는 점을 헷깔리면 안된다. 예를 들어 내부적으로 포드를 생성하는 디플로이먼트나 레플리카셋을
    생각해보자. 여러 개의 포드를 생성하도록 설정된 디플로이먼트의 포드들은 한꺼번에 동일하게 스케쥴링되는 것이 아니라 각 포드가 하나씩 독립적으로 스케쥴링
    한다. 즉, 아래의 YAML과 같이 디플로이먼트에 라벨을 통해서 nodeSelector 항목을 정의했더라도 디플로이먼트의 모든 포드가 동일한 하나의 노드에 할당
    되는 것은 아니라는 것이다. 
```
deployment-nginx-node-selector.yaml
```yaml
...
  replicas: 3
  selector:
    matchLabels:
      app: deployment-nginx
  template:
    metadata:
      name: deployment-nginx
      labels:
        app: deployment-nginx
    spec:
      nodeSelector:
        mylabel/disk: hdd
```
```dockerfile
        > Node Affinity를 이용한 스케쥴링 방법
    nodeSelector도 나쁘지 않은 방법이지만, 단순히 라벨의 키-값이 같은지만 비교해서 노드를 선택하기 떄문에 활용 방법이 다양하지 않다. 이를 보완하기 위해
    쿠버네티스는 Node Affinity라는 스케쥴링 방법을 제공한다. Node Affinity는 nodeSelector에서 조금 더 확장된 라벨 선택 기능을 제공하며,
    반드시 충족해야하는 조건(Hard)과 선호하는 조건(Soft)을 별도로 정의할 수도 있다.  Node Affinity에는 2가지 종류의 옵션이 있다.
    
        - requiredDuringSchedulingIgnoredDuringExecution
        - preferredDuringSchedulingIgnoredDuringExecution
        
    위 두 옵션은 다른 기능을 수행한다. 먼저 requiredDuringSchedulingIgnoredDuringExecution를 사용하며 예시를 보자
```
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-nodeaffinity-required
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: mylabel/disk
            operator: In
            values:             # values의 값 중 하나만 만족해도 된다.
              - ssd
              - hdd 
  containers:
  - name: nginx
    image: nginx:latest
```
```dockerfile
    굉장히 양이 많아 보이지만, '- matchExpression'과 하위 항목들을 보면 된다. 위 YAML 파일에서 "operator: In" 항목은 key의 라벨이 values의
    값 중 하나를 만족하는 노드에 포드를 스케쥴링한다는 것이다. 따라서 노드에 설정된 라벨이 mylabel/disk=ssd 또는 mylabel/disk=hdd라면 해당
    노드에 포드가 할당될 것이다. 
    
    이처럼 Node Avfinity는 여러 개의 키-값을 정의한 뒤 operator를 통해 별도의 연산자를 사용할 수 있다. 이때 operator에는 In 외에도 NotIn,
    Exsits, DoesNotExist, Gt(grater than), Lt(less than)을 사용할 수 있어서 nodeSelector보다 더욱 다양하게 활용할 수 있다.
    
    단, 위의 YAML 파일에서는 requiredDuringSchedulingIgnoredDuringExecution 옵션을 사용했다는 것을 유의해야한다. required...라는 이름에서
    볼 수 있듯이 '반드시 만족해야만 하는 제약 조건'을 정의할 때 쓰인다. 따라서 nodeSelector의 기능을 확장했다고 생각하면 쉽다.
    
    하지만 preferredDuringSchedulingIgnoredDuringExecution 옵션은 preferred라는 이름이 나타내는 것처럼 '선호하는 제약 조건'을 의미한다.
    따라서 preferredDuringSchedulingIgnoredDuringExecution 아래에 정의한 키-값 조건은 반드시 만족할 필요는 없으며, 만약 해당 조건을 만족하는
    노드가 있으면 그 노드를 조금 더 선호하겠다는 의미가 된다. 
```
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-nodeaffinity-preferred
spec:
  affinity:
    nodeAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 80      #가중치 (1~100)
        preference:
          matchExpressions:
          - key: mylabel/disk
            operator: In
            values:
            - ssd
  containers:
  - name: nginx
    image: nginx:latest
```
```dockerfile
    이번에는 required.. 대신 preferred를 사용했다. weight라는 값이 눈에 보이는데, 이 값은 조건에 해당하는 노드를 얼마나 선호할지를 나타내는 가중치
    이다. 즉, 때에 따라서는 matchExpressions의 조건을 만족하는 노드를 반드시 선택하지 않을 수도 있지만, 가급적이면 해당 노드를 선택하도록 가중치를 부여
    한다고 보면 된다. 이 가중치는 할당 가능한 모든 노드를 필터링한 뒤 수행하는 노드 스코어링 단계에서 적용된다.
    
    위의 YAML을 생성하면  mylabel/disk=ssd 라벨을 갖고 있지 않은 노드에도 포드가 할당될 수 있지만, mylabel/disk=ssd 라벨을 설정한 노드에 할당될
    확률이 높아지기 때문에 일반적으로 이를 soft 제약조건이라고 한다. 
    
        'kubectl apply -f nodeaffinity-preferred.yaml'
        'kubectl get pods -o wide'
    단, 이러한 스케쥴링 조건은 포드를 할당할 당시에만 유효하다. 따라서 일단 포드가 할당 뒤에 노드의 라벨이 변경되더라도 다른 노드로 포드가 옮겨가는 퇴거(Eviction)
    이 발생하지는 않는다. requiredDuringSchedulingIgnoredDuringExecution라는 이름에서 이 동작의 원리를 알 수 있다. '스케쥴링 과정에서는
    유효하지만(required during scheduling), 일단 시작한 다음에는 무시된다.(ignored during execution)'
    
        {
            반대되는 옵션으로  requiredDuringSchedulingRequiredExecution처럼 접미어를 바꾸어 사용할 수도 있다. 이 경우 스케쥴링에 영향을 주는 노드
            라벨이 포드가 실행된 뒤에 변경됐다면 포드가 다른 노드로 옮겨 간다. 
        }
```



````dockerfile
        > Pod Affinity를 이용한 스케쥴링 방법
    Node Affinity가 특정 조건을 만족하는 노드를 선택하는 방법이라면, Pod Affinity는 특정 조건을 만족하는 포드와 함께 실행되도록 스케쥴링한다. 
    사용 방법은 Node Affinity와 거의 같기 때문에 이전에 사용했던 requiredDuringSchedulingIgnoredDuringExecution과 같은 옵션을 똑같이 사용할
    수 있다. 
````
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-podaffinity
spec: 
  affinity:
    podAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: mylabel/database
            operator: In
            values:
            - mysql
        topologyKey: failure-domain, beta, kubernetes.io/zone
  containers:
  - name: nginx
    image: nginx:latest
```
```dockerfile
    대부분의 항목은 Node Affinity를 사용했을 때와 같지만, nodeAffinity 대신 podAffinity 항목을 사용했다는 점이 다르다. 이번에는 또한 topologyKey
    라는 새로운 항목을 정의했다. 
    
    위의 YAML 파일은 "mylabel/database=mysql"이라는 라벨을 가지는 포드와 함께 위치하도록 스키쥴링하라는 뜻이다. 이는 requiredDuringScheduling
    IgnoredDuringExecution 항목을 통해 이전과 비슷한 의미로 (required..) 사용되고 있지만, 이 라벨을 가지는 포드와 무조건 같은 노드에 할당하라는
    뜻이 아니다. topologyKey는 해당 라벨을 가지는 토폴로지 범위의 노드를 선택한다는 것을 의미한다. 예를 들어 쿠버네티스 노드들이 topologyKey에 할당된
    라벨의 키-값에 따라 여러 개의 그룹(topology)로 분류된다고 생각해보자 이때 matchExpression의 라벨 조건을 만족하는 포드가 위치한 그룹의 노드 중
    하나에 포드를 할당한다. 따라서 조건을 만족하는 포드와 동일한 노드에 할당될 수도 있지만, 해당 노드와 동일한 그룹(topology)에 속하는 다른 노드에 포드가
    할당될 수도 있다. 
    이러한 Pod Affinity 스케쥴링 전략은 다양한 용도로 활용할 수 있지만, 대표적인 활용 예로는 응답 시간을 최대한 줄여야 하는 두 개의 포드를 동일한 가용
    영역(AZ: Available Zone) 또는 리전(Region)의 노드에 할당하는 경우를 생각해 볼 수 있다.
```
```yaml
... 
  - matchExpressions:
    - key: mylabel/database
      operator: In
      values:
      - mysql
    topologyKey: kubernetes.io/hostname
``` 
```dockerfile
        {
            kubernetes.io/hostname 라벨은 쿠버네티스를 설치하면 기본적으로 모든 노드에 설정되는 라벨이다. 이 라벨의 값은 각 노드의 호스트 이름으로
            설정된다. 
        }
        
    기본적으로 모든 노드 호스트 이름은 고유하기 때문에 하나의 토폴로지에 두 개 이상의 노드가 존재할 수 없다. 이는 곧 하나의 노드가 하나의 토폴로지에 대응된
    다는 것을 의미한다. 따라서 위의 YAML을 적용하면 스케쥴러는 반드시 matchExpression을 만족하는 포드가 위치한 노드를 선택할 것이다. 
    
    
    
        > Pod Anti-affinity를 이용한 스케쥴링 방법
    Pod Anti-affinity는 Pod Affinity와 반대로 동작한다. Pod Affinity가 특정 포드와 동일한 토폴로지에 존재하는 노드를 선택한다면, Pod Anity-
    affinity는 특정 포드가 같은 토폴로지의 노드를 선택하지 않는 방법이다. 이 원리를 잘 이용하면 고가용성을 보장하기 위해 포드를 여러 가용 역역 또는
    리전에 멀리 퍼뜨리는 전략을 세울 수도 있다.
    
    Pod Anti-affinity를 사용하는 방법은 간단한다. 이전의 YAML파일에서 podAffinity를 podAnityAffinity로 바꾸기만 하면 된다.
```
pod-antiaffinity-required.yaml
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-pod-antiaffinity
spec: 
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: mylabel/database
            operator: In
            values:
            - mysql
        topologyKey: failure-domain, beta, kubernetes.io/zone
  containers:
  - name: nginx
    image: nginx:latest
```
```dockerfile
    podAntiAffinity를 사용하면 matchExpressions 조건을 만족하는 포드가 위치한 노드와 다른 토폴로지의 노드에 포드가 할당된다. 예를 들어 mylabel/data
    base=mysql 라벨이 설정된 포드가 kubernetes.io/zone=api-northeast-2a 라벨을 갖는 노드에서 실행 중이라면 ap-northeast-2a 라벨이 없는
    다른 토폴로지 또는 노드에 포드가 스케쥴링 된다. 
    
        {
            Pod Affinity와 Anti-Affinity는 Node Affinity와 동일하게 soft 제한을 사용할 수 있다. requiredDuringSchedulingIgnored
            DuringExecution을 사용하면 토폴로지마다 반드시 하나의 포드만 할당하게 되지만, preferredDuringSchedulingIgnoredDuringExecution
            을 사용하면 각 토폴로지의 노드에 포드를 여러 개 할당할 수 있다. 
        }
        
    이러한 원리를 활용하면 모든 노드에 포드를 하나씩 할당하는, 마치 데몬셋(DaemonSet)과 비슷한 디플로이먼트를 생성할 수도 있다. 디플로이먼트를 생성할 때,
    포드 템플릿에서 Pod Anti-affinity를 위한 toploogyKey를 kubernetes.io/hostname으로 설정하면 어떻게 될까?
```
```yaml
apiVersion: apps/v1
kind: Deployment
......

    metadata:
      name: deployment-nginx
      labels:
        app: deployment-nginx
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
                - key: app
                  operator: In
                  values:
                  - deployemnt-nginx
            topologyKey: "kubernetes.io/hostname"
        containers:
        - name: deployment-nginx
          image: nginx:latest
```
```dockerfile
    앞서 알아본 바와 같이 모든 노드의 호스트 이름은 고유하기 때문에 하나의 노드는 하나의 토폴로지로 간주된다. 위 예시에서는 디플로이먼트의 각 포드에 설정된
    라벨을 podAntiAffinity의 matchExpression 조건에 다시 사용함으로써 디플로이먼트의 각 포드가 서로 다른 호스트 이름을 가지는 노드에 할당되도록 구성
    했다. 따라서 하나의 노드에 두 개의 포드가 스케쥴링 되는 일이 벌어지지 않을 것이다. 
    
    
    
            > Taints와 Tolerations 사용하기
            > Taints와 Tolerations를 이용한 포드 스케쥴링 
    쿠버네티스에서는 라벨 외에도 Taints라는 방법을 이용해서 포드를 할당할 노드를 선택할 수 있다. Taints라는 이름의 의미와 같이 특정 노드에 얼룩(Taints)
    를 지정함으로써 해당 노드에 포드가 할당되는 것을 막는 기능이라고 생각하면 쉽다. 하지만 해당 Taints에 대응하는 Tolerations를 포드에 설정하면
    Taints가 설정된 노드에도 포드를 할당할 수 있다. 말하자면 얼룩(Taints)가 생겼지만 용인(Tolerations)할 수 있는 포드만 해당 노드에 할당할 수 
    있다는 것이다. 
    Taints의 종류는 다양하다. 직접 우리가 Taints를 노드에 별도로 설정할 수도 있고, 특정 이벤트로 인해 쿠버네티스가 자동으로 노드에 Taints를 설정하기도
    한다. 이러한 Taints는 kubectl로 지정하거나 해제할 수 있다. Taints는 라벨과 유사하게 키=값으로 사용한다. 
    
        ##예시 : 'kubectl taint nodes nodename key=value:effect'
        'kubectl taint node ip-10-43.... alicek106/my-taint=dirty:NoScedule'
    
        ## 노드의 Taint를 삭제할 때는 라벨과 마찬가지로 -(대시)를 뒤에 붙이면 된다.
        'kubectl taint nodes nodename key:effect-'
        
    하지만 라벨과는 한 가지 다른 점이 있다. key=value 뒤에 effect(taint 효과)를 추가로 명시한다. Taint 효과는 taint가 노드에 설정됐을 때 어떤
    효과를 낼 것인지를 결정한다. Taints 효과에는 NoSchedule(포드 스케쥴링 하지 않음), NoExecute(포드 실행 자체를 허용하지 않음),
     PreferNoSchedule(가능하면 스케쥴링 하지 않음) 총 3가지가 있다.
     
     위 예시에서는 alicek106/my-taint=dirty라는 Taint 키-값으로 NoSchedule을 설정했기에 일반적인 포드는 해당 노드에 스케쥴링되지 않는다. 
     앞서 설명했던 것처럼 Taint가 설정된 노드에 포드를 할당하려면 해당 Taint를 용인할 수 있도록 Toleration을 YAML 파일에 별도로 정의해야한다. 
     예를 들어, alicek106/my-taint=dirty:NoSchedule이라는 Taint가 설정된 노드에도 포드를 할당하려면 아래와 같이 작성하면 된다.
```
toleration-test.yaml
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-toleration-test
spec:
  tolerations:
  - key: alicek106/my-taint
    value: dirty
    operator: Equal
    effect: NoSchedule
  containers:
  - name: nginx
    image: nginx:latest
```
```dockerfile
        {
            위의 YAML 파일은 alicek106/my-taint=dirty:NoSchedule이라는 Taint를 용인할 수 있을 뿐, 해당 Taint가 설정된 노드에 반드시 포드를 
            할당한다는 의미는 아니다. 테스트를 위해서 Taint가 설정된 노드에 포드를 할당하려면 nodeSelector 등을 함께 사용하면 된다. 
        }
    
    이처럼 우리가 직접 Taint를 노드에 설정해도 되지만, 쿠버네티스는 기본적으로 다양한 Taint를 노드에 설정한다. 대표적인 예로 마스터 노드에 기본적으로
    설정된 Taint를 들 수 있다. 지금까지 포드를 생성하면 기본적으로 마스터가 아닌 워커 노드에 할당됐는데, 이는 쿠버네티스가 기본적으로 마스터 노드에
    Taint를 설정함으로써 포드가 할당되는 것을 방지하기 때문이다. 'kubectl describe node' 명령어로 마스터 노드의 정보를 자세히 출력해보면 이를
    확인할 수 있다.
    
        'kubectl describe nodes [nodename]' #마스터 노드 조회
        
    마스터 노드에는 node-role.kubernetes.io/master:NoSchedule이라는 이름의 Taints가 자동으로 설정돼 있다. 또한, UnSchedulable의 값이
    false로 설정돼 있는데, 이는 스케쥴링의 대상이 되는 노드라는 것을 의미한다. 따라서 마스터 노드 또한 워커 노드와 마찬가지로 포드가 할당될 수 있는
    노드이지만, Taints가 설정돼 있기 때문에 일반적인 포드들은 지금까지 할당되지 않았던 것이다.
    
        {
            마스터 노드에 설정된 Taint는 키-값의 형태가 아니라는 사실을 알 수 있다. Taint는 기본적으로 키-값의 형태를 가지지만, 값을 생략해 사용할
            수도 있다. 값이 생략된 경우는 ""(빈 문자열)의 값을 가지는 것으로 간주한다.
        }
    
    마스터 노드에 설정된 Taint 또한 Toleration으로 용인할 수 있다. 따라서 마스터 노드를 스케쥴링 대상으로 간주하려면 아래와 같이 포드의 YAML 파일에
    마스터 노드의 Toleration을 정의하면 된다. 단, 마스터 노드에는 일반적으로 API 서버와 같은 핵심 컴포넌트만 실행하는 것이 바람직하는 사실을 유념해야한다.
```
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-master-toleration
spec:
  tolerations:
  - key: node-role.kubernetes.io/master
    effect: NoSchedule
    operator: Equal
    value: ""
  nodeSelector:
    node-role.kubernetes.io/master: "" #마스터 노드에서도 포드가 생성되도록 지정
  containers:
  - name: nginx
    image: nginx:latest
```
```dockerfile
    그렇다면 마스터 노드에서 실행 중인 포드에는 어떤 Toleration이 설정돼 있을까? API 서버가 실행 중인 포드의 정보를 조회해보자.
        
            'kubectl get pods -n kube-system | grep api'
            'kubectl describe pod kube-apiserver-ip ..... -n kube-system'
            
            .....
                QoS Class:      Burstable
                Node-Selectors: <none>
                Tolerations:    :NoExecute
                Events:         <none>
            .....
    
    API 서버 포드에는 :NoExecute라는 Toleration이 설정돼 있다. 이 Toleration은 Taint의 키와 값이 무엇이든지 상관없이 모든 :NoExecute 종류의
    Taint를 용인할 수 있음을 의미한다. API 서버 포드의 정보를 YAML 포맷으로 출력해보면 YAML 파일에서 실제로 어떻게 설정돼 있는지 알 수 있다.
    
            'kubectl get pod kube-apiserver-ip-10..... -n kube-system -o yaml | grep -F2 toleration'
        
    Toleration에서 operator의 값은 Equal 외에도 Exists를 사용할 수 있다. 위처럼 Toleration의 operator 항목이 Exists로 설정된 경우에는 
    Taint에 대한 와일드 카드로서 동작한다. 즉, key, value  및 effect 항목을 명시하지 않았다면 해당 항목의 값에 상관없이 모두 용인할 수 있다. 위 
    경우에는 key와 value를 명시하지 않았기 때문에 모든 NoExecute 종류의 Taint에 대해 적용된다. operator의 값이 Exists로 설정된 경우에는 다양한
    방법으로 Toleration을 정의할 수 있다. 다음은 operator:Exists를 사용하는 예시이다.  
```
| ...<br/>tolerations:<br/> - operator: Exists | ...<br/>tolerations: <br/>- key: my-key<br/>operator:Exists | ...<br/>tolerations: <br/>- key: my-key<br/>operator: NoExecute<br/>operator: "Exists" |
|---------------------------------------------:|------------------------------------------------------------:|---------------------------------------------------------------------------------------:|
|                             모든 종류의 Taint를 용인 |                      키의 이름이 my-key인 모든 Taint에 대해 값에 상관없이 용인 |                             키의 이름이 my-key이고, Taint 효과가 NoExecute인 Taint에 대해 값에 상관없이 용인 |

```dockerfile
        > NoExecute와 tolerationSeconds
    Taint의 효과는 NoSchedule 외에도 PreferNoSchedule과 NoExecute가 있다. 이 중에서 NoExecute는 포드를 해당 노드에 스케쥴링하지 않을 뿐만
    아니라 해당 노드에서 아예 포드를 실행할 수 없도록 설정한다. NoSchedule과 NoExecute의 차이점이 모호하게 느껴질 수도 있는데, NoSchedule은 노드에
    설정하더라도 기존에 실행 중이던 포드는 정상적으로 동작하는 반면 NoExecute는 해당 노드에서 실행 중인 포드를 종료시킨다. 물론 포드에 NoExecute에 대한
    Toleration이 설정돼 있다면 해당 포드는 종료되지 않는다. 
    
        'kubectl taint node [node name] alicek106/you-taint=your-taint-value:NoExecute'
        # 노드에 NoExecute 효과를 갖는 Taint를 설정하는 예시이다.
        
    단, 포드가 디플로이먼트나 레플리카셋 등과 같은 리소스로부터 생성됐다면 NoExecute에 의해 포드가 종료됐더라도 포드는 다른 노드로 옮겨가는, 이른바 포드의
    퇴거(Eviction)가 발생한다. NoExecute에 의해 포드가 종료되면 레플리카셋은 라벨 셀렉터가 일치하는 포드의 개수가 replicas에 지정된 값보다 적다는 것을
    감지할 것이고, 다른 노드에 새롭게 포드를 생성할 것이기 때문이다.
    
    또한 포드를 생성하 쿠버네티스는 자동으로 NoExecute에 대한 Toleration을 추가한다. 지금까지 생성했던 포드 중에서 아무 포드나 골라서 상세 정보를 출력하면
    Toleration 항목을 확인할 수 있다.
    
        'kubectl describe pod < 포드 명 > '
   
    node.kubernetes.io/not-ready와 unreachable이라는 Taint에 대해 Toleration이 설정돼 있다. 이는 노드가 준비되어 있지 않았거나 네트워크 통신이
    불가능 상황일 때를 위한 Toleration이다. 
    쿠버네티스는 특정 문제가 발생한 노드에 대해서는 자동으로 Taint를 추가한다. 대표적인 예로 아직 노드가 준비되지 않은 상태(NotReady), 네트워크 불안정 상태
    (Unreachable), 또는 메모리 부족(memory-pressure)이나 디스크 공간 부족(disk-pressure)에 대한 Taint 등이 있다. 특히나 NotReady 또는
    Unreachable은 노드 자체에 장애가 생긴 경우일 수 있기 때문에 쿠버네티스는 노드 아래에 Taint를 추가한다.
    
        - node.kubernetes.io/not-ready:NoExecute
        - node.kubernetes.io/unreachable:NoExecute
        
    예를 들어, kubectl get nodes에서 STATUS가 NotReady로 표시되는 경우에도 노드에 자동으로 Taint가 추가된다. 
        'kubectl get nodes'
    모든 포드에 자동으로 추가된 node.kubernetes.io/not-ready:NoExecute for 300s와 같은 Toleration은 바로 이러한 상황을 위한 것이다. 이 
    Toleration은 노드에 장애가 발생해 not-ready나 unreadable 상태의 Taint가 발생하더라도 300초 동안은 해당 Taint를 용인하겠다는 뜻이다. 300초 
    이내에 노드가 정상 상태로 돌아와 Taint가 삭제되지 않으면 포드는 다른 노드로 옮겨가게 된다. 즉, 노드에 장애가 생겨도 해당 노드에서 실행 중이던 포드가
    즉시 다른 노드로 옮겨가는 것은 아니며, 기본적으로 300초 후에 옮겨가게 된다. 
    
    이러한 옵션을 tolerationSeconds라고 부르며, 포드가 실행 중인 노드에 Taint가 추가됐을 때 해당 Taint를 용인할 수 있는 최대 시간을 의미한다.
    tolerationSeconds에 설정된 시간보다 더 많은 시간이 흘렀다면 해당 포드 또한 다른 노드로 옮겨갈 것이다. tolerationSeconds는 아래와 같은
    형식으로 사용할 수 있다. 
    
        'kubectl get pod <포드 이름> -o yaml | grep -F4 tolerationSeconds'
        
        {
            node.kubernetes.io/not-ready:NoExecute 및 node.kubernetes.io/unreachable:NoExecute에 대한 Toleration은
            DefaultTolerationSeconds라는 이름의 어드미션 컨트롤러(Admission Controller)에 의해서 포드에 추가된다.
            필요하다면 두 Toleration의 값을 포드의 YAML 파일에서 별도로 재정의할 수도 있다. 
        }
        
        
        
            > 2.4 Cordon, Drain 및 PodDsistributionBudget
        > cordon을 이용한 스케쥴링 비활성화
    Taint와 Toleration을 이용해 노드에 포드가 스케쥴링되는 것을 막을 수도 있지만, 쿠버네티스에서 제공하는 더 명시적인 방법을 사용할 수도 있다. 
    아래와 같이 kubectl cordon 명령어를 사용하면 해당 노드에 더 이상 포드가 스케쥴링되지 않는다.
    
            #kubectl cordon < 노드 이름 > 
        'kubectl cordon [노드 이름] cordoned'
            #cordon을 해제하려면 uncordon을 사용한다.
        'kubectl uncordon [노드 이름]'
        
    cordon 명령어로 지정된 노드는 새로운 포드가 할당되지 않는다. 'kubectl get nodes' 명령어로 노드의 상태를 확인해 보면 STATUS 항목에
    SchedulingDisabled가 추가된 것을 확인할 수 있다.
        
            'kubectl get nodes'
    
      NAME          STATUS                         ROLES       AGE     VERSION
    [노드 이름]       READY                          master      30d       v1.15.1
    [노드 이름]       READY,SchedulingDisabled       master      30d       v1.15.1
    
    kubectl describe 명령어로 해당 노드에 어떠한 설정이 추가됐는지 확인해보자. nodes.kubernetes.io/unschedulable:NoSchedule라는 이름이
    Taint가 추가됐을 뿐만 아니라 Unschedulable 항목 또한 true 로 설정돼 있다. 
    
        'kubectl describe node [node name]'
        '
            ...
             Taints:        node.kubernetes.io/unschedulable:NoSchedule
             Unschedulable: True
             ...
        '
    
    단, 노드에 cordon 명령어를 사용하더라도 해당 노드에서 이미 실행 중인 포드가 종료되지는 않는다. cordon 명령어는 NoExecute가 아닌 NoSchedule
    효과가 있는 Taint를 노드에 추가하기 때문이다.
    
        {
            Nginx 인그레스 컨트롤러 포드가 실행 중인 노드에 cordon을 설정하면 해당 노드에서 실행 중인 포드가 종료되지는 않지만, 인그레스의 트래픽이
            해당 노드의 포드로 전달되지 않는다. 
        }    
        
        
            > drain 명령어로 노드 비활성화
    drain은 cordon처럼 해당 노드에 스케쥴링을 금지한다는 것은 같지만, 노드에서 기존에 실행 중이던 포드를 다른 노드로 옮겨가도록 퇴거(Eviction)를 수행
    한다는 점이 다르다. drain 명령어를 사용하면 해당 노드에 포드가 실행되지 않기 때문에 커널 버전 업그레이드, 유지 보수 등의 이유로 인해 잠시 노드를 중지
    해야할 때 유용하게 사용할 수 있는 명령어이다.  kubectl drain 명령어를 사용하면 노드를 drain상태로 만들 수 있다.
    
        ' kubectl drain < 노드 이름 > '
        'kubectl get nodes'
        NAME        STATUS                      ROLES        AGE     VERSION
        [name]      Ready,SchedulingDisabled    <none>      32d         ...
    
    포드가 스케쥴리오디지 않게 cordon은 설정됐지만, 해당 노드에서 실행 중이던 데몬셋 포드가 존재하여 drain을 할 수 없을 때, 데몬셋을 무시하고 drain하려면
    --ignore-daemonsets 옵션을 함께 사용하면 된다. 
        
        'kubectl drain < 노드 이름 >  --ignore-daemonsetes'
    
    디플로이먼트나 레플리카셋, 잡, 스테이트풀셋 등에 의해 생성되지 않은 포드, 즉 단일 포드가 노드에 존재할 때도 drain 명령어는 실패한다. 이는 YAML 파일
    에서 type:Pod처럼 정의해 생성한 단일 포드는 어떠한 이유로 종료되더라도 다른 노드로 옮겨가서 생성되지 않기 때문이다. 만약 단일 포드를 무시하도 노드를
    drain 을 하려면 --force 옵션을 함꼐 사용한다.
    
    
        > PodDisruptionBudget으로 포드 개수 유지하기
    drain은 노드에서 실행 중이던 포드를 모두 종료시키는 퇴거(Eviction) 기능을 포함하고 있다. 퇴거 작업은 이반적으로 포드를 종료시키는 것만을 의미하지만,
    특정 개수의 포드 개수를 유지하려는 디플로이먼트나 레플리카셋 등에 의해 생성된 포드라면 포드가 퇴거되더라도 다른 노드에서 다시 생성되는 것이 일반적이다.
    그런데 drain과 같이 포드 퇴거 작업이 수행될 때는 한 가지 문제점이 있다. 만약 drain된 노드에서 실행 중인 포드가 종료되어 해당 포드가 다른 노드로 옮
    겨가는 사이에는 애플리케이션이 중단 될 수 있기 떄문이다. 
    디플로이먼트에 의해 포드가 생성된 노드에 drain을 설정했다고 가정해보자. 실행 중이던 포드는 drain에 의해서 종료(Evict)됐기에 더 이상 요청을 처리할 수 
    없는 상태가 된다. 디플로이먼트의 레플리카셋은 실행 중인 포드의 개수가 replicas의 개수가 일치하지 않는다는 것을 감지하고 다른 노드에 포드를 새롭게 생
    성한다.
    이떄 다른 노드에서 포드가 새롭게 생성되어 준비되기 전까지는 포드가 사용자 요청을 처리할 수 없다. 물론, 디플로이먼트에서 포드의 개수(replicas)를 여러
    개로 설정함으로써 일정 개수의 포드가 중지되더라도 애플리케이션에 장애가 발생하지 않도록 구성할 수도 있다. 그렇지만 drain 명령어를 사용한 노드에서 
    여러 개의 포드가 실행되고 있었다면 어쨌든 그 포드 개수만큼은 사용자 요청을 처리할 수 없는 상태가 되고, 처리할 수 있는 요청의 총량은 일시적으로 감소할
    것이다.
    쿠버네티스에서는 이러한 상황에 대처하기 위해서 PodDisruptionBudget이라는 기능을 제공한다. PodDisruptionBudget은 kubectl drain 명령어 등으로
    인해 포드에 퇴거(Eviction)가 발생할 때, 특정 개수 또는 비율만큼 포드는 반드시 정상적인 상태를 유지하기 위해서 사용된다. 이 기능 또한 쿠버네티스의
    오브젝트이기 때문에 kubectl 명령어로 확인할 수 있다.
    
        'kubectl get poddisruptionbudges' || 'kubectl get pdb'
    
    간단한 PodDisruptionBudget을 YAML로 정의해보자.
```
```yaml
apiVersion: policy/v1beta1
kind: PodDisruptionBudget
metadta:
  name: simple-pdb-example
spec:
  maxUnavailable: 1 #비활성화될 수 있는 포드의 최대 개수 또는 비율(%)
  #minAvailable: 2
  selector:     #PDB 대상이 될 포드를 선택하는 라벨 셀렉터
    matchLabels:
      app:  webserver
```
```dockerfile
    PodDisruptionBudget에는 maxUnavailable, minAvailable 두 가지 중 하나를 사용할 수 있다. maxUnavailable은 kubectl drain 등에
    의해 노드의 포드가 종료될 때, 최대 몇 개까지 동시에 종료될 수 있는지를 뜻한다. 위 예시처럼 maxUnavailable 값을 1을 설정하면 kubectl drain
    명령어를 사용한 노드의 포드가 하나씩 종료되어 다른 노드에서 다시 생성될 것이다. 이 값은 숫자가 될수 있지만 30%, 50%와 같은 비율로 설정할 수도 있다.
    
    minAvailable 또한 비슷한 의미로 사용한다. minAvailable은 퇴거가 발생할 때, 최소 몇 개의 포드가 정상 상태를 유지해야 하는지를 의미한다. 이 값
    역시 숫자 혹은 비율로 설정할 수 있다. 단, maxUnavailable과 minAvailable은 의미만 다를 뿐 맥락상으로 같은 기능이므로 PodDisruptionBudget
    에는 둘 중 하나만 정의해야한다.
    
    selector에는 PodDisruptionBudget이 적용될 포드의 라벨을 입력한다. 이때 주의해야할 점은 디플로이먼트와 같은 컨트롤러 라벨이 아닌, 포드의 라벨을
    입력해야한다는 것이다. 따라서 위의 예시에서 webserver와 같이 PodDisruptionBudget을 디플로이먼트에 적용하려면 포드 스펙을 아래와 같이 정의해야한다.
    
```
```yaml
    ...
      metadata:
        name: my-webserver
        labels:
          app: webserver
      spec:
        containers:
        - name: my-webserver 
```

```dockerfile
    PodDisruptionBudget이 생성된 상태에서 PodDisruptionBudget의 라벨 셀렉터에 일치하는 포드가 'kubectl drain'등에 의해 퇴거해야 한다면
    PodDisruptionBudget에 정의된 값에 따라 정상 상태의 포드 개수가 일정하게 유지된다.
    단, maxUnavailable을 0 또는 0%로 설정하거나 minAvailable을 100%로 설정하면 노드의 drain이 진행되지 않을 수도 있다는 부분에 유의해야 한다. 
    
        {
            포드를 삭제하는 것(Delete)과 퇴거시키는 것(Eviction)은 결과적으로 포드를 삭제한다는 것으로 같지만, 실제로는 두 기능 전혀 다른 의미히다.
            삭제는 kubectl delete pod이기에 PodDisruptionBudget과는 상관없이 포드를 삭제한다. 그렇지만 퇴거는 쿠버네티스 내부 Evict라는 
            별도의 API로 구혀노디어 있으며 이 경우는 PodDisruptionBudget의 설정에 영향을 받는다.
        }
        
        
        
                > 2.6. 커스텀 스케쥴러 및 스케쥴러 확장
            > 커스텀 스케쥴러 구현
    지금까지의 쿠버네티스 스케쥴링 이외에도 커스터마이징하여 스케쥴링 전략을 수립할 수도 있다. 쿠버네티스는 kube-system 네임 스페이스에 존재하는 
    kube-scheduler(기본 스케쥴러) 외에도 여러 개의 스케쥴러를 동시에 사용할 수 있도록 지원한다. 이때 별도 스케쥴러는 직접 구현하거나 설정해야한다.
    
    포드를 생성하면 기본적으로 기본 스케쥴러(kube-scheduler)를 사용하게 되며, 노드 필터링과 노드 스코어링 단계를 거쳐 스케쥴링 작업을 수행한다. 포드를
    생성한 뒤에 자동으로 추가되는 schedulerName 항목에서 기본 스케쥴러 이름을 확인할 수 있다.
    
        'kubectl get pod <포드 이름> -o yaml | grep scheduler'
        
    포드를 생성할 때 schedulerName 항목을 정의하지 않으면 쿠버네티스는 기본적으로 default-scheduler라는 값을 설정하는데, 이는 기본 스케쥴러
    (kube-scheduler 포드)를 의미한다. 기본 스케쥴러는 포드의 schedulerName이 default-scheduler일 때만 해당 포드를 스케쥴링한다.
    따라서 기본 스케쥴러가 아닌 커스터마이징 스케쥴러로 포드를 스케쥴링하려면 포드를 생성할 때 schedulerName을 별도로 명시하면 된다.
    
```
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: custom-scheduled-pod
spec:
  schedulerName: my-custom-scheduler
  cotainers:
  - name: nginx:container
    image: nginx
```
```dockerfile
    이 다음은 스케쥴러를 직접 구현하는 것이다. 아래의 단계를 차례대로 소스코드로 구현하면 된다.
    
        1. API 서버의 Watch API를 통해 새롭게 생성된 포드의 데이터를 받아온다.
        2. 포드의 데이터 중에서 nodeName이 설정돼 있지 않으며 schedulerName이 스케쥴러의 정해진 이름과 일치하는지 검사한다. 일반적으로 schedulerName
        은 스케쥴러 이름을 나타내는 고유한 값을 사용한다.
        3. 필요에 따라 적절한 스케쥴링 알고리즘을 수행한 뒤, 바인딩 API 요청을 통해 스케쥴링 된 노드의 이름을 포드의 nodeName에 설정한다.

    쿠버네티스 SDK를 통해 위 단계만 구현할 수 있다면 어떤 언어를 사용해도 상관이 없다. 스케쥴러를 구현하려면 API 서버와 통신해야하기 때문에 스케쥴러는 
    kube-scheduler 포드처럼 쿠버네티스 클러스터 내부에서 포드를 실행시키는 것이 일반적이다. 그러나 스케쥴러의 원리를 간단히 테스트하기 위한 용도라면
    마스터 노드에서 셸 스크립트를 이용해볼 수 있다.
   
   
   
   
   
                > 3. 쿠버네티스 애플리케이션 상태와 배포
      쿠버네티스에서 애플리케이션을 배포하려면 어떤 방법을 사용할 수 있을까? 가장 간단한 방법은 'kubectl apply -f'로 디플로이먼트를 생성함으로써 여러 개의
      포드를 배포하는 방식을 생각할 수 있다. 조금 더 고도화된 배포를 원하면 Spinnaker, Helm, Kustomize 또는 ArgoCD나 Jenkins와 같은 지속적
      배포 도구(Continuous Delivery)를 사용할 수도 있다.
    
      단순히 애플리케이션을 생성하려면 배포도구 등을 고려할 필요 없이 새로운 버전의 도커 이미지를 사용하는 디플로이먼트의 YAML 파일을 'kubectl apply -f'
      명령어로 적용하기만 하면 도니다. 디플로이먼트에서는 애플리케이션의 버전별로 레플리카 셋을 관리하기 때문이다.
      
      하지만 애플리케이션을 안정적으로 배포하려면 더 많은 부분을 신경 써야한다. 예를 들어 기존에 생성된 애플리케엿ㄴ을 삭제한 다음 새로운 버전의 애플리케이션을
      배포해야 할 수도 있고, 이전 버전의 애플리케이션으로 롤백해야할 수도 있다.
      
      애플리케이션이 잠시 중단돼도 상관이 없다면 기존의 디플로이먼트를 삭제한 다음 새로운 디플로이먼트를 생성하는 작업만으로 충분할 것이다. 그렇지만 만약
      무중단 상태를 유지해야한다면 이러한 방식은 바람직하지 않다. 기존 디플로이먼트를 삭제한 뒤 새롭게 생성하는 사이, 애플리케이션은 다운 타임이 발생한다.
      삭제되는 포드가 처리 중이던 사용자 요청이 정상적으로 완료되지 않은 상태로 종료될 수도 있기 때문이다. 
      
      쿠버네티스는 애플리케이션을 안정적으로 배포하기 위한 몇 가지 기능이 있다. 대포적으로는 새로운 버전의 애플리케이션이 점진적으로 배포될 수 있도록 디플로이먼트에서
      롤링 업데이트 기능을 사용할 수도 있으며, 배포된 애플리케이션의 버전을 내부적으로 저장함으로써 언제든지 원하는 버전의 디플로이먼트로 되돌릴 수도 있다. 
      그뿐만 아니라 새롭게 배포되는 포드의 애플리케이션이 사용자의 요청을 처리할 준비가 됐는지 확인할 수도 있고, 삭제될 포드가 애플리케이션을 gracefully
      하게 종료할 수 있도록 별도의 설정을 추가할 수도 있다. 
      
        {
            쿠버네티스는 애플리케이션의 장애 상황을 시뮬레이션하기 위한 카오스 테스트 등의 기능을 직접적으로 제공하지는 않는다. 이러한 고급 배포 전략에 
            관심이 있다면 ISTIO, SERVICE MESH와 같은 솔루션을 고려해보는 것도 좋다.
        }
     
                > 3.1. 디플로이먼트를 통해서 롤링 업데이트
                > 디플로이먼트를 이용한 레플리카셋의 버전 관리
      테스트 또는 개발 환경이 아닌 한 포드를 직접 생성하는 경우는 거의 없다. 대부분 디플로이먼트를 생성하고, 디플로이먼트에 속하는 레플리카셋이 포드를 생성하는
      것이 일반적이다. 포드를 생성할 때 레플리카셋 대신 디플로이먼트를 사용하는 이유는 레플리카셋의 변경 사항을 저장하는 리비전(revision)을 디플로이먼트에서
      관리함으로써 애플리케이션의 배포를 쉽게하는 것이었다.
      
      디플로이먼트에서 변경 사항이 생기면 새로운 레플리카 셋이 생성되고, 그에 따라 새로운 버전의 애플리케이션이 배포된다. 이때 '--record' 옵션을 추가해
      디플로이먼트의 변경 사항을 적용하면 이전에 사용하던 레플리카셋의 정보는 디플로이먼트의 히스토리에 기록된다. 그리고 이러한 리비전을 이용해 언제든지 원하는
      버전의 애플리케이션(레플리카셋)으로 롤백할 수 있다.
      
        'kubectl apply -f deployment-v1.yaml --record'
        
        {
            기본적으로는 레플리카셋의 리비전은 10개까지만 히스토리에 저장되지만, 필요하다면 디플로이먼트를 생성할 때 revisionHistoryLimit이라는 항목을
            지정함으로써 리비전 최대 개수를 정할 수 있다.
            
            deployment-history-limit.yaml
            kind: Deployment
            metadata:
                name: deployment-history-limit
            spec:
                revisionHistoryLimit: 3
        } 
        
        
            > 디플로이먼트를 통한 롤링 업데이트 설정
      디플로이먼트를 통해 새로운 버전의 포드를 생성하는 작업 자체는 단순한 일이다. 하지만 배포 중에 애플리케이션이 중단돼도 괜찮은지에 따라 어떠한 배포 방법을
      사용할 것인지 생각해볼 필요가 있다. 일시적으로 사용자의 요청을 처리하지 못하더라도 괜찮다면 쿠버네티스에서 제공하는 ReCreate를 사용할 수도 있다.
      이 방법은 기존 버전의 포드를 모두 삭제한 뒤, 새로운 버전의 포드를 생성하는 방식이다. 
      이러한 배보 전략은 디플로이먼트의  YAML 파일에 있는 strategy의 type 항목에서 설정할 수 있다. 
```
deployment-recreate-v1.yaml
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: deployment-recreate
spec:
  replicas: 3
  strategy:
    type: Recreate
```
```dockerfile
        'kubectl apply -f deployment-recreate-v1.yaml'
        'kubectl get pods' -> STATUS: RUNNING
        'kubectl apply -f deployment-recreate-v2.yaml'
        'kubectl get pods' -> STATUS: TERMINATING
    
    하지만 포드를 삭제하고 새롭게 생성하는 사이에는 사용자의 요청을 처리할 수 없기 때문에 애플리케이션의 중단이 허용되지 않을 때는 Recrate 방식이 적절하지
    않을 수 있다. 이를 위해 쿠버네티스에서는 포드를 조금씩 삭제하고 생성하는 롤링 업데이트 기능을 제공한다. 롤링 업데이트를 사용하면 디플로이먼트를 업데이트
    하는 도중에도 사용자의 요청을 처리할 수 있는 포드가 계속 존재하기 때문에 애플리케이션의 중단이 발생하지 않는다. 
    
    우리가 YAML 파일에서 별도의 설정을 하지 않아도 디플로이먼트의 버전을 업데이트할 때는 기본적으로 롤링 업데이트를 사용하도록 설정돼 있다. 이때 롤링 업데이트
    도중에 기존 버전의 포드를 몇 개씩 삭제할 것인지, 새로운 버전의 포드는 몇 개씩 생성할 것인지 설정할 수 있다. 이러한 세부 옵션을 설정하려면 디플로이먼트를
    정의하는 YAML 파일에서 명시적으로 strategy의 type 항목을 RollingUpdate로 설정해야 한다. 
```
```yaml
    ...
      spec:
        replicas: 3
        strategy:
          type: RollingUpdate
          rollingUpdate:
            maxSurge: 2
            maxUnavailable: 2
```
```dockerfile
    롤링 업데이트의 세부 옵션에는 maxSurge, maxUnavailable 두 가지가 있으며, 이 옵션을 적절히 섞어 롤링 업데이트의 속도를 조절할 수 있다. 옵션의 값은
    숫자나 비율을 값으로 사용할 수 있으며, 비율을 사용하면 전체 포드의 개수(디플로이먼트에 정의된 replicas 값)를 기준으로 값이 결정된다. 퍼센트를 사용할 때
    maxSurge의 소수점 값은 반올림되고, maxUnavailable의 소수점은 버려진다. 또한, 두 옵션 모두 기본값은 25%이다.
    
        1. maxUnavailable: 롤링 업데이트 도중 불가능한 상태가 되는 포드의 최대 개수를 설정한다. 즉, 롤링 업데이트 도중에도 사용자의 요청이 처리될 수 
        있도록 실행 중인 포드의 개수가 일정 값 이하로 내려가지 않도록 유지한다. 예를 들어 maxUavailable의 기본값인  25%를 그대로 사용한다면 롤링 
        업데이트 도중 75%만큼의 포드는 사용자의 처리할 수 있는 상태로 유지된다.
        
        2. maxSurge: 롤링 업데이트 도중 전체 포드의 개수가 디플로이먼트의 replicas 값보다 얼마나 더 존재할 수 있는지 설정한다. 이는 곧 새로운 버전의
        포드가 얼마나 많이 생성될 수 있는지 의미한다. 예를 들어 maxSurge의 기본값인 25%를 사용하면 <이전 포드 + 새로운 포드> 의 개수는 replicas 값
        대비 최대 125%까지 늘어날 수 있다.
    
    예를 들어서 4개의 포드를 서비스 중이고 업데이트 전이 v1, 업데이트 후가 v2, maxUnavailable이 1 그리고 maxSurge가 2라면, 
        1. 업데이트 전 v1 포드 4개를 서비스한다. -> v1:4, v2:0
        2. 업데이트 시작되면 v1포드를 최대 maxUnavailable 만큼 지운다. -> v1:3 , v2:0
        3. maxSurge + 서비스 기준 개수 4 만큼이 최대이므로 v2를 맞춰서 생성한다. -> v1: 3, v2:3
        4. 업데이트 이전 버전을 삭제한다. -> v1:0, v2:3
        5. 기준치까지 v2를 채운다. -> v1:0, v2:4
    
    만약 maxUnavailable의 값을 0으로 설정하면 롤링 업데이트 도중 전체 포드 개수는 적어도 replicas의 개수만큼 유지하게 된다. 이때 maxSurge의 값도 0으로
    설정해버리면 전체 포드 개수의 상,하한선이 같아져서 새로운 버전의 포드가 생성될 수 없으며, 롤링 업데이트가 진행되지 않는다. 따라서 maxUnavailable,
    maxSurge 값을 모두 0으로 설정하는 것은 허용되지 않는다. 
    
        {
            롤링 업데이트를 사용하면 특정 순간에는 기존 버전, 새로운 버전이 공존할 수 있다. 따라서 애플리케이션과 통신하는 다른 컴포넌트들은 기존, 새로운
            버전 어떠한 버전과 통신해도 전체 시스템에 문제가 발생하지 않아야 한다.
        }
        
        
        
            > 블루 그린 배포 사용하기
    블루 그린 배포는 기존 버전의 포드를 그대로 놔둔 상태에서 새로운 버전의 포드를 미리 생성해둔 뒤 서비스의 라우팅만 변경하는 배포 방식을 의미한다. 블루 그린
    배포는 롤링 업데이트와 달리 특정 순간에 두 버전의 애플리케이션이 공존하지 않으며, Recreate 전략처럼 중단 시간이  발생하지 않는다는 장점이 있다.
    블루 그린 배포를 쿠버네티스 자체적으로 지원하지 않지만 지금까지의 기능을 활용하면 구현할 수 있다.
    
        1. 기존 버전 디플로이먼트 생성되어 있으며, 서비스는 사용자 요청을 v1포드로 전달한다.
        2. 새로운 버전의 디플로이먼트를 생성한다.
        3. 서비스의 라벨을 변경함으로써 서버를 통한 요청이 새로운 버전의 디플로이먼트로 전달되도록 수정한다.
        4. 새로운 버전의 디플로이먼트가 잘 동작하는 것을 확인했다면 기존 버전의 디플로이먼트를 삭제한다. 만약 롤백이 필요하다면 서비스 라벨을 다시 이전 상태로
        되돌린다.
        
    하지만 블루 그린 배포를 사용하면 특정 순간에는 디플로이먼트에 설정된 replicas 개수의 두 배에 해당하는 포드가 실행되기 때문에 일시적으로 전체 자원을
    많이 소모할 수 있다. 
    
    
                > 3.2. 포드의 생애 주기(LifeCycle)
    디플로이먼트를 이용해 새로운 버전의 애플리케이션으로 롤링 업데이트를 진행할 때는 기존 포드가 정상적으로 종료됐는지, 새로운 포드가 사용자의 요청을 처리할 수 
    있도록 준비됐는지 확인하는 것이 좋다. 새로운 포드가 사용자의 요청을 처리할 수 있도록 준비됐는지 확인하는 것이 좋다. 새로운 포드가 생성되어 Running
    상태가 됐더라도 애플리케이션의 초기화 작업 등으로 인해 사용자의 요청을 아직 처리할 준비가 되지 않은 상태일 수도 있다. 그뿐만 아니라 기존의 포드를 종료할 
    때는 애플리케이션이 처리 중인 요청을 전부 완료한 뒤 포드를 종료시켜야 한다.
    
    이러한 부분을 신경쓰지 않으면 디플로이먼트를 통해 업데이트를 진행할 때 사용자의 요청이 제대로 처리되지 않은 채로 포드가 종료되는 상황이 발생할 수 있다. 
    이를 위해 쿠버네티스는 포드가 시작할 때 애플리케이션이 준비됐는지 확인하거나 포드가 종료될 때 애플리케이션이 gracefully하게 종료될 수 있도록 별도의
    기능을 지원한다. 
    이번에는 새로운 버전의 애플리케이션을 배포할 때 알아야할 포드의 라이프사이클에 대해 설명한 다음, 애플리케이션의 상태 검사를 위한 livenessProbe와 
    readinessProbe에 대해서 설명한다. 
    
                > 3.2.1. 포드의 상태와 생애 주기
    포드의 생애 주기는 포드의 상태를 의미한다. 이는  'kubectl get pods'로 확인할 수 있다.
    
        1. pending: 포드를 생성하는 요청이 API 서버에 의해 승인됐지만, 어떠한 이유로 아직 실제로 생성되지 않은 상태이다. 예를 들어, 포드가 아직 노드에
        스케쥴링 되지 않았을 때는 포드의 상태가 Pending으로 출력된다. 
        2. Running: 포드에 포함된 컨테이너들이 모두 생성돼 포드가 정상적으로 실행된 상태이다. 일반적으로 쿠버네티스에서 바람직한 상태(Desired)로 간주하는
        포드의 상태에 해당된다.
        3. Completed: 포드가 정상적으로 실행되지 않은 상태로 종료됐음을 의미한다. 포드 컨테이너의 init 포로세스가 종료 코드로 0을 반환한 경우
        4. Error: 포드가 정상적으로 실행되지 않은 상태로 종료됐음을 의미한다. 포드 컨테이너의 init 프로스세스가 0이 아닌 종료 코드를 반환했을 때의 이야기
        이다.
        5. Terminating: 포드가 삭제 또는 퇴거(Eviction)되기 위해 삭제 상태에 머물러 있는 경우에 해당한다.
    
    애플리케이션을 배포할 때 중요한 상태는 Running, Terminating 두 가지이다. 사용자의 요청은 Running 상태의 포드에 전달돼야 하며, Terminating
    상태의 포드에 전달되서 안되기 때문이다. 하지만 Completed나 Error 또한 포드가 어떻게 종료됐는지를 나타내는 중요한 증거이기 때문에 어떤 상황에서 
    Completed, Error가 되는지 알아두는 것이 좋다.
    
                
                > Completed, Error와 restartPolicy
    함수가 종료되면 특정 값을 반환(return)하듯이 리눅스의 프로세스 또한 종료될 때 종료 코드를 반환한다. 컨테이너 내부의 프로세스 또한 종료될 때 종료 코드를 
    반환하는데, 컨테이너 init 프로세스가 어떠한 값을 반환하느냐에 따라 포드의 상태가 Completed 또는 Error로 설정된다. 
        {
            init 프로세스는 리눅스 시스템이 구동될 때 가장 먼저 실행되는 프로세스로, 일반적으로 프로세스 번호(PID)가 1번인 프로세스를 의미한다. 
            컨테이너에서는 Dockerfile 등에 의해 설정된 커맨드(CMD)와 Entrypoint의 조합이 init 프로세스가 된다. 예를 들어, 우분투 이미지의
            init 프로세스는 /bin/bash로 설정돼 있으며, Nginx이미지의 init 프로세스는 nginx 바이너리로 실행된 nginx 웹 서버 프로세스가 된다. 
            init 프로세스가 종료되면 컨테이너 또한 종료된다. 
        }
    Completed 상태가 되는 간단한 포드를 하나 생성해 보자. 
```
```yaml
apiVersion: v1
kind: Pod
metadata: 
  name: completed-pod-example
spec:
  containers:
  - name: completed-pod-example
    image: busybox
    command: ['sh']
    args: ['-c','sleep 10 && exit 0']
```
```dockerfile
    위의 YAML 파일에서 생성된 포드는 10초 동안 대기한 뒤 종료 코드 0을 반환하고 종료된다. 이때의 포드의 상태 변화를 보면
    
         'kubectl apply -f completed-pod.yaml'
         'kubectl get pod --watch'
                NAME              READY       STATUS      RESTARTS        AGE
        completed-pod-example      1/1        RUNNING        0             7s
        completed-pod-example      0/1        COMPLETED      0             17s
        completed-pod-example      1/1        RUNNING        1             23s
        completed-pod-example      1/1        COMPLETED      1             32s
        
    처음에는 정상적으로 Running 상태가 되고, 0을 종료 코드로 반환한 뒤, Completed 상태로 전환된다. 하지만 포드가 Completed 상태가 된 후에도 
    계속해서 다시 실행됨과 동시에 RESTARTS 카운트가 증가하는데, 이는 기본적으로 포드의 재시작 정책을 설정하는 restartPolicy 속성이 Always이기 때문이다.
    restartPolicy를 Always로 설정하면 포드의 컨테이너가 종료됐을 때 자동으로 다시 재시작된다.
    
        'kubectl get pod completed-pod-example -o yaml | grep restartPolicy'
        restartPolicy: Always
        
    restartPolicy의 값에는 Always 외에도 Never, OnFailure가 있다. Never은 포드 종료시 절대로 다시 시작하지 않음, OnFailure는 포드의 컨테이너
    가 실패했을 때, 즉 0이 아닌 종료 코드를 반환했을 때만 포드를 다시 재시작한다. 그렇다면 restartPolicy 항목을 추가한 후 새롭게 포드를 생성해보자.
         
```
```yaml
apiVersion: v1
kind: Pod
metadata: 
  name: completed-pod-restart-never
spec:
  restartPolicy: Never
  containers:
  - name: completed-pod-restart-never
    image: busybox
    command: ['sh']
    args: ['-c','sleep 10 && exit 0']
```
```dockerfile
         'kubectl apply -f completed-pod-restart-never.yaml'
         'kubectl get pod --watch'
                 NAME                    READY       STATUS               RESTARTS        AGE
        completed-pod-restart-never      1/1        CONTAINERCREATING        0             6s
        completed-pod-restart-never      1/1        RUNNING                  0             7s
        completed-pod-restart-never      1/1        COMPLETED                0             17s
        
    포드가 종료된 뒤에도 재시작하지 않고 Completed에 머물러 있다. 포드가 종료된 뒤 시작하지 않도록 restartPolicy를 Never, OnFailure로 설정하는 것은 
    쿠버네티스의 JOB, CRONJOB 오브젝트로부터 생성된 포드의 작업이 완료되어 다시 실행할 필요가 없을 때 유용하게 사용할 수 있다.
    그렇다면 포드의 컨테이너가 0이 아닌 종료 코드를 반환하면 어떻게 될까? 위 파일에서 args의 exit을 0이 아닌 1로 바꿔보자.ㅏㅏ
        
```
error-pod-restart-never.yaml
```yaml
apiVersion: v1
kind: Pod
metadata: 
  name: error-pod-restart-never
spec:
  restartPolicy: Never
  containers:
  - name: error-pod-restart-never
    image: busybox
    command: ['sh']
    args: ['-c','sleep 10 && exit 1']
```
```dockerfile
        'kubectl apply -f error-pod-restart-never.yaml'
        
                 NAME                    READY       STATUS     RESTARTS        AGE
        completed-pod-restart-never      1/1        Running         0             6s
        completed-pod-restart-never      0/1        Error           0             15s
    
    종료 코드로 1이 반화노댓끼 때문에 포드의 상태가 Error로 출력됐다. 이때 포드의 YAML 파일에서 restartPolicy를 Never로 설정했다는 점에 유의해야
    한다. 만약 restartPolicy를 별도로 명시하지 않았다면 자동으로 Always로 설정됐을 것이고, Error 상태 뒤에도 계속해서 포드는 재시작 될 것이다. 
    
    하지만 포드가 종료될 때마다 즉시 재시작되는 것은 아니다. 포드가 다시 재시작되는 과정을 유심히 봤다면 CrashLoopBackOff라는 생태를 봤을 것이다.
    쿠버네티스에서는 어떠한 작업이 잘못돼 실패했을 때, 일정 간격을 두고 해당 작업을 다시 시도한다. 그리고 실패하는 횟수가 늘어날수록 재시도하는 간격이
    지수 형태로 늘어나게 되는데, 그 중간 상태가 바로 CrashLoopBackOff이다. 따라서 실패를 반복할수록 간격, 즉 CrashLoopBackOff 상태에 머무르는 
    시간이 길어진다. 
    
    
    
            >3.2.2 Running 상태가 되기 위한 조건
    쿠버네티스에서 애플리케이션을 배포할 때 포드의 Running 상태는 매우 중요한 의미를 갖는다. 쿠버네티스에서는 대부분의 경우 포드가 Running 상태일 때를
    바람직한 상태로 간주하며, 이는 곧 포드의 컨테이너들이 정상적으로 생성됐다는 것을 의미한다.
    하지만 포드를 생성헀다고 해서 무조건 Running 상태가 되는 것은 아닐뿐더러, 포드가 Running 상태에 머물러 있다고 해서 컨테이너 내부의 애플리케이션이
    제대로 동작하고 있을 것이라는 보장은 없다. 이를 위해서 쿠버네티스는 아래와 같은 기능을 제공하고 있다. 
    
        - init Container
        - podStart
        - livenessProbe, readinessProbe
        
    포드를 생성하기 위해 위 기능들을 반드시 사용해야 하는 것은 아니지만 애플리케이션이 많고 복잡해질수록 이러한 기능을 어떻게 활용할 수 있을지 고민하는 것이
    좋다. 
    
    
            1.  Running 상태가 되기 위한 조건 - init 컨테이너
    init 컨테이너는 포드의 컨테이너 내부에서 애플리케이션이 실행되기 전에 초기화를 수행하는 컨테이너이다. Init 컨테이너는 포드의 애플리케이션 컨테이너와
    거의 동일하게 사용할 수 있지만, 포드의 애플리케이션 컨테이너보다 먼저 실행된다는 점이 다르다. 따라서 포드의 애플리케이션 컨테이너가 실행되기 전에 특정 
    작업을 미리 수행하는 용도로 사용할 수 있다.
    
    Init 컨테이너는 아래의 YAML 파일처럼 initContainers라는 별도의 항목에 정의해 사용할 수 있다. 1개 이상의 Init 컨테이너를 정의한 경우에는 각
    Init 컨테이너가 순서대로 실행된다. 
```
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: init-container-example
spec:
  initContainers: #초기화 컨테이너를 이 항목에 정의한다.
  - name: my-init-container
    image: busybox
    command: ["sh", "-C", "ech hello world"]
  containers: #애플리케이션 컨테이너를 이 항목에 정의
  - name: nginx
    image: nginx
```
```dockerfile
    위의 YAML로 포드를 생성하면 initContainers 항목에 정의한 컨테이너가 먼저 실행된 뒤, containers 항목에 정의한 컨테이너가 생성된다.
        
            'kubectl apply -f init-container-example.yaml'
            'kubectl get pods -w'
            
                        NAME                  READY         STATUS                    RESTARTS          AGE
                init-container-example         0/1         INIT:0/1                      0              3s
                init-container-example         0/1         PodInitializing               0              6s
                init-container-example         1/1         Running                       0              12s
    
    이때 Init 컨테이너가 하나라도 실패하게 된다면 포드의 애플리케이션 컨테이너는 실행되지 않으며, 포드의 restartPolicy에 따라서 init 컨테이너가
    다시 재시작 된다. 따라서 포드가 최종적으로 Running 상태가 되려면 Init 컨테이너가 무사히 실행을 마쳐야만 한다. 이러한 성질을 이용해서 Init 컨테이너
    내부에서 dig, nslookup 명령어 등을 사용해서 다른 디플로이먼트가 생성되기를 기다리거나, 애플리케이션 컨테이너가 사용할 설정 파일 등을 미리 준비해 둘
    수 있다.
    
    아래의 YAML은 다른 서비스 또는 디플로이먼트가 생성될 때까지 Init 컨테이너에서 대기하는 예시이다. 쿠버네티스에서는 여러 리소스를 한 번에 생성할 때 각 
    리소스의 의존성을 정의하는 기능을 별도로 제공하지는 않지만 Init 컨테이너를 사용하면 아래와 같이 간접적으로 의존성을 정의할 수 있다. 
```
init-container-usecase.yaml
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: init-container-usecase
spec:
  containers:
  - name: nginx
    image: nginx
  initContainers:
  - name: wait-other-service
    image: busybox
    command: ["sh", "-c", "until nslookup myservice; do echo waiting..; sleep 1; done;"]
```
```dockerfile
        {
            init 컨테이너 또한 포드에 포함된 컨테이너이기 때문에 포드의 화녕을 공유해 사용한다. 따라서 init 컨테이너에서 emptyDir 볼륨을 사용하거나
            포드의 네트워크 정보 등을 가져올 수도 있다. 
        }
    
        
            2. Running 상태가 되기 위한 조건 - postStart
    포드의 컨테이너가 실행되거나 삭제될 때, 특정 작업을 수행하도록 라이프사이클 훅(Hook)을 YAML에서 정의할 수 있다. 이 훅에는 두 가지 종류가 있는데, 
    컨테이너가 시작될 때 실행되는 podStart 컨테이너가 종료될 때 실행되는 preStop이다. preStop은 포드의 Terminating 상태를 다룰 때 쓰는 것이다.
    podStart를 먼저 알아보면, 두 가지 방법으로 사용할 수 있다.
        
        - HTTP: 컨테이너가 시작한 직후, 특정 주소로 HTTP 요청을 전송한다.
        - Exec: 컨테이너가 시작한 직후, 컨테이너 내부에서 특정 명령어를 시작한다. 
        
    두 방식 모두 상관 없지만  보편적으로 사용하는 Exec로 podStart 훅을 사용해 보자.
```
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: poststart-hook
spec: 
  containers:
  - name: poststart-hook
    image: nginx
    lifeCycle:
      postStart:
        exec:
          command: ['sh', '-c', 'touch /myfile']
```
```dockerfile
    이번에는 lifeCycle.postStart라는 항목을 새롭게 정의했고, 컨테이너가 시작될 때 실행할 명령어를 함께 설정했다. podStart 명령어를  ['sh', '-c', 'touch /myfile']
    로 설정했기 때문에 컨테이너가 실행됨과 동시에 /myfile 파일이 실행될 것이다. 단, postStart 컨테이너의 Entrypoint와는 비동기적으로 실행되며,
    어떠한 것이 먼저 실행된다는 보장은 없다.
    
        'kubectl apply -f  poststart-hook.yaml'
        'kubectl exec poststart-hook ls /myfile'
        
    이때 postStart 명령어나 HTTP 요청이 제대로 실행되지 않으면 컨테이너는 Running 상태로 전환되지 않으며, Init 컨테이너와 마찬가지로 restartPolicy
    에 의해 해당 컨테이너가 재시작된다. 그뿐만 아니라 postStart 단계에서 시간이 오래 걸리면 그만큼 Running 상태까지 도달하는 시간이 길어질 수 있다.
    
        {
            init 컨테이너의 로그는 kubectl logs < 로그 이름 > -c < 컨테이너 이름 > 으로 확인할 수 있지만, postStart에 의한 실행 로그는 에러가
            발생하지 않는 한 별도로 확인할 수 없다. 
        }
        
        
        
        
        
                > 3.2.3. 애플리케이션의 상태 검사 - livenessProbe, readinessProbe
    Init 컨테이너가 차례대로 실행되고, 컨테이너 내부에서 postStart훅이 실행된 뒤에야 비로소 포드가 Running 상태로 바뀌게 된다. 하지만 Init 컨테이너나
    postStart 훅이 정상적으로 실행됐다고 해서 애플리케이션이 제대로 동작하고 있다는 보장은 없다. 애플리케이션이 실행됐더라도 여타 이유로 인해 사용자의
    요청을 처리할 수 없는 상태일 수도 있기 때문이다.
    
                                        POD
    포드 생성 ->    [init containers]  ->  [Application Containers](pod start <readinessProbe> Running <livenessProbe> )
    *** 포드가 시작되고 난 뒤 컨테이너 내부에서 동작 순서
    
    
    쿠버네티스는 애플리케이션이 사용자 요청을 처리할 수 있는 상태인지 판별하기 위해 livenessProbe, readinessProbe 두 가지 방법을 제공한다. 이 두
    가지 방법은 포드가 Running 상태가 되기 위한 필수 조건은 아니지만, 포드 내부의 애플리케이션이 실제로 사용자의 요청을 처리할 수 있는 상태인지
    확인하기 위해 사용할 수 있다. 
    
        - livenessProbe : 컨테이너 내부의 애플리케이션이 살아있는지(liveness) 검사한다. 검사에 실패할 경우 해당 컨테이너는 restartPolicy에 
        따라 재시작된다.
        - readinessProbe : 컨테이너 내부의 애플리케이션이 사용자 요청을 처리할 준비가 됐는지(readiness) 검사한다. 검사에 실패할 경우 컨테이너는 
        서비스 라우팅 대상에서 제외된다.
        
    livenessProbe와 readinessProbe는 언뜻 보기에 비슷해 보일 수 있지만 각 기능이 의도하는 목적은 명확히 다르다. livenessProbe는 애플리케이션이
    정상 상태를 유지하고 있는지 지속해서 검사하는 것이고,  readinessProbe는 애플리케이션이 시작된 뒤 초기화 작업이 마무리되어 준비 됐는지(readiness)
    검사하는 것이 목적이다. 
    livenessProbe 검사에 실패했다는 것은 애플리케이션 내부에 뭔가 문제가 생겼다는 것이기에 정상 상태로 되돌리기 위해서 컨테이너를 재시작하지만,
    readinessProbe는 그렇지 않다. readinessProbe가 실패했다는 것은 애플리케이션이 실행 직후 초기화 등의 작업으로 인해 아직 준비되지 않다는 뜻이기
    때문에 사용자의 요청이 전달되지 않도록 서비스의 라우팅 대상에서 포드의 IP를 제외한다. 어느정도 시간이 지나 애플리케이션의 초기화 작업이 끝나 준비가
    완료되서야 readinessProbe 검사에 성공할 것이고, 사용자의 요청이 포드로 전달될 수 있게 서비스의 라우팅 대상에 포드의 IP가 추가될 것이다.
    
    
        > livenessProbe로 애플리케이션의 상태 검사
    livenessProbe 기능을 테스트해보기 위해서 간단한 포드를 생성해보자. 아래의 내용으로 YAML 파일을 작성하자.
```
livenessprobe-pod.yaml
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: livenessprobe-pod
spec:
  containers:
  - name: livenessprobe-pod
    image: nginx
    livenessProbe: # 이 컨테이너에 대해 livenessProbe를 정의한다.
      httpGet:     # HTTP 요청을 통해 애플리케이션의 상태를 검사한다.
        port: 80   # <포드의 IP>:80/ 경로를 통해 헬스 체크 요청을 보낸다.
        path: / 
```
```dockerfile
    컨테이너의 내부 항목에 livenessProbe를 정의했으며, HttpGet에 경로와 포트를 지정했다. livenessProbe와 readinessProbe는 아래의 3가지 방식
    중 하나를 선택해 애플리케이션의 상태를 검사할 수 있다. 위의 예시에서는 Nginx 서버 컨테이너에 HTTP 요청을 전송함으로써 상태를 검사하는 httpGet을
    사용했다.
    
        - httpGet: HTTP 요청을 전송해 상태를 검사한다. HTTP 요청의 종료 코드가 200 혹은 300 계열이 아닌 경우 애플리케이션의 상태 검사가 싶패한 것
        으로 간주한다. 요청을 보낼 포트와 경로, 헤더, Https 사용 여부 등을 추가로 지정할 수 있다.
        - exec: 컨테이너 내부에서 명령어를 실행해 상태를 검사한다. 명령어의 종료 코드가 0이 아닌 경우에 애플케이션의 상태 검사가 실패한 것으로 간주한다.
        - tcpSocket: TCP 연결이 수립될 수 있는지 체크함으로써 상태를 검사한다. TCP 연결이 생성될 수 없는 경우에 애플리케이션의 상태 검사가 실패한 것
        으로 간주된다. 
        
    이 포드를 생성하면 주기적으로 포드의 IP로 HTTP 요청을 전송함으로써 상태 검사를 수행한다. 
    
        ' kubectl apply -f livenessprobe-pod.yaml '
        ' kubectl get pods '
        
    Nginx 서버는 기본적으로 80 포트의 / 경로에서 웹페이지(index.html)를 제공하기 때문에 검사가 문제 없이 통과했을 것이다. 만약 여기서 일부러 index.html
    을 삭제하면 livenessProbe가 실패하면 어떻게 될 것인가?
    
        ' kubectl exec livenessprobe-pod --rm /usr/share/nginx/html/index.html '
        ' kubectl get pods - w '
        
    시간이 어느 정도 지난 뒤, 포드의 restart 횟수가 증가했다. 주기적으로 실행되고 있는 livenessProbe의 상태 검사가 실패해 컨테이너가 재시작 됐기 때문이다.
    컨테이너가 재시작함으로써 Nginx 서버의 index.html 파일 또한 원래대로 되돌아 왔기에 livenessProbe는 성공이 된다. kubectl describe 명령어로 
    포드의 정보를 확인하면 이를 명확히 할 수 있다. 
    
        ' kubectl describe po livenessprobe-pod '
        {
            Events는 kubectl get events 명령어로도 확인할 수 있다. 
        }
        
            > readinessProbe로 애플리케이션의 상태 검사하기
    앞서 설명한 것처럼 readinessProbe는 아직 준비되지 않은 포드의 애플리케이션이 사용자의 요청을 받아들이지 않도록 하는 기능이다. readinessProbe
    상태 검사에 실패했더라도 시간이 지남에따라 초기화 작업 등이 완료되어 준비 상태가 될 수 있기 때문에 일시적으로 포드를 서비스의 라우팅 대상에서 제외하는 
    작업만을 수행한다.
    readinessProbe를 테스트하기 위해서 간단한 포드와 서비스를 생성하는 YAML 파일을 작성한다. 이 YAML 파일로 생성되는 폳는 서비스 리소스를 통해 
    접근할 수 있다.
```
readinessprobe-pod-svc.yaml
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: readinessprobe-pod
  labels:
    my-readinessprobe: test
spec:
  containers:
  - name: readinessprobe-pod
    image: nginx #nginx 서버 컨테이너를 생성
    readinessProbe: #<포드의 IP>:80/로 상태 검사 요청을 전송한다.
---
apiVersion: v1
kind: Service
metadata:
  name: readinessprobe-svc
spec:
  ports:
  - name: nginx
    port: 80
    targetPort: 80
  selector:
    my-readinessprobe: test
  type: ClusterIP
```
```dockerfile
    livenessProbe와 달리  restart 횟수가 증가하지 않았으며, 단순히 Ready 상태인 컨테이너가 하나 줄었들었을 뿐이다. Nginx 서버로의  readinessProbe
    에 실패했기 때문에 컨테이너가 준비되지 않았다고 간주하는 것이다. 따라서 서비스 리소스는 사용자 요청을 이 포드로 전달하지 않는다.
    
        ' kubectl run -i -tty -rm debug --image=alicek106/ubuntu:curl --restasrt=Never --curl --connect-timeout 5 readi\
        nesssprobe-svc'
        
    서비스에 의해 생성된 엔드포인트(EndPoint) 리소스 목록을 확인해 보면 라우팅 대상에서 포드의 IP가 제거돼 있을 것이다. 
    
        'kuectl get endpoints'
        
        {
            애플리케이션에 readinessProbe를 적용하기 어렵거나, 초기화 시간이 어느 정도 필요한 경우에는 디플로이먼트에서  minReadySeconds를 사용할
            수 있다. minReadySeconds는 디플로이먼트의 업데이트시 컨테이너가 준비되기 위한 최소 대기 시간을 의미하며, 새로운 포드가 생성된 뒤, 
            minReadySeconds의 시간이 지난 뒤에야 포드의 삭제 및 생성이 계속된다. 
            
            minreadyseconds-v1.yaml
            ...
                spec:
                    replicas: 1
                    minReadySeconds: 30
                    strategy:
                        type: RollingUpdate
            ...
        }
        
        
                > livenessProbe와 readinessProbe의 세부 옵션
    필요하다면 livenessProbe, readinessProbe의 상태 검사 주기, 타임아웃 시간 등의 세부 옵션을 명시적으로 설정할 수 있다. 앞서 livenessProbe와
    readinessProbe를 사용했던 것처럼 세부 옵션을 설정하지 않았다면 기본값이 적용된다. 
    
        - periodSeconds: 상태 검사를 진행할 수기를 설정한다. 기본값은 10초이다.
        - initDelaySeconds: 포드가 생성된 뒤 상태 검사를 시작할 때까지의 대기 시간을 설정한다. 기본적으로 설정돼 있지 않다.
        - timeoutSeconds: 요청에 대한 타임아웃 시간을 설정한다. 기본값은 1초이다.
        - successThreshold: 상태 검사에 성공했다고 간주할 검사 성공 횟수를 설정한다. 기본값은 1이다.
        - failureThreshold: 상태 검사가 실패했다고 간주할 검사 실패 횟수를 설정한다. 기본 값은 3이다. 
```
probe-options.yaml
```yaml
...
  readinessProbe:
    httpGet:
      port: 80
      path: /
      periodSeconds: 5
      initialDelaySeconds: 10
      timeoutSeconds: 1
      successThreshold: 1
      failureThreshold: 3
```
```dockerfile
            > 3.2.4. Terminating 상태와 애플리케이션의 종료
    새로운 버전의 애플리케이션을 배포할 떄, 새로운 포드가 준비됐는지 확인하는 것만큼 중요한 작업은 '기존 버저느이 포드를 무사히 종료시키는 것'이다. 
    예를 들어서, 사용자의 요청을 처리하던 도중에 포드가 삭제되어 애플리케이션이 비정상적으로 종료될 경우 사용자들은 Empty Reply처럼 잘못된 응답을 수신할
    수도 있다. 따라서 새로운 애플리케이션으로 업데이트하는 것뿐만 아니라. 기조넹 실행 중이던 애플리케이션을 어떻게 gracefully하게 종료할 수 있을지에 대해서
    도 고민해볼 필요가 있다. 
    
    gracefully하게 포드 내부의 애플리케이션을 종료하는 가장 좋은 방법은 애플리케이션의 소스코드 레벨에서 종료 처리 로직을 구현하는 것이다. 이러한 종료 처리
    로직의 에시로는 이미 도착해있던 사용자 요청을 마저 끝내는 것일 수도 있고, DB 커넥션 등과 같은 리소스를 정리하는 것일 수도 있다. 하지만 이러한 로직이 언제 
    실행될지를 파악하려면 포드가 삭제될 떄 어떤 일들이 발생하는지 알 필요가 있다. 
    
        1. 리소스가 삭제될 예정이라는 의미의 deletionTimestamp 값이 포드의 데이터에 추가되고, 포드는 Terminating 상태로 바뀐다.
        2. 아래의 세 가지 장업이 동시에 실행된다. 
            2-1. 포드에 preStop 라이프사이클 훅이 설정돼 있다면 preStop이 실행된다.
            2-2. 포드가 레플리카셋으로부터 생성된 경우 해당 포드는 레플리카셋의 관리 영역에서 벗어나며, 레플리카셋은 새로운 포드를 생성하려고 시도한다.
            2-3. 포드가 서비스 리소스의 라우팅 대상에서 제외된다. 
        3. preStop 훅이 완료되면 리눅스 시그널 중 SIGTERM이 포드의 컨테이너에 전달된다. 컨테이너의  init 프로세스는 SIGTERM을 수신한 뒤 종료돼야 한다.
        4. 특정 유예 기간이 지나도 컨테이너 내부의 프로세스가 여전히 종료되지 않으면 프로세스로 SIGKILL 시그널이 전달된다. 이 유예 기간은 기본적으로
        30초로 설정돼 있으며, 포드의 terminationGracePeriodSeconds라는 항목을 통해 설정할 수 있다. 
        
        
        prestop 실행                  SIGTERM 전달                              (아직 종료 안됐다면) SIGKILL전달
          ⬇    [preStop 실행 중]           ⬇  [프로세스 종료 중]                                    ⬇       
        0 ---------------------------------------------------------------------------------------------->t1
                            terminationGracePeriodSeconds의 값: t1( 기본값 30초 )
    
    위 단계 중에서 애플리케이션이 우아하게 종료될 수 있도록 별도의 장치를 마련할 수 있는 부분은 preStop, SIGTERM 시그널 전달 단계이다. 
    preStop 라이프사이클 훅은 포드의 컨테이너가 종료되기 전에 실행되는 작업으로, 앞서 사용해봤던 postStart처럼 exec, http로 사용할 수 있다. 예를 들어
    아래의 YAMLㅏ핑ㄹ처럼 프로세스를 정리하는 명령어를 사용할 수도 있고, 서버를 종료하는 /abort와 같은 경로로 http 요청을 보낼 수도 있다. 
```
prestop-hook.yaml
```yaml
apiVersion: v1
kind: Pod
metadata: 
  name: prestop-hook
spec:
  containers:
  - name: prestop-hook
    image: nginx
    lifeCylcle:
        preStop:
          exec:
            command: ['/user/sbin/nginx', '-s', 'quit']
```
```dockerfile
    preStop 훅시 실행되고 나면 포드의 컨테이너들에 SIGTERM 시그널을 보냄으로써 포드가 곧 종료될 것이라고 알린다. 이때 애플리케이션의 소스코드에서는 
    SGITERM 시그널을 수신했을 떄 어떠한 행동을 취할 것인지 별도로 구현해 놓아야한다. 만약 SIGTERM 시그널을 처리하는 별도로 로직을 구현하지 못한 상태로
    포드가 종료된다면 클라이언트는 해당 포드로부터 응답을 제대로 수신하지 못할 수도 있다. 만약 포드 내부의 애플리케이션이 SIGTERM을 수신했는데도 특정 유예 
    시간 이내에 종료되지 않으면 쿠버네티스는 SIGKILL 시그널을 전송해 강제로 프로세스를 종료하게 도니다. 이 유예 기간은 기본적으로 30초이지만, 
    포드의 terminationGracePeriodSeconds 값을 명시함으로써 별도로 설정할 수도 있으며, kubectl deelte 명령어에서 '--grace-period=10'처럼
    사용해 설정할 수도 있다.
```
termination-grace-period-seconds.yaml
```yaml
...
  metadata:
    name: termination-grace-period-seconds
  spec:
    terminationGracePeriodSeconds: 10
  containers:
...
```
```dockerfile
    {
        terminationGracePeriodSeconds 값이 0 으로 설정된다는 것은 포드의 컨테이너를 강제로 종료한다는 것을 의미한다. 
    }
    
            > 3.3. HPA를 활용한 오토 스케일링 
    실제 사용자의 요청을 처리하는 서버를 배포할 떄, 서버의 개수를 구정시켜 놓은 것은 상당히 비효율적이다. 부하가 적을 경우 리소스를 낭비하는 셈이 될 것이고
    부하가 많을 때는 각 서버가 감당할 수 있는 처리량보다 더 많은 요청을 처리해야할 수도 있기 때문이다. 이러한 경우에 대비해 쿠버네티스에서는 리소스 사용량에
    따라 디플로이먼트의 포드 개수를 자동으로 조절하는 HPA(Horizontal Pod AutoScaler)라는 기능을 제공한다. 
    
    HPA는 쿠버네티스에 내장돼 있는 기능이긴 하지만 mertrics-server라는 별도의 리소스 메트릭 수집도구를 설치해야만 오토스케일링 기능을 정상적으로 사용할 
    수 있다. 오토스케일링을 수행하기 위해서는 CPU나 메모리 사용량 정보를 어디선가 제공받아야하는데, 쿠버네티스가 자체적으로 메트릭을 수집하는 기능을 제공하지
    않기 때문이다. 따라서 설명할 내용들은 metrics-server를 설치해서 kubectl top 명령어를 정상적으로 사용할 수 있다는 가정하에 진행된다. 
    
    오토스케일링 기능을 사용해보기 위해 간단한 HPA와 디플로이먼트를 생성해보자. 아래와 같은 YAML 파일을 작성한다.
```
simple-hpa.yaml
```yaml
apiVersion: autoscaling/v1
kind: HorizontalPodAutoscaler
metadata: 
  name: simple-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: hostname-deployment           #[1] simple-deployement의 자원 사용량에서 
  targetCPUUtilizationPercentage: 50    #[2] CPU 활용률이 50% 이상인 경우
  maxReplicas: 5                        #[3] 포드를 최대로 5까지 늘린다.
  minReplicas: 1                        #[4] 또는 최소 1개까지 줄어들 수도 있다. 
```
```dockerfile
    위의 내용 중 CPU 사용량이 아닌 CPU Utilization이라고 표현한 점에 유의해야한다. HPA는 포드의 절대적인 리소스 사용량이 아닌, 포드에 할당된 request
    대비 얼마나 리소스를 사용하고 있는지를 기준으로 삼는다. 예를 들어, 만약 포드의 CPU request 값이 1000m 이라면 포드의 CPU 사용률이 50%가 되는 지점,
    즉 500m을 기준으로 오토스케일링을 진행한다. 
    
    만약 처리해야하는 요청량이 동일하게 정해져 있다면 포드 개수를 늘릴 경우 자연스럽게 부하가 분산될 것이다. HPA는 전체 리소스 사용률의 평균 타깃 값보다
    아래가 될 때까지 오토스케일링을 진행하기 때문에 포드가 늘면서 CPU Utilization을 계산하여 안정화 된 상태까지 오토스케일링을 진행한다.
    
    여러 개의 포드가 존재하는 경우 모든 포드의 리소스 사용량의 평균값을 계산해서 사용한다. 예를 들어 두 개의 포드 (A: 600m), (B: 600m)가 존재하는 경우
    포드의 리소스 사용률 값의 평균을 낸 다음, 리소스 타깃보다 낮아질 수 있을 만큼의 포드를 더 생성한다.
    
        (600+600) / (1000: cpu Request) / 2(포드 개수) * 100 = 60%(50%보다 크므로 오토스케일링이 진행됨)
        
    하지만 HPA가 모든 상황에서 좋은 것은 아니다. 예를 들어, 애플리케이션을 초기화할 때 잠시 동안만 CPU를 과도하게 소모는 JVM기반 애플리케이션을 생각해보자
    HPA는 포드의 생성 시간이 아닌 CPU 사용률을 기준으로 오토스케일링을 진행하기 떄문에 불필요하게 포드가 계속해서 스케일 아웃(scale-out)될 것이고,
    이는 계속해서 포드가 증식하는 연쇄 작용을 불러일으킬 수도 있다. 현재 쿠버네티스에서 이를 해결하는 완변한 방법을 제공하고 있지는 않지만 필요하다면 HPA가
    포드 개수를 싱크하는 주기인 --horizontal-pod-autoscaler-sync-perod 옵션 등을 쿠버네티스 컨트롤러(kube-controller-manage)에서 수정해
    어느 정도 완화할 수는 있다. 
```