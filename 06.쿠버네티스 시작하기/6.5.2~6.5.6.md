####6.5.2 ClusterIP 타입의 서비스 - 쿠버네티스 내부에서만 포드 접근하기
```yaml
apiVersion: v1
kind: Service
metadata:
  name: hostname-svc-clusterip
spec:
  ports:
    - name: web-port
      port: 8080
      targetPort: 80
  selector:
    app: webserver
  type: ClusterIP
```
```dockerfile
    1. spec.selector: selector 항목은 이 서비스에서 어떠한 라벨을 가지는 포드에 접근할 수 있게 만들 것인지 결정한다. 위 예시에서는 
    app: webserver라는 라벨을 가지는 포드들의 집합에 접근할 수 있는 서비스를 생성한다. deployment-hostname.yaml 파일로 생성된 디플로이먼트의 
    포드는 이 라벨이 설정돼 있으므로 이 서비스에 의해 접근 가능한 대상으로 추가된다. 
   2. spec.ports.port: 생성된 서비스는 쿠버네티스 내부에서만 사용할 수 있는 고유한 IP(ClusterIP)를 할당받는다. port 항목에는 서비스의 IP에 
   접근할 때 사용할 포트를 설정한다. 
   3. spec.ports.targetPort: selector 항목에서 정의한 라벨에 의해 접근 대상이 된 포드들이 내부적으로 사용하고 있는 포트를 입력한다.
   포드 템플릿에 정의된 containerPort와 같은 값으로 설정해야한다. 
   4. spec.type: 이 서비스가 어떤 타입인지 나타낸다. 서비스의 종류에는 ClusterIP, NodePort, LoadBalancer 등을 설정할 수 있다. 
   
   이를 통해 만든 후 요청을 보내면 서비스를 생성할 때 별도의 설정을 하지 않아도 서비스는 연결된 포드에 대해서 로드 밸런싱을 수행한다. 서비스에는
   IP뿐만 아니라 서비스 이름 그자체로도 접근할 수 있다. 쿠버네티스는 애플리케이션이나 서비스나 포드를 쉽게 찾을 수 있도록 내부 DNS를 구동하고 있으며,
   포드들은 자동으로 이 DNS를 사용하도록 설정된다.
   
   {
        서비스의 라벨 셀렉터(selector)와 포드의 라벨이 매칭돼 연결되면 쿠버네티스는 자동으로 엔드포인트(endpoint)라고 부르는 오브젝트를 별도로 생성
        한다. 엔드 포인트라는 이름이 의미하는 것처럼 엔드포인트 오브젝트는 서비스가 가리키고 있는 도착적을 나타낸다. 엔드포인트는 서비스를 이용해서 포드를
        연결하면 엔드포인트는 자동으로 생성되므로 엔드포인트는 자세하게 알 필요까지는 없다. 다면, 엔드포인트 자체도 독립된 쿠버네티스의 리소스이기 떄문에
        이론상으로는 서비스와 엔드포인트를 따로 만드는 것도 가능하다.  
   } 
```
####6.5.3 NodePort 타입의 서비스 - 서비스를 이용해 포드를 외부에 노출하기 
```dockerfile
    ClusterIP 타입의 서비스는 내부에서만 접근 가능하지만, NodePort 타입의 서비스는 클러스터 외부에서도 접근할 수 있다. 단, NodePort라는 이름에서 알 
    수 있듯이 NodePort 타입의 서비스는 모든 노드(Node)의 특정 포트(Port)를 개방해 서비스에 접근하는 방식이다. 스웜 모드에서 컨테이너를 외부로
    노출하는 방식과 비슷하다고 생각하면 쉽다.
```
```yaml
apiVersion: v1
kind: Service
metadata:
  name: host-svc-nodeport
spec:
  ports: 
    - name: web-port
      port: 8080
      targetPort: 80
  selector:
    app: webserver
  type:NodePort
```
```dockerfile
    ClusterIP 타입의 서비스를 생성했을 때 사용한 YAML 파일과 비교했을 때, type 항목을 NodePort로 설정한 점을 제외하고는 모두 동일하다. 
    NodePort는 ClusterIP와 동작 방법이 다른 것일 뿐 동일한 서비스 리소스이기 때문에 라벨 셀렉터, 포트 설정 등과 같은 기본 항목의 사용 방법은
    모두 같다. 서비스 목록을 확인해보면 NodePort 타입의 서비스가 생성됐음을 알 수 이싿. PORT(S) 항목에 출력된 포트는 모든 노드에서 동일하게 접근할 수
    있는 포트를 의미한다. 즉, 클러스터의 모든 노드에 내부 IP또는 외부 IP를 통해서 31514 포트로 접근하면 동일한 서비스에 연결할 수 있다. 
    단 GKE에서 쿠버네티스를 사용하고 있는 경우 각 노드의 랜덤한 포트에 접근하기 위해 별도로 방화벽 설정을 추가해야한다. 또한 AWS에서도 마찬가지로 
    Security Group에 별도로 Inbound 규칙을 추가하지 않으면 NodePort 통신이 실패할 수도 있다. 
    {
        spec:
            ports:
            - name: web-port
              port: 8080
              targetPort: 80
              nodePort: 31000 ##과 같이 지정할 수 있다.
    }
    이상한 점이있다면 NodePort 타입 서비스임이도 불구하고 'kubectl get service' 명령어의 출력에서 CLUSTER-IP 항목에 내부 IP가 할당됐기 때문이다.
    ClusterIP 타입의 서비스에 접근했을 떄와 마찬가지로 NodePort 타입 서비스의 내부 IP로 접근할 수도 있다. 이는 사실 NodePort 타입의 서비스가 
    ClsuterIP의 기능을 사용할 수 있기 떄문이다. 즉, NodePort 타입의 서비스는 내부 네트워크와 외부 네트워크 양쪽에서 접근할 수 있다.
    
    {
        기본적으로 NodePort가 사용할 수 있는 포트 범위는 30000 ~ 32768이지만, API 서버 컴포넌트 실행 옵션을 변경하면 원하는 포트 범위를 설정할 수 
        있다. 포트 범위를 직접 지정하려면 API 서버 옵션을 다음와 같이 추가하거나 수정한다. '--service-node-port-range=30000-35000'
    }
    
    그렇지만 실제 운영 환경에서 NodePort로 서비스를 외부에 제공하는 경우는 많지 않다. NodePort에서 포트 번호를 80 또는 443으로 설정하기에는 적절하지
    않으며, SSL 인증서 적용,  라우팅 등과 같은 복잡한 설정을 서비스에 적용하기가 어렵기 떄문이다. 따라서 NodePort 서비스 그 자체를 통해 서비스를 외부로
    제공하기보다는 인그레스(Ingress)라고 부르는 쿠버네티스의 오브젝트에서 간접적으로 사용되는 경우가 많다. 인그레스 오브젝트는 단순하게 외부 요청을 실제로
    받는 관문 정도로 이해하면 된다.
```
####6.5.4 클라우드 플랫폼의 로드 밸런서와 연동하기 - LoadBalancer 타입의 서비스 
```dockerfile

    A. 클라우드
     
    LoadBalancer 타입의 서비스는 서비스 생성과 동시에 로드 밸런서를 새롭게 생성해 포드와 연결한다. NodePort를 사용할 떄는 각 노드의 IP를 알아야만
    포드에 접근할 수 있었지만, 이번에 사용할 LoadBalancer 타입의 서비스는 클라우드 플랫폼으로부터 도메인 이름과 IP를 할당받기 때문에 NodePort보다 
    더욱 쉽게 포드에 접근할 수 있다. 
    단, LoadBalancer 타입의 서비스는 로드 밸런서를 동적으로 생성하는 기능을 제공하는 환경에서만 사용할 수 있다는 점을 알아둬야 한다. 일반적으로 AWS, 
    GCP 등과 같은 클라우드 플랫폼 환경에서만 LoadBalancer 타입을 사용할 수 있으며, 가상 머신이나 온프레미스 환경에서는 사용하기 어려울 수 있다.
    
    AWS는 kops를 GCP는 GKE(Google Kubernetes Engine)에서 사용하면 된다. 또는 AWS에서 클라우드 프로바이더를 설정해 kubeadm으로 설치한 쿠버네
    티스를 사용해도 된다. 
```
```yaml
apiVersion: v1
kind: Servie
metadata:
  name: hostname-svc-1b
spec:
  ports:
  - name: web-port
    port: 80
    targetPort: 80
  selector:
    app: webserver
  type: LoadBalancer
```
```dockerfile
    이번 ports.port 항목을 80으로 변경했으며, type 항목을 LoadBalancer로 설정했다. ports.port 항목은 로드 밸런서에 접근하기 위한 포트를 의미하
    기 떄문에, 이번에는 80으로 설정했다. 'kubectl apply -f hostname-svc-lb.yaml'으로 실행 후 'kubectl get svc'로 목록을 보면 
    LoadBalancer 타입 또한 NodePort나 ClusterIP와 동일하게 서비스의 IP(CLUSTER-IP)가 할당 됐으며, 포드에서는 서비스의 IP 또는 서비스 이름으로
    서비스에 접근할 수 있다. 그러나 여기서 눈여겨봐야할 항목은 EXTERNAL-IP이다. 이 주소는 클라우드 플랫폼인 AWS로부터 자동으로 할당된 것이며, 이 주소와
    80포트를 통해 포트에 접근할 수 있다.  다른 서비스 타입과 마찬가지로 요청이 여러 개의 포드로 분산되는 로드 밸런싱 기능을 자동으로 사용할 수 있다.
    PORTS에 80:32620이라고 되어 있는데 32620은 무엇일까? 이 숫자는 각 노드에서 동일하게 접근할 수 있는 포트 번호를 의미합니다. 32620 포트를 통해 각 
    노드의 IP로 접근해보면 로드 밸런서와 똑같이 포드에 접근할 수 있다. 
    이렇게 각 노드의 포트로 접근하는 것은 마치 NodePort 타입의 서비스와 비슷해 보이기도 한다. 그렇지만 LoadBalancer 타입의 서비스를 생성했는데, 
    32620 포트는 왜 개방된 것일까? 그 이유는 LoadBalancer 타입의 서비스가 포드로 요청을 전송하는 원리에 있다. 
    
        1. LoadBalancer 타입의 서비스가 생성됨과 동시에 모든 워크 노드는 포드에 접근할 수 있는 랜덤한 포트를 개방한다. 위의 예시에는 32620이 개방.
        2. 클라우드 플랫폼에서 생성된 로드 밸런서로 요청이 들어오면 이 요청은 쿠버네티스의 워커 노드 중 하나로 전달되며, 이때 사용되는 포트는 1번에서
        개방된 포트인 32620이다.
        3. 워커 노드로 전달된 요청은 포드 중 하나로 전달되어 처리된다.
    
    AWS를 사용하는 경우 관리 콘솔에서 로드 밸러서의 정보를 확인해 보면 모든 워커 노드가 로드 밸런서에 연결돼 있음을 알 수 있다. 로드 밸런서로 들어온
    요청은 각 워커의 32620 포트로 전달된다. 즉, 위에서 분명 LoadBalacner 타입을 명시해 생성했지만 NodePort의 간접적인 기능 또한 자동으로 사용할 수 
    있는 셈이다.
    
    B. 온프레미스 환경에서 LoadBalancer 사용
    LoadBalancer 타입의 서비스는 일반적으로 AWS와 같은 클라우드 플랫폼에서 사용되지만, 필요하다면 직접 갖고 있는 온프레미스 서버에도 LoadBalancer
    타입을 사용할 수 있다. 단, 쿠버네티스가 이 기능을 직접 제공하는 것은 아니며, MetalLB나 오픈 스택과 같은 특수한 환경을 직접 구축해야한다. 
    그 중에도 MetalLB는 쿠버네티스의 공식 프로젝트가 아니며, 유지보수가 지속적이지 않을 수 있다.
```

####6.5.5 트래픽의 분배를 결정하는 서비스 속성 :externalTrafficPolicy
```dockerfile
    LoadBalancer 타입의 서비스를 사용하면 외부로부터 들어온 요청은 각 노드 중 하나로 보내지며, 그 노드에서 다시 포드 중 하나로 전달된다. 마찬가지로
    NodePort 타입을 사용했을 떄도 각 노드로 들어오는 요청은 다시 포드 중 하나로 전달된다. 그렇지만 이러한 요청 전달 원리는 경우에 따라 효율적이지 않을
    때도 있다. 
    
    
        랜덤 포트   → [      <포드a>  ] (워커 노드 A)
                        ↘︎
                    [      <포드b>  ] (워커 노드 B)
                    
    LoadBalancer 또는 NodePort에 의해 모든 노드에서 31000번 포트가 개방되어 포드가 개방되어 포드에 접근할 수 있으며, 워커 노드 A로 들어오는 요청은
    A에 위치한 a포드 또는 B에 위치한 b포드 중 하나로 전달된다. 여기서 주목해야 하는 부분은 A노드로 들어오는 굳이 B로 전달되지 않고 A에서 처리할 수 있다는
    부분이다. A에서 B로 넘어가면서 불필요한 네트워크 홉(hop)이 한 단계 더 발생하게 된다. 게다가 노드 간의 리다이렉트가 발생하게 되어 출발지 주소가 바뀌는
    SNAT이 발생하게 된다. 이로 인해 클라이언트의 IP주소 또한 보존되지 않는다는 단점이 있다. 
    이러한 요청 전달 메커니즘은 서비스의 속성 중 externalTrafficPolicy 항목에 정의되어 있다. 'kubectl get -o yaml' 명령어로 서비스의 모든 속성
    을 출력해 보면 externalTrafficPolicy가 Cluster로 설정된 것을 알 수 있다. 
    
    이처럼 externalTrafficPolicy에서 기본적으로 설정된 값인 Cluster는 클러스터의 모든 노드에 랜덤한 포트를 개방하는, NodePort와 LoadBalacner
    타입의 서비스가 기본적으로 동작하는 방식이다. 그러나 externalTrafficPolicy를 Local로 설정하면 포드가 생성된 노드에서만 포드로 접근할 수 있으며, 
    로컬 노드에 위치한 포드 중 하나로 요청이 전달된다. 즉, 추가적인 네트워크 홉이 발생하지 않으며, 전달되는 요청의 클라이언트 IP 또는 보존된다.
    
```         
```yaml
apiVersion: v1
kind: Servie
metadata:
  name: hostname-svc-1b
spec:
  externalTrafficPolicy: Local
  ports:
  - name: web-port
    port: 80
    targetPort: 80
  selector:
    app: webserver
  type: LoadBalancer
```
```dockerfile
    'kubectl apply -f hostname-svc-lb-local.yml'으로 실행하거나 'kubectl scale --replicas=1 deployment hostname-deployment'로
    포드 수를 줄여서 살펴보자 externalTrafficPolicy를 Local로 설정했기 때문에 해당 노드에서만 포드에 접근할 수 있다.
    
        1. externalTrafficPolicy 속성이 Cluster로 설정된다. 이 경우 모든 워커 노드에서 동일한 랜덤 포트가 개방된다. 클라우드 플랫폼의 로드 
        밸런서는 노드 중 하나로 요청을 전달하고, 노드는 다시 포드 중 하나로 요청을 전달한다. 단, 노드 간에 요청이 리다이렉트 되어 NAT이 발생하므로
        클라이언트의 IP를 보존할 수 없다.
        
        2. 서비스의 externalTrafficPolicy 속성을 Local로 설정해 생성하면 포드가 위치한 노드만 랜덤한 포트를 개방한다. 로드 밸런서는 포드가 위치한
        노드로만 요청을 전달하며, 해당 노드 내의 포드에서만 요청이 분산된다. 따라서 네트워크 홉이 한 단계 적으며, 클라이언트의 IP 또한 포드의 소스코드 
        내에 정상적으로 확인할 수 있다.
        
    그렇지만 externalTrafficPolicy를 Local로 설정하는 것이 무조건 좋은 것이 아니다. 각 노드에 포드가 고르지 않게 스케줄링됐을 때, 요청이 고르게
    분산되지 않을 수도 있다. 
    
                                               → [ 포드 a (25%)]
                              → 랜덤 포트 (50%) ┤ 
    총 요청량 100% -> 로드 밸런서 ┤                 → [ 포드 b (25%)]                 
                              → 랜덤 포트 (50%) → [ 포드 c (50%)] 
    
            [불균형 트래픽 분배 예시]
    
    위와 같이 자원 활용율 측면에서 바람직하지 않을 수도 있다는 것을 의미한다. Cluster와 Local은 둘 다 장단점이 있기 때문에 뚜렷한 정답은 없다. 
    불필요한 네트워크 홉으로 인한 레이턴시나 클라이언트의 IP 보존이 중요하지 않다면 Cluster를 사용해도 된다. 그러나 그 반대라면 Local을 사용 하는 것이
    좋은 선택일 수 있다. 
```

####6.5.6 요청을 외부로 리다이렉트하는 서비스 : ExternalName
```dockerfile
    쿠버네티스를 외부 시스템과 연동해야할 때는 ExternalName 타입의 서비스를 이용할 수도 있다. ExternalName 타입을 이용해서 서비스를 생성하면 서비스가
    외부 도메인을 가리키도록 설정할 수 있다. 예를 들어 아래 설정은 쿠버네티스 내부의 포드들이 externalname-svc라는 이름으로 요청을 보낼 경우 
    쿠버네티스의 DNS는 my.database.com으로 접근할 수 있도록 CNAME 레코드를 반환한다. 즉, externalname-svc로 요청을 보내면 my.database.com
    에 접근하게 된다. ExternalName 타입의 서비스는 쿠버네티스와 별개로 존재하는 레거시 시스템에 연동해야하는 상화엥서 유용하게 사용할 수 있다.
```
```yaml
apiVersion: v1
kind: Service
metadata:
  name: externalname-svc
spec:
  type: ExternalName
  externalName: my.database.com
```
```dockerfile
    {
        DNS 레코드 종류 중 CNMAE 레코드는 Canoncial Name의 줄임말로, 도메인을 가리키는 다른 이름을 뜻한다. 이와 비슷한 레코드로는 A 레코드가 
        있는데 A 레코드는 도메인 이름이 직접 IP로 변환되는 경우를 의미한다.
    }
    
    리소스 정리
    'kubectl delete -f ./'로 YAML 파일이 위치한 디렉토리를 통해 리소스를 삭제할 수도 있다. 
```