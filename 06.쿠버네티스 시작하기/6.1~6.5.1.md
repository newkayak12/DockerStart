#6. 쿠버네티스 시작하기
###6.1 쿠버네티스를 시작하기 전
```dockerfile
    쿠버네티스는 도커 스웜과 비교해서 쿠버네티스만이 가지는 고유한 특징이 있다.
    
    1. 모든 리소스는 오브젝트 형태로 관리된다.
    쿠버네티스는 대부분의 리소스를 '오브젝트' 형태로 관리한다. 일전에 도커 스웜은 컨테이너의 묶음을 표현하기 위해서 서비스라는 것을 사용했다. 스웜 모드의
    서비스도 컨테이너 리소스의 집합을 정의한 것이기 때문에 일종의 오브젝트라고 볼 수 있다. 그러나 쿠버네티스는 이러한 개념을 더욱 폭넓고 세밀한 단위로
    사용한다. 에를 들어 쿠버네티스는 컨테이너의 집합(Pods), 컨테이너의 집합을 관리하는 컨트롤러(Replica Set), 심지어 사용자 (Service Account),
    노드(Node)까지도 하나의 오브젝트로 사용할 수 있습니다.
    
    'kubectl api-resources' 명령어를 사용하면 꽤 많은 오브젝트를 사용할 수 있음을 알 수 있다.
    
    2. 쿠버네티스는 명령어로도 사용할 수 있지만, YAML을 더 많이 사용한다.
    도커 스웜은 docker service create.. 와 같은 명령어로 컨테이너 서비스를 생성하고 삭제했다. 쿠버네티스에서도 마찬가지로 kubectl이라고 하는 명령어
    로 쿠버네티스를 사용할 수 있으며, 대부분은 kubectl 명령어로 실행할 수 있다.
     스웜 모드에서 스택(stack)을 생성하기 위해서 YAML 파일을 사용했던 것처럼 쿠버네티스도 YAML 파일로 컨테이너 리소스를 생성하거나 삭제할 수 있다. 
    그러나 쿠버네티스에서 YAML 파일의 용도는 컨테이너뿐만 아니라 거의 모든 리소스 오브젝트들에 사용할 수 있다는 것이 큰 특징이다. 
    예를 들어서 컨테이너 자체는 물로니옥, 컨테이너의 설정값(ConfigMap), 비밀값(Secrets) 등 모두 YAML 파일로 정의해서 사용한다. 그리고 쿠버네티스에서
    실제로 서비스를 배포할 때에도 kubectl 명령어가 아닌 여러 개의 YAML 파일을 정의해서 쿠버네티스에 적용하는 방식으로 동작한다. 그래서 쿠버네티스 사용을 
    잘하려면 YAML 파일을 잘 작성하는 것이 도움이 된다.
    
    3. 쿠버네티스는 여러 개의 컴포넌트로 구성되어 있다. 
    쿠버네티스 노드의 역할은 마스터 - 워커로 나뉘어 있다. 마스터 노드는 쿠버네티스가 제대로 동작할 수 있도록 클러스터를 관리하는 역할을 담당하며, 워크 노드
    에서는 애플리케이션 컨테이너가 생성된다. 
     도커 스웜 모드를 사용할 때는 단일 도커 데몬만을 설치해 사용했지만, 쿠버네티스는 도커를 포함한 매우 많은 컴포넌트들이 실행된다. 그러나 쿠버네티스는 도커
    를 포함한 매우 많은 컴포넌트들이 실행된다. 에를 들어 마스터 노드에서는 API 서버(kube-apiserver), 컨트롤러 매니저(kube-controller-manager)
    , 스케쥴러(kube-schedular), DNS서버(coreDNS) 등이 실행되며, 모든 노드에서는 오버레이 네트워크 구성을 위해서 프록시(kube-proxy)와 네트워크
    플러그인(calico, flannel 등)이 실행된다. 이러한 컴포넌트들은 기본적으로 도커 컨테이너로서 실행되고 있다. 마스터 노드에 SSH로 접근해서 'docker ps'
    명령어를 실행해 보면 이를 확인할 수 있다.
      그리고 쿠버네티스 클러스터 구성을 위해서 'kubelet'이라는 에이전트가 모든 노드에서 실행된다. kubelet은 컨테이너의 생성, 삭제뿐만 아니라 마스터와
    워커 노드 간의 통신 역할을 함께 담당하는 매우 중요한 에이전트이다. 따라서 kubelet이 정상적으로 실행되지 않으면 해당 노드는 쿠버네티스와 제대로 연결되지
    않을 수도 있다.
      쿠버네티스의 입장에서 보면 도커 데몬 또한 하나의 컴포넌트이다. 도커 스웜 모드와 달리 쿠버네티스는 도커에 내장된 기능이 아니며, 오히려 컨테이너를 사용
    하기 위해 쿠버네티스가 도커를 이용하는 방식이다. 따라서 쿠버네티스에서 반드시 도커를 사용해야하는 것은 아니며, OCI(Open Container Initative)라는
    컨테이너의 런타임 표준을 구현한 CRI(Container Runtime Interface)를 갖추고 있다면 어떠한 컨테이너를 사용해도 문제는 없다.  
       {
        CRI는 kubelet과 통신하기 위한 인터페이스를 의미하며, CRI를 구현한 컨테이너 런타임이라면 쿠버네티스의 컨테이너로서 사용할 수 있다. 도커 컨테이너
        의 경우 runC 컨테이너 런타임을 제어하는 containerd(컨테이너-디)는 자체적으로 CRI 플러그인을 내장하고 있으므로 도커 엔진만 설치해도 쿠버네티스
        와 별다른 문제 없이 연결해서 사용할 수 있다. CRI를 구현하는 다른 오픈소스로는 cri-o가 있다. 
       }
```

### 6.2 포드(Pod) : 컨테이너를 다루는 기본 단위
#### 6.2.1 포드 사용
```dockerfile
    쿠버네티스에서는 컨테이너 애플리케이션의 기본 단위를 'Pod'라고 부르며, 포드는 1개 이상의 컨테이너로 구성된 컨테이너의 집합이다. 포드는 쿠버네티스에서
    가장 기초적이고 중요한 개념이다. 도커 엔진에서는 기본 단위가 '도커 컨테이너'였고, 스웜 모드에서는 기본 단위가 여러 개의 컨테이너로 구성된 '서비스'였다.
    이와 비슷한 맥락으로 쿠버네티스에서는 컨테이너 애플리케이션을 배포하기 위한 기본 단위로 포드라는 개념을 사용한다. 1개의 포드에는 1개의 컨테이너가 
    존재할 수도 있고, 여러 개의 컨테이너가 존재할 수도 있다. 
      간단한 예시로 Nginx 웹 서비스를 쿠버네티스에서 생성하려면 포드 1개에 Nginx 컨테이너 1개만을 포함해 생성하면 된다. 만약 여러 개를 생성하고 싶다면
      1개의 Nginx 컨테이너가 들어있는 동일한 포드를 여러 개 생성하면 된다. 이처럼 포드는 컨테이너 애플리케이션을 나타내기 위한 기본 구성 요소가 된다. 
```
```yaml
    apiVersion: v1
    kind: Pod
    metadata:
      name: my-nginx-pod
    spec: 
      containers:
        - name: my-nginx-container
          image: nginx:latest
          ports:
            - containerPort: 80
              protocol: TCP
```
```dockerfile
    쿠버네티스의 YAML은 일반적으로 'apiVersion', 'kind', 'metadata', 'spec' 네 가지 항목으로 구성된다. 
    
        - apiVersion : YAML 파일에서 정의한 오브젝트의 API 버전을 나타낸다. 오브젝트의 종류 및 개발 성숙도에 따라 apiVersion의 설정값이 달라질
        수 있다
        - kind : 리소스의 종류를 나타낸다. 위의 YAML 파일에서 생성하려고 하는 거싱 포드이기 때문에 Pod를 입력했다. kind 항목에서 사용할 수 있는
        리소스 오브젝트 종류로는 kubectl api-resources 명령어의 KIND 항목에서 확인할 수 있다. 
        - metadata : 라벨, 주석, 이름 등과 같은 리소스의 부가 정보들을 입력한다. 
        - spec : 리소스를 생성하기 위한 제세한 정보를 입력한다. 위 에시에서는 포드에 실행될 컨테이너 정보를 정의하는 containers 항목을 작성한 뒤, 
        하위 항목인 images에서 사용할 도커 이미지를 지정했다. name 항목에서는 컨테이너의 이름을, ports항목에는 Nginx 컨테이너가 사용할 포트인 80을
        입력했다. 
        
    작성한 YAML 파일은 kubectl apply -f  명령어로 쿠버네티스에 생성할 수 있다. 'kubectl apply -f nginx-pod.yaml' 
    또한 'kubectl get <오브젝트 이름>' 을 사용하면 특정 오브젝트의 목록을 확인할 수 있다. 예를 들어, "kubectl get pods" 명령어는 현재 
    쿠버네티스에 존재하는 포드의 목록을 출력한다.
    
    이 Nginx 포드를 생성할 때, YAML 파일에 사용할 포트(ContainerPort)를 정의하기는 했지만, 아직 외부에서 접근할 수 있는 상태는 아니다. 따라서 포드
    의 Nginx 서버로 요청을 보내려면 포드 컨테이너의 내부 IP로 접근해야 한다.
    kubectl describe 명령어를 사용하면 생성된 리소스의 자세한 정보를 얻어올 수 있다. 예를 들어, 포드의 자세한 정보를 출려하고 싶다면 
    'kubectl describe pods <포드 이름>'처럼 명령어를 사용한다. 해당 명령어를 입력하면 많은 정보가 출력되는데, 그 중 IP는 외부 접근이 가능한 IP가 
    아니라 클러스터 내부에서만 접근할 수 있다. docker run 명령어에서 -p 옵션 없이 컨테이너를 실행한 것과 비슷하다고 생각하면 이해가 쉬울 것이다. 
    
    쿠버네티스 외부 또는 내부에서 포드에 접근하려면 서비스라고 하는 쿠버네티스 오브젝트를 따로 생성해야 한다. (서비스 오브젝트 없이 클러스터 노드에서 해당 
    IP로 HTTP 요청을 던질 수도 있다.) 혹시 이도 어렵다면 'kubectl run -i --tty --rm debug --image=alicek106/ubuntu:curl \
    --restart=Never bash' 로 테스트용 포드를 생성해서 사용할 수도 있다.
    
    포드 컨테이너 내부로 직접 들어가려면 docker exdc와 비슷하게 쿠버네티스에서도 'kubectl exec' 명령으로 포드 컨테이너에 명령어를 전달할 수 있다.
    예를 들어 'kubectl exec -it my-nginx-pod bash'으로 확인을 해볼 수 있다. 또한 도커에서 docker logs 명령어를 사용했던 것처럼 쿠버네티스에서
    도 kubectl logs 명령어로 포드의 로그를 확인할 수 있다. 쿠버네티스의 오브젝트는 'kube delete -f'로 쉽게 삭제할 수 있다. 'kubectl delete \
    -f nginx-pod.yaml'은 nginx-pod.yaml에 정의된 Nginx를 삭제하는 명령어이다. 또는 'kubectl delete pod <포드 이름>'으로도 가능하다.
```

#### 6.2.2 포드 vs. 도커 컨테이너
```dockerfile
    위의 기능들만 본다면 포드는 docker run으로 생성한 단일 nginx 컨테이너와 크게 다르지 않아 보인다. 포드는 컨테이너 IP 주소를 가지고 있어 쿠버네티스
    클러스터 내부에서 접근할 수 있고, kubectl exec 명령어로 포드 컨테이너 내부로 들어갈 수도 있으며, kubectl logs 명령어로 포드의 로그를 확인할 수도
    있기 때문이다. 그렇다면 왜 쿠버네티스는 왜 '도커 컨테이너'가 아니라 '포드'라는 새로운 개념을 사용하는 걸까?
    
    쿠버네티스가 포드를 사용하는 이유는 컨테이너 런타임의 인터페이스 제공 등 여러 가지가 있지만, 그 이유 중 하나는 여러 리눅스 네임스페이스(namespace)를
    공유하는 여러 컨테이너들을 추상화된 집합으로 사용하기 위해서이다. 좀 더 자세히 보면
    'kubectl get pods' 명령어로 포드의 목록을 출력했을 때, READY 항목에서 1/1이라는 출력을 볼 수 있다. 이는 한 개의 포드가 있고 한 개가 정상적으로
    준비됐다는 뜻이다.
    
    실제로 대부분 쿠버네티스의 컨테이너 애플리케이션은 이처럼 1개의 컨테이너로 포드를 구성해서 사용한다. 그러나 1/1이라는 항목에서 알 수 있듯이, 포드는 
    반드시 1개의 컨테이너로 구성해야하는 것은 아니다. 
```
```yaml
    apiVersion: v1
    kind: Pod
    metadata:
      name: my-nginx-pod
    spec: 
      containers:
        - name: my-nginx-container
          image: nginx:latest
          ports:
            - containerPort: 80
              protocol: TCP

        - name: ubuntu-sidecar-container
          image: alicek106/rr-test:curl
          command: ["tail"]
          args: ["-f", "/dev/null"] # 컨테이너가 종료되지 않도록 유지한다.
```
```dockerfile
    YAML에서 대시(-)를 사용하는 항목은 여러 개의 항목을 정의할 수 있음을 의미한다. 예를 들어 위에서 사용한 spec, contianers의 하위 항목은 
    "- name: my-nginx-container"와 같이 대시로 구분되며, 여러 개의 컨테이너를 정의할 수 있다. 따라서 이번에는 포드에 우분투를 하나 더 추가했다.
    
    {
        포드의 YAML 파일에서 사용되는 command와 args는 컨테이너 내부에서 가장 먼저 실행될 프로세스를 지정한다. YAML 파일에서 command를 설정하면
        도커 컨테이너의 Entrypoint로, 포드에서 args를 설정하면 도커 CMD로 치환된다고 생각하면 된다.
    }
    
    앞서 포드를 생성했던 것처럼 'kubectl apply -f' 명령을 사용해서 YAML 파일을 쿠버네티스에 적용하고 시간이 지나면 2개의 컨테이너가 실행 중인 것을 
    알수 있다. 이번에는 'kubectl exec' 명령어를 이용해 새롭게 추가된 우분투 컨테이너의 내부로 들어가보면 kubectl exec, logs 등과 같은 명령어를
    사용할 때는 -c 옵션으 이용해 포드의 어떤 컨테이너에 대해 명령어를 수행할지 명시할 수 있다. 'kubectl exec -it my-nginx-pod -c ubuntu-side\
    car-container bash'와 같음 명령어로 배시 쉘을 실행한다.  ubuntu-sidecar-container 컨테이너 내부에서 로컬호스트로 HTTP 요청을 전송하면
    Nginx서버의 응답이 도착하는 것을 확인할 수 있다. 여기서 이상한 점을 발견할 수 있다. 우분투 컨테이너가 Nginx 서버를 실행하고 있지 않은데도, 우분투
    컨테이너의 로컬 호스트에서 Nginx 서비스로 접근이 가능하기 때문이다. 이는 포드 내의 컨테이너들이 네트워크 네임스페이스 등과 같은 리눅스 네임스페이스를
    공유해서 사용하기 떄문이다. 
    
    {
        네트워크 네임스페이스는 컨테이너의 고유햔 네트워크 환경을 제공해주는 역할을 담당한다. 예를 들어 docker run 명령어로 docker0 브릿지에 연결된
        컨테이너가 생성됐다면, 그 컨테이너는 자기 자신만의 고유한 네트워크 네임스페이스를 가지게 된다. 그렇기 때문에 호스트 및 다른 컨테이너와 다른 고유한
        IP를 유지할 수 있는 것이다.    
    }
    
    docker run --net container:[컨테이너 이름]  옵션을 사용하는 컨테이너 네트워크를 보면 컨테이너 네트워크 네임스페이스를 컨테이너 간의 공유해서 사용
    할 수 있도록 설정하기 때문에 여러 개의 컨테이너가 동일한 네트워크 환경을 가진다. 쿠버네티스의 포드 또한 이러한 리눅스 네임스페이스의 공유 개념을 사용하고
    있다. 그러나 포드가 공유하는 리눅스 네임스페이스에 네트워크 환경만 있는 것은 아니다. 1개의 포드에 호함된 컨테이너들은 여러 개의 리눅스 네임스페이스를 
    공유한다. 
```

#### 6.2.3 완전한 애플리케이션으로서의 포드
```dockerfile
    앞서 말했던 것처럼 실제 쿠버네티스 환경에서는 1개의 컨테이너로 구성된 포드를 사용하는 경우가 많다. 그렇다면 왜 하나의 포드에 여러 개의 컨테이너가 포함
    되어야 하는지가 궁금할 수도 있는데 여기서 한 가지 유의해야 할 점은 '하나의 포드는 하나의 완전한 애플리케이션'이라는 점이다. 따로 부가적인 기능이 필요
    하다면 주 컨테이너에 기능 확장을 위한 추가 컨테이너를 함께 포드에 포함시킬 수 있다. 이렇게 포드에 정의된 부가적인 컨테이너를 사이드카 컨테이너라고 부르며,
    사이드카 컨테이너는 포드 내의 다른 컨테이너와 네트워크 환경 등을 공유하게 된다. 때문에 포드에 포함된 컨테이너들은 모두 같은 워커 노드에서 함께 실행된다.
    
    이러한 구조 및 원리에 따라 포드에 정의된 여러 개의 컨테이너는 하나의 완전한 애플리케이션으로서 동작하게 되는 것이다. 이것이 도커 컨테이너와 
    쿠버네티스의 포드의 차이점이다. 
```

###6.3 레플리카셋(Replica Set) : 일정 개수의 포드를 유지하는 컨트롤러
####6.3.1 레플리카셋을 사용하는 이유
```dockerfile
    쿠버네티스의 기본 단위인 포드는 여러 개의 컨테이너를 추상화해 하나의 애플리케이션으로 동작하도록 만드는 훌륭한 컨테이너 묶음이다. 그러나 YAML에 포드만
    정의해 생성하게 되면 이 포드의 생애 주기(LifeCycle)는 어떻게 될까? 예를들어 2개의 컨테이너가 담겨 있는 포드는 'kubectl delete' 명령어로 포드를
    삭제하면 그 포드의 컨테이너 또한 삭제된 뒤 쿠버네티스에서 영원히 사라지게 된다. 이처럼 YAML 파일에 포드만 정의해 생성할 경우 해당 포드는 오직 쿠버네티
    스 사용자에 의해 관리된다. 단순히 포드의 기능을 테스트하는 드으이 간단한 용도로는 이렇게 사용할수 있을지 모른다. 그렇지만 실제로 외부 사용자의 요청을 
    처리해야하는 마이크로 서비스 구조의 포드라면 이렇게 사용하기 어렵다. 스웜 모드에서 다뤘던 것처럼 마이크로 서비스에서는 여러 개의 동일한 컨테이너를 
    생성한 뒤 외부 요청이 각 컨테이너 적절히 분배될 수 있어야 한다.
    
    쿠버네티스에서는 기본 단위가 포드이기 때문에 동일한 여러 개의 포드를 생성해 외부 요청을 각 포드에 분배하는 방식을 사용해야 할 것이다. 그렇지만 동일한
    여러 개의 포드를 어떻게 생성할 수 있을까? 아마 가장 간단한 방법은 다른 이름을 가지는 여러 개의 포드를 직접 만드는 방식일 것이다.
```
```yaml
    apiVersion: v1
    kind: Pod
    metadata:
      name: my-nginx-pod-a
    spec: 
      containers:
        - name: my-nginx-container
          image: nginx:latest
          ports:
            - containerPort: 80
              protocol: TCP
---
    apiVersion: v1
    kind: Pod
    metadata:
      name: my-nginx-pod-b
    spec:
      containers:
        - name: my-nginx-container
            image: nginx:latest
            ports:
              - containerPort: 80
                protocol: TCP
```
```dockerfile
    그러나 여러 개의 포드를 직접 생성하는 방법은 여러 가지 이유로 적절하지 않다. 우선 동일한 포드의 개수가 많아질수록 이처럼 일일이 정의하는 것은 매우
    비효율적이다. 또한 포드가 어떠한 이유로든지 삭제되거나, 포드가 위치한 노드에 장애가 발생해 더 이상 포드에 접근하지 못하게 됐을 때, 직접 포드를 삭제하고
    다시 생성하지 않는 한 해당 포드는 다시 복구되지 않는다.
    
    아래의 예시에서는 kubectl get pods에 -o wide 옵션을 붙여서 포드가 실행 중인 워커 노드를 확인한 뒤 워커 노드 서버를 종료해봤다. 포드가 생성된
    노드에 장애가 발생하더라도 포드는 다른 노드에서 다시 생성되지 않으며, 포드는 단순히 종료가 된다. 이처럼 포드만 YAML 파일에 정의해 사용하는 방식은 
    여러 가지 한계점이 있다. 따라서 쿠버네티스에서 포드만 정의해서 사용하는 경우는 거의 없으며, 이러한 한계점을 해결해주는 것이 레플리카셋(replicaSet)
    이라는 쿠버네티스 오프젝트이다. 레플리카셋이 수행하는 역할을 간단하게 설명하면 아래와 같다.
    
        1. 정해진 수의 동일한 포드가 항상 실행되도록 관리한다.
        2. 노드 장애 등의 이윯 포드로 사용할 수 없다면 다른 노드에서 포드를 다시 생성한다. 
    
    따라서 동일한 포드를 안정적으로 여러 개 실행할 수도 있고, 워커 노드에 장애가 생기더라도 정해진 개수의 포드를 유지할 수도 있다. 이처럼 레플리카셋이 
    포드를 관리하기 때문에 사용자가 직접 관리할 일은 거의 없다. 
```

####6.3.2 레플리카셋 사용하기
```dockerfile
    레플리카셋을 이용해서 YAML을 작성해보면 아래와 같다.
```
```yaml
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: replicaset-nginx
spec: 
  replicas: 3
  selector:     ## 레플리카셋 정의 시작
    matchLabels:
      app: my-nginx-pods-label  ## 레플리카셋 정의 끝
  template:   ## 포드 정의
    metadata:
      name: my-nginx-pod
      labels:
        app: my-nginx-pods-label
    spec:
      containers:
        - name: nginx
          image: nginx:latest
          ports:
            - containerPort: 80
```
```dockerfile
    리소스의 고유한 이름은 포드 뿐만 아니라 모든 쿠버네티스 오브젝트에서 설정할 수 있으며, 이 레플리카셋의 이름은 metadata의 name 항목에서 
    replica-nginx로 설정했다. 그런데 이전의 포드를 설정할 때 사용한 YAML파일과 비교해보면 새로운 항목이 몇 가지 추가된 것을 알 수 있다. 
    {
        앞으로 YAML 파일에서 들여쓰기된 항목의 이름을 표현하기 위해 상위 항목부터 이름을 표기하는 방법을 사용할 것이다. 예를 들어서, metadata.name이면
        ```
            metadata:
              name: replicaset-nginx
        ```
        와 같이 말이다. 
        
        1. spec.replicas: 동일한 포드를 몇 개 유지시킬 것인지 설정한다. 위 예시에는 3개로 설정했기 때문에 레플리카셋을 3개 만든다.
        2. spec.template 아래의 내용들 : 포드를 생성할 때 사용할 템플릿을 정의한다. template 아래의 내용을 자세히 들여다보면 이전에 작성했던
        nginx-pod.yaml 파일의 내용과 거의 다르지 않음을 알 수 있다. 즉, 포드를 사용했던 내용을 동일하게 레플리카셋에도 정의함으로써 어떠한 포드를 
        어떻게 생성할지를 명시한다. 이를 보통 포드 스펙, 또는 포드 템플릿이라고 한다.
    }
    파일을 작성했다면 위 내용으로 레플리카셋을 생성할 수 있다. 'kubectl apply -f replicaset-nginx.yaml' 명령어를 입력하면 사용할 수 있다. 
    {
        kubectl 명령어를 사용할 떄, 이름을 줄여 쓸 수 있는 몇 가지 쿠버네티스 오브젝트가 있다. 예를 들어 pods 대신 po를, replicasets 대신 rs를
        사용할 수 있다. 물론 오브젝트 이름을 줄여서 사용해도 kubectl은 동일하게 동작한다. 사용할수 있는 줄임말 목록은 'kubectl api-resources'
        명령어의 SHORTNAMES에서 확인할 수 있다.
    }
    docker-compose와 유사하게 변경점이 있으면 레플리카셋을 삭제하고 다시 생성할 필요 없이 기존의 yaml을 수정해서 사용할 수 있다. 이미 생성된 리소스의
    속성을 변경하는 기능을 제공하기 때문이다. 이를 위해서 'kubectl edit, kubectl patch' 등 여러 방법을 사용할 수 있지만 yaml만 바꿔도 사용할 수
    있다. 이후, 'kubectl apply -f' 명령어를 실행하면 적용이 된다.
```
####6.3.3 레플리카셋의 동작 원리
```dockerfile
    앞서 살펴본 예시만 보면 레플리카 셋은 포드와 연결된 것처럼 보인다. 레플리카셋을 생성하면 포드가 생서되고, 레플리카 셋을 삭제하면 포드 또한 삭제되기 
    때문이다. 그러나 실제로는 레플리카 셋은 포드와 연결되지 ㅇ낳았다. 오히려 느슨한 연결(loosely coupled)을 유지하고 있으며, 이러한 느슨한 연결은 포드
    와 라벨 셀렉터(Label Selector)를 이용해서 이뤄진다. 
    이전에 포드를 성성할 때 metadata 항목에서는 리소스의 부가적인 정보를 설정할 수 있었다. 그 부가 정보 중에는 리소스의 고유한 이름뿐만 아니라 주석,
    라벨 등도 포함된다. 특히 라벨은 포드 등의 쿠버네티스 리소스를 분류할 때 유용하게 사용할 수 있는 메타데이터이다.
    라벨은 쿠버네티스 리소스의 부가적인 정보를 표현할 수 있을 뿐만 아니라, 서로 다른 오브젝트가 서로를 찾아야 할 때 사용되기도 한다. 예를 들어서 레플리카셋은
    'spec.selector.matchLabel'에 정의된 라벨을 통해 생성해야하는 포드를 찾는다. 즉, app:my-nginx-pods-label 라벨을 가지는 포드의 개수가 
    replicas 항목에 정의된 숫자인 3개와 일치하지 않으면 포드를 정의하는 포드 템플릿 항목 내용을 기반으로 포드를 생성한다. 
    그럼 같은 라벨을 갖는 포드를 미리 생성해 놓은 다음, 레플리카셋을 생성하면 어떻게 될까? 생성 후 'kubectl get pods --show-labels'로 라벨도 
    함께 출력할 수 있다. 여기서 yaml을 통해서 포드를 생성하면 부족한 수량만큼 포드가 생성된다. 그렇다면 수동으로 생성한 포드를 삭제하면 어떻게 될까?
    'kubectl delete pods [포드 라벨]'을 실행하면 부족한 양만큼 알아서 새로운 포드를 생성하는 것을 알 수 있다.
    {
        ! 레플리카셋과 포드의 라벨은 고유한 Key-Value 이어야한다. 레플리카셋과 동일한 라벨을 갖는 포드를 직접 생성하는 것은 좋지 않다.
    }
    
    그렇다면 레플리카셋이 생성해 놓은 포드의 라벨을 삭제한다면 어떻게 될까? 이번에는 'kubectl edit' 명령어로 포드 중 하나의 라벨을 삭제해보겠다.
    'kubectl edit'은 리소스의 속성을 변경할 수 있도록 텍스트 편집기를 실행하며, 변경 사항을 적용하려면 파일을 저장한 뒤 빠져나오면 된다.
    
    {
        kubectl edit 명령어는 포드뿐만 아니라 모든 종류의 쿠버네티스 오브젝트에 사용할 수 있으며, YAML에서 설정하지 않았던 상세한 리소스의 설정까지 
        확인할 수 있다. 예를 들어서 레플리카셋으로부터 생성된 포드는 레플리카셋의 이름을 ownerReferenes라는 항목에 저장하고 있다. 
    }
    
    'kubectl edit pods replicaset-nginx-[uuid]'를 입력하고 
    
    labels:  ##이 부분을
        app: labelName ## 모두 지웠을 때
    
    변경 사항을 적용하고 'kubectl get pods --show-labels'로 목록을 조회하면 라벨이 떨어진 포드의 수만큼 새롭게 포드가 생성된다. 이 포드는 레플리카
    셋을 삭제('kubectl delete rs replicaset-nginx')해도 잔존하므로 수동으로 삭제해야한다. 'kubectl delete pods replicaset-nginx-\
    [uuid]'
    
    결과적으로 보면 레플리카 셋의 목적은 지정한 개수의 포드를 유지하는 것이 목적이라는 것이다 오해 하지 말아야 할 점은 레플리카셋의 목적이 
    '포드를 생성하는 것'이 아니라는 것이다.   
```
####6.3.4 레플리케이션 컨트롤러 vs. 레플리카셋
```dockerfile
    이전 버전의 쿠버네티스에서는 레플리카셋이 아닌 레플리케이션 컨트롤러(Replication Controller)라는 오브젝트를 통해서 포드의 개수를 유지했다. 
    그러나 쿠버네티스 버전이 올라가고 레플리케이션 컨트롤러는 deprecated되었다. 
    레플리카셋이 레플리케이션 컨트롤러와 다른 점 중 하나는 "표현식(matchExpression)"기반의 라벨 셀렉터를 사용할 수 있다는 것이다.  예를 들어 
    레플리카셋의 YAML 파일에서 selector 항목은 아래와 같이 정의할 수도 있다. 
```
```yaml
selector:
  matchExpressions:
    - key: app
      values:
        - my-nginx-pods-label
        - your-nginx-pods-label
      operator: In
  template: ## 중략
```
```dockerfile
    위 예시는 키가 app인 라벨을 가지고 있는 포드들 중에서 values 항목에 정의된 값들이 존재(In)하는 포드들을 대상으로 하겠다는 의미이다. 따라서 
    app:my-nginx-pods-label이라는 라벨을 가지는 포드뿐만 아니라 app:your-nginx-pods-labeldㅣ라는 라벨을 가지는 포드 또한 레플리카 셋의 관리
    하에 놓이게 된다.
```

###6.4 디플로이먼트(Deployment): 레플리카셋, 포드의 배포를 관리
####6.4.1 디플로이먼트 사용하기
```dockerfile
    레플리카셋만 사용해도 충분히 마이크로서비스 구조의 컨테이너를 구성할 수 있을 것 같지만, 실제 쿠버네티스 운영 환경에서 레플리카셋을 YAML 파일에서 
    사용하는 경우는 거의 없다. 대부분은 레플리카셋과 포드의 정보를 정의하는 디플로이먼트(Deployment)라는 이름의 오브젝트를 YAMl 파일에 정의해서 사용한다.
    디플로이먼트는 레플리카셋의 상위 오브젝트이기 때문에 디플로이먼트를 생성하면 해당 디플로이먼트에 대응하는 레플리카셋도 함께 생성된다. 따라서 디플로이먼트를
    사용하면 포드와 레플리카셋을 직접 생성할 필요가 없다.  
```
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-nginx-deployment
spec:
  replicas: 3
  selector: 
    matchLabels:
      app: my-nginx
  template:
    metadata:
      name: my-nginx-pod
      labels:
        app: my-nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.10
        ports: 
          - containerPort: 80
```
```dockerfile
    위의 YAML 파일의 내용을 훑어보면 단지 kind 항목이 Deployment로 바뀌었을 뿐, 레플리카셋의 YAML은 거의 변경된 부분이 없다. 
    'kubectl apply -f deployment-nginx.yaml'으로 실행하고 'kubectl get deployment'로 출력할 수 있다.  확인해 보면 READY 항목에
     3/3이라는 출력으로 3개의 포드가 준비된 것을 알 수 있다. 그러나 포드 개수 유지는 레플리카셋의 담당이므로 실제로는 디플로이먼트와 레플리카셋이 함께
     생성되어 있을 것이다. 즉, 디플로이먼트 생성으로 레플리카셋이 생성됐고, 레플리카셋이 포드를 생성한 것이다. 따라서 디플로이먼트를 삭제하면 레플리카셋과
     포드 또한 함꼐 삭제된다.  'kubectl delete deploy my-nginx-deployment'
```
####6.4.2 디플로이먼트를 사용하는 이유
```dockerfile
    그렇다면 쿠버네티스는 왜 레플리카셋을 그대로 사용하지 않고 굳이 상위 개념인 디플로이먼트를 다시 정의해서 사용하는가? 레플리카셋만으로도 동일한 개수의 
    포드를 충분히 유지할수 있음에도 불구하고 말이다.
    디플로이먼트를 사용하는 핵심적인 이유 중 하나는 애플리케이션의 업데이트와 배포를 더욱 편하게 하기 위해서이다. 디플로이먼트라는 이름 그대로 디플로이먼트는
    컨테이너 애플리케이션을 배포하고 관리하는 역할을 담당한다. 예를들어 애플리케이션을 업데이트할 때 레플리카셋의 변경 사항을 저장하는 리비전(revision)을
    남겨 롤백을 가능하게 해주고, 무중단 서비스를 위해 포드의 롤링 업데이트 전략을 지정할 수도 있다. 
    
    예시를 들어서 'kubectl apply -f deployment-nginx.yaml --record'로 디플로이를 한다. 그리고 컨테이너 애플리케이션의 버전이 업데이트 되어
    포드의 이미지를 변경해야한다고 가정해보자. 이때 디플로이먼트에서 생성된 포드의 이미지를 변경할 때는 'kubectl set image' 명령어를 사용할 수 있다.
    예를 들어 포드의 이미지의 버전을 nginx:1.11로 업데이트하려면 'kubectl set image deployment my-nginx-deployment nginx=nginx:1.11 \
    --record'를 입력하면 된다.
    {
        'kubectl set image' 대신 YAML을 수정한 다음 'kubectl apply -f'로 적용할 수도 있다. 혹은 'kubectl edit' 명령어를 사용해도 된다.
    }
    
    그 뒤에 'kubectl get pods'를 입력해서 확인하면 두 개의 레플리카 셋이 있는 것을 볼 수 있다. DESIRED, CURRENT 등의 항목이 3으로 되어 있는 
    레플리카셋이 이미지 업데이트로 새롭게 생긴 레플리카셋이다. 다른 레플리카셋은 0으로 설정되어 있는(포드 생성이 안된) 레플리카셋이다. 디플로이먼트는 포드의 
    정보를 업데이트함으로써 새로운 레플리카셋과 포드를 생성했음에도 불구하고 이전의 레플리카셋을 삭제하지 않고 남겨두고 있다. 즉, 디플로이먼트는 포드의
    정보가 변경되어 업데이트가 발생했을 때, 이전의 정보를 리비전으로서 보존한다. 'kubectl rollout history deployment my-nginx-deployment'
    로 이를 확인할 수 있다. '--record=true' 옵션으로 디플로이먼트를 변경하면 변경 사항을 위와 같이 디플로이먼트에 기록함으로써 해당 버전의 레플리카셋을
    보존한다. 만약 이전 버전의 레플리카셋으로 되돌리는 롤백을 하고 싶다면 '--to-revision'에 되돌리려는 리비전 번호를 입력하면 된다.
    'kubectl rollout undo deployment my-nginx-deployment --to-revision=1' 쿠버네티스 리소스의 자세한 정보를 출력하는 
    'kubectl describe' 명령어를 사용해 디플로이먼트의 정보를 출력해 보면 현재의 레플리카셋 리비전 정보와 활성화된 레플리카셋 이름을 확인할 수 있다.
    이처럼 디플로이먼트는 여러 개의 레플리카셋을 관리하기 위한 상위 오브젝트이다. 디플로이먼트르 사용하면 이러한 레플리카셋의 리비전 관리뿐만 아니라 다양한
    포드의 롤링 업데이트 정책을 사용할 수도 있다는 장점이 있다. 따라서 쿠버네티스에서도 공식적으로 디플로이먼트를 사용할 것을 권장한다.
```
#### 6.4.3 리소스 정리
```dockerfile
    'kubectl delete deployment, pod, rs -all'로 모든 리소스를 정리할 수 있다.
```

###6.5 서비스(Service) : 포드를 연결하고 외부에 노출
```dockerfile
    쿠버네티스의 포드는 도커의 컨테이너와 마찬가지로 영속적이지 않아 항상 변할 수 있다. 여러 개의 디플로이먼트를 하나의 완벽한 애플리케이션으로 연동하려면 
    포드의 IP가 아닌, 서로를 발견(Discovery)할 수 있는 다른 방법이 필요하다.
    
    이전 장에서 다뤘던 도커 사용 방법을 되살펴보면 도커 컨테이너는 -p(publish) 옵션으로 손쉽게 컨테이너를 외부로 노출할 수 있었다. 즉, 컨테이너가 생성됨
    과 동시에 외부로 노출되는 방식이었다. 또한 오버레이 네트워크가 도커 사용자 정의 네트워크, docker run --link 옵션으로 컨테이너들이 서로를 이름으로 
    접근할 수도 있었다.
    
    그렇지만 쿠버네티스에스는 포드에 접근하도록 정의하는 방법이 도커와는 약간 다르다. docker run -p 명령어와는 달리 쿠버네티스는 디플로이먼트를 생성할 때
    포드를 외부로 노출하지 않으며, 디플로이먼트의 YAML 파일에는 단지 포드의 애플리케이션이 사용할 내부 포트만 정의한다. 이전의 Nginx 디플로이먼트를 생성
    했을때 사용했던 YAML 파일 중에서 containerPort 항목이 파로 그것이다. 그러나 YAML 에서 containerPort 항목을 정의했다고 해서 이 포드가 바로 
    외부에 노출되는 것은 아니다. 이 포트를 외부로 노출해 사용자들이 접근하거나, 다른 디플로먼트의 포드들이 내부적으로 접근하려면 서비스(Service)라고 부르는
    별도의 쿠버네티스 오브젝트를 생성해야한다. 서비스는 포드에 접근하기 위한 규칙을 정의하기 때문에 쿠버네티스에서 애플리케이션을 배포하기 위해서는 반드시 
    알아야할 오브젝트이다. 서비스에는 다양한 기능이 있지만, 핵심 기능만 살펴보면 아래와 같다.
    
        1. 여러 개의 포드에 쉽게 접근할 수 있도록 고유한 도메인 이름을 부여한다.
        2. 여러 개의 포드에 접근할 때, 분산하는 로드 밸런서 기능을 수행한다.
        3. 클라우드 플랫폼의 로드 밸런서, 클러스터 노드의 포트 등을 통해 포드를 외부로 노출한다. 
    
    {
        쿠버네티스를 설치할 때 기본적으로 calico, flannel 등의 네트워크 플러그인을 사용하도록 설정되기 때문에 자동으로 오버레이 네트워크를 통해 각 포드
        끼리 통신할 수 있다. 단, 어떠한 네트워크 플러그인을 사용하느냐에 따라서 네트워킹 기능 및 성능에 차이가 있을 수도 있다.
    }
```
####6.5.1 서비스(Service)의 종류
```dockerfile
    서비스의 개념과 사용 방법을 익히기 위해 포드와 서비스를 연결해 보자. 
```
```yaml
apiVersion: apss/v1
kind: Deployment
metadata:
  name: hostname-deployment
spec:
  replicas: 3
  selector: 
    matchLabels:
      app: webserver
  template:
    metadata:
      name: my-webserver
      labels:
        app: webserver
    spec:
      containers:
      - name: my-webserver
        image: alicek106/rr-test:echo-hostname
        ports: 
        - containerPort: 80
```
```dockerfile
    'kubectl get pods -o wide' 명령어로 포드의 ip를 확인한 뒤 curl 등과 같은 도구로 http 요청을 보내 포드의 이름을 확인할 수 있다. 혹은
    'kubectl run -i --tty --rm debug --image=alicek106/ubuntu:curl --restart=Never curl 192.168.109.17 | grep hello'으로
    클러스터의 노드 중 하나에 접속해서 노드에서 curl을 통해 포드로 접근해도 된다.
    포드에 접근할 수 있는 규칙을 정의하는 서비스 리소스를 새롭게 생성해 보자. 한가지 알아야 할 점은 쿠버네티스의 서비스는 포드에 어떻게 접근할 것이냐에 따라
    종류가 여러 개로 세분화 되어 있다. 따라서 목적에 맞는 적절한 서비스 종류를 선택해야한다. 
    
        1. ClusterIP 타입 : 쿠버네티스 내부에서만 포드들에 접근할 때 사용한다. 외부로 포드를 노출하지 않게 때문에 쿠버네티스 클러스터 내부에만 사용되는
        포드에 적합하다.
        2. NodePort 타입 : 포드에 접근할 수 있는 포트를 클러스터의 모든 노드에 동일하게 개발한다. 따라서 외부에서 포드에 젖ㅂ근할 수 있는 서비스 타입
        이다. 접근할 수 있는 포트는 랜덤으로 정해지지만, 특정 포트로 접근하도록 설절할 수도 있다. 
        3. LoadBalancer 타입 : 클라우드 플랫폼에서 제공하는 로드 밸러서를 동적으로 프로비저닝해 포드에 연결한다. NodePort 타입과 마찬가지로 외부에서
        포드에 접근할 수 있는 서비스 타입이다. 그렇지만 일반적으로 AWS, GCP 등과 같은 클라우드 플랫폼 환경에서만 사용할 수 있다.
        
    예를 들어, 앞서 생성했던 포드를 내부에서만 접근하려면 ClusterIP, 외부에서 접근하려면 NodePort, 실제 운영 환경은 LoadBalancer 타입을 사용하면 된다. 
```
